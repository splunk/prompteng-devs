{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Foundation\n",
    "\n",
    "| **Aspect** | **Details** |\n",
    "|-------------|-------------|\n",
    "| **Goal** | Set up your development environment and learn the 4 core elements of effective prompts |\n",
    "| **Time** | ~20 minutes |\n",
    "| **Prerequisites** | Python 3.8+, IDE with notebook support, API access (GitHub Copilot, CircuIT, or OpenAI) |\n",
    "| **Setup Required** | Clone the repository and follow [Quick Setup](../README.md) before running this notebook |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Why Prompt Engineering for Software Engineers?\n",
    "\n",
    "### What is Prompt Engineering?\n",
    "\n",
    "**Prompt Engineering** is the fastest way to harness the power of large language models. By interacting with an LLM through a series of questions, statements, or instructions, you can adjust LLM output behavior based on the specific context of the output you want to achieve.\n",
    "\n",
    "**Effective prompt techniques can help your business accomplish the following benefits:**\n",
    "\n",
    "- **Boost a model's abilities and improve safety**\n",
    "- **Augment the model with domain knowledge and external tools** without changing model parameters or fine-tuning\n",
    "- **Interact with language models to grasp their full capabilities**\n",
    "- **Achieve better quality outputs through better quality inputs**\n",
    "\n",
    "### Two Ways to Influence LLM Behavior\n",
    "\n",
    "**1. Fine-tuning (Traditional Approach)**\n",
    "- Adjust the model's weights/parameters using training data to optimize a cost function\n",
    "- **Expensive process** - requires significant computation time and cost\n",
    "- **Limited flexibility** - model is locked into specific behavior patterns\n",
    "- **Problem:** Still produces vague, inconsistent results without proper context\n",
    "\n",
    "**2. Prompt Engineering vs. Context Engineering**\n",
    "\n",
    "According to [Anthropic's engineering team](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), there's an important distinction:\n",
    "\n",
    "- **Prompt Engineering** refers to methods for writing and organizing LLM instructions for optimal outcomes\n",
    "- **Context Engineering** refers to the set of strategies for curating and maintaining the optimal set of tokens (information) during LLM inference, including all the other information that may land there outside of the prompts\n",
    "\n",
    "**Key Difference:** Prompt engineering focuses on writing effective prompts, while context engineering manages the entire context state (system instructions, tools, external data, message history, etc.) as a finite resource.\n",
    "\n",
    "### The Evolution: From Prompting to Context Engineering\n",
    "\n",
    "**Traditional Prompting** is asking AI questions without providing sufficient context, leading to generic, unhelpful responses. It's like asking a doctor \"fix me\" without describing your symptoms.\n",
    "\n",
    "**Context Engineering** treats context as a finite resource that must be carefully curated. As [Anthropic explains](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), \"context is a critical but finite resource for AI agents\" that requires thoughtful management.\n",
    "\n",
    "**Prompt Engineering** focuses on writing effective instructions, while **Context Engineering** manages the entire information ecosystem that feeds into the model.\n",
    "\n",
    "| **Traditional Prompting** | **Context Engineering** | **Prompt Engineering** |\n",
    "|---------------------------|-------------------------|-------------------------|\n",
    "| ‚ùå \"Fix this code\" | ‚ö†Ô∏è \"Fix this code. Context: Python e-commerce function. Tools: [code_analyzer, refactor_tool]. History: [previous attempts]\" | ‚úÖ \"You are a senior Python developer. Refactor this e-commerce function following SOLID principles, add type hints, handle edge cases, and maintain backward compatibility. Format your response as: 1) Analysis, 2) Issues found, 3) Refactored code.\" |\n",
    "| ‚ùå \"Make it better\" | ‚ö†Ô∏è \"Improve this security function. Context: Critical system. Available tools: [security_scanner, vulnerability_checker]. Previous findings: [XSS vulnerability found]\" | ‚úÖ \"Act as a security expert. Analyze this code for vulnerabilities, performance issues, and maintainability problems. Provide specific fixes with code examples. Use this format: [Security Issues], [Performance Issues], [Code Quality], [Solutions].\" |\n",
    "| ‚ùå \"Help me debug\" | ‚ö†Ô∏è \"Debug this error. Context: Production system. Tools: [log_analyzer, system_monitor]. Recent changes: [deployment at 2pm]\" | ‚úÖ \"You are a debugging specialist. Debug this error: [specific error message]. Context: [system details]. Expected behavior: [description]. Use step-by-step troubleshooting approach: 1) Reproduce, 2) Isolate, 3) Fix, 4) Test.\" |\n",
    "\n",
    "**Without Context (Traditional):**\n",
    "```\n",
    "User: \"Fix this code\"\n",
    "AI: \"I'd be happy to help! Could you please share the code you'd like me to fix?\"\n",
    "```\n",
    "\n",
    "**With Context (Prompt Engineering):**\n",
    "```\n",
    "User: \"Fix this code: def calculate_total(items): return sum(items)\n",
    "Context: This is a Python function for an e-commerce checkout. \n",
    "Requirements: Handle empty lists, add type hints, include error handling.\n",
    "AI: Here's the improved function with proper error handling and type hints...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Elements of a Prompt\n",
    "\n",
    "A prompt's form depends on the task you are giving to a model. As you explore prompt engineering examples, you will review prompts containing some or all of the following elements:\n",
    "\n",
    "### **1. Instructions**\n",
    "This is a task for the large language model to do. It provides a task description or instruction for how the model should perform.\n",
    "\n",
    "**Example:** \"You are a senior software engineer conducting a code review. Analyze the provided code and identify potential issues.\"\n",
    "\n",
    "### **2. Context**\n",
    "This is external information to guide the model.\n",
    "\n",
    "**Example:** \"Code context: This is a utility function for user registration in a web application.\"\n",
    "\n",
    "### **3. Input Data**\n",
    "This is the input for which you want a response.\n",
    "\n",
    "**Example:** \"Code to review: `def register_user(email, password): ...`\"\n",
    "\n",
    "### **4. Output Indicator**\n",
    "This is the output type or format.\n",
    "\n",
    "**Example:** \"Please provide your response in this format: 1) Security Issues, 2) Code Quality Issues, 3) Recommended Improvements, 4) Overall Assessment\"\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Evaluate and Iterate\n",
    "\n",
    "**Review model responses** to ensure prompts elicit appropriate quality, type, and range of responses. Make changes as needed.\n",
    "\n",
    "**Pro tip:** Ask one copy of the model to improve or check output from another copy.\n",
    "\n",
    "**Remember:** Prompt engineering is an iterative skill that improves with practice. Experimentation builds intuition for crafting optimal prompts.\n",
    "\n",
    "### üéØ Key Benefits of Effective Prompting\n",
    "\n",
    "Effective prompt techniques can help you accomplish the following benefits:\n",
    "\n",
    "- **üöÄ Boost a model's abilities and improve safety**  \n",
    "  Well-crafted prompts guide models toward more accurate and appropriate responses\n",
    "\n",
    "- **üß† Augment the model with domain knowledge and external tools**  \n",
    "  Without changing model parameters or fine-tuning\n",
    "\n",
    "- **üí° Interact with language models to grasp their full capabilities**  \n",
    "  Unlock advanced reasoning and problem-solving abilities\n",
    "\n",
    "- **üìà Achieve better quality outputs through better quality inputs**  \n",
    "  The precision of your prompts directly impacts the quality of results\n",
    "\n",
    "**Real Impact:** Transform AI from a \"helpful chatbot\" into a reliable development partner that understands your specific coding context and delivers consistent, actionable results.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started: Setup and Practice\n",
    "\n",
    "Now that you understand why prompt engineering matters and what makes it effective, let's set up your development environment and start building! You'll create your first AI-powered code review assistant that demonstrates all the concepts we've covered.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö How This Notebook Works\n",
    "\n",
    "<div style=\"margin-top:16px; color:#991b1b; padding:12px; background:#fee2e2; border-radius:6px; border-left:4px solid #ef4444;\">\n",
    "<strong>‚ö†Ô∏è Important:</strong> <br><br>\n",
    "This notebook cannot be executed directly from GitHub. You must clone the repository and run it locally in your IDE.<br>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-top:16px; color:#1e3a8a; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6\">\n",
    "<strong>üÜï First time using Jupyter notebooks?</strong><br><br>\n",
    "See the <strong><a href=\"../../README.md#-about-jupyter-notebooks\">About Jupyter Notebooks</a></strong> section in the main README for a complete guide on how notebooks work, where code executes, and how to get started.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick start:**\n",
    "- Press `Shift + Enter` to run each cell\n",
    "- Run cells sequentially from top to bottom\n",
    "- Output appears below each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "Let's start by installing the packages we need for this tutorial.\n",
    "\n",
    "Run the cell below. You should see a success message when installation completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_requirements():\n",
    "    try:\n",
    "        # Install from requirements.txt\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"])\n",
    "        print(\"‚úÖ SUCCESS! All dependencies installed successfully.\")\n",
    "        print(\"üì¶ Installed: openai, anthropic, python-dotenv, requests\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Installation failed: {e}\")\n",
    "        print(\"üí° Try running: pip install openai anthropic python-dotenv requests\")\n",
    "\n",
    "install_requirements()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Success!** Dependencies installed on your local machine. Now let's connect to an AI model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Connect to AI Model\n",
    "\n",
    "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
    "<strong>üí° Note:</strong> <br><br>\n",
    "The code below runs on your local machine and connects to AI services over the internet.\n",
    "</div>\n",
    "\n",
    "Choose your preferred option below. Each option has detailed setup instructions in its own section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: GitHub Copilot (Recommended)\n",
    "\n",
    "**Best for:** Users with GitHub Copilot subscription (no additional API keys needed)\n",
    "\n",
    "**Supports:** Both Claude and OpenAI models\n",
    "\n",
    "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
    "<strong>üí° Note:</strong> <br><br>\n",
    "The GitHub Copilot API repository (<code style=\"background:#f3f4f6; padding:2px 6px; border-radius:3px; color:#dc2626;\">copilot-api</code>) used in this course is a fork of the original repository from: <br><br><strong><a href=\"https://cto-github.cisco.com/xinyu3/copilot2api\">https://cto-github.cisco.com/xinyu3/copilot2api</a></strong>\n",
    "</div>\n",
    "\n",
    "- Follow the setup steps in [https://github.com/snehangshu-splunk/copilot-api/blob/main/.github/README.md](https://github.com/snehangshu-splunk/copilot-api/blob/main/.github/README.md) to:\n",
    "  - Authenticate (`auth`) with your GitHub account that has Copilot access\n",
    "  - Start the local server (default: `http://localhost:7711`)\n",
    "- Then run the \"GitHub Copilot API setup (local proxy)\" cells below.\n",
    "\n",
    "Quick reference (see [README](../../GitHub-Copilot-2-API/README.md) for details):\n",
    "\n",
    "1. **Download and install dependencies**\n",
    "    ```bash\n",
    "    # Clone the repository\n",
    "    git clone https://github.com/snehangshu-splunk/copilot-api.git\n",
    "    cd copilot-api\n",
    "\n",
    "    # Install dependencies with pip (recommended)\n",
    "    pip install -e .\n",
    "    \n",
    "    # Alternative: Using uv (faster package manager)\n",
    "    # uv sync\n",
    "    ```\n",
    "\n",
    "2. **Authenticate with GitHub**\n",
    "    ```bash\n",
    "    # For business account (using pip installation)\n",
    "    copilot2api auth --business\n",
    "    \n",
    "    # Alternative: If you installed with uv\n",
    "    # uv run copilot2api auth --business\n",
    "    ```\n",
    "    \n",
    "    When authenticating for the first time, you will see the following information:\n",
    "    ```\n",
    "    Press Ctrl+C to stop the server\n",
    "    Starting Copilot API server...\n",
    "    Starting GitHub device authorization flow...\n",
    "\n",
    "    Please enter the code '14B4-5D82' at:\n",
    "    https://github.com/login/device\n",
    "\n",
    "    Waiting for authorization...\n",
    "    ```\n",
    "    You need to copy `https://github.com/login/device` to your browser, then log in to your GitHub account through the browser. This GitHub account should have GitHub Copilot functionality. After authentication is complete, copy '14B4-5D82' in the browser prompt box. This string of numbers is system-generated and may be different each time.\n",
    "\n",
    "    > **Don't copy the code here.** If you copy this, it will only cause your authorization to fail.\n",
    "\n",
    "    After successful device authorization:\n",
    "    - macOS or Linux: In the `$HOME/.config/copilot2api/` directory, you will see the github-token file.\n",
    "    - Windows: You will find the github-token file in the `C:\\Users\\<username>\\AppData\\Roaming\\copilot2api\\` directory.\n",
    "\n",
    "3. **Start the Server**\n",
    "    ```bash\n",
    "    # Start API server on default port 7711 (using pip installation)\n",
    "    copilot2api start\n",
    "    \n",
    "    # Alternative: If you installed with uv\n",
    "    # uv run copilot2api start\n",
    "    ```\n",
    "\n",
    "Now use the OpenAI libraries to connect to the LLM by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: GitHub Copilot API setup (Recommended)\n",
    "import openai\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# üéØ CHOOSE YOUR AI MODEL PROVIDER\n",
    "# ============================================\n",
    "# Set your preference: \"openai\" or \"claude\"\n",
    "PROVIDER = \"claude\"  # Change to \"claude\" to use Claude models\n",
    "\n",
    "# ============================================\n",
    "# üìã Available Models by Provider\n",
    "# ============================================\n",
    "# OpenAI Models (via GitHub Copilot):\n",
    "#   - gpt-4o (recommended, supports vision)\n",
    "#   - gpt-4\n",
    "#   - gpt-3.5-turbo\n",
    "#   - o3-mini, o4-mini\n",
    "#\n",
    "# Claude Models (via GitHub Copilot):\n",
    "#   - claude-3.5-sonnet (recommended, supports vision)\n",
    "#   - claude-3.7-sonnet (supports vision)\n",
    "#   - claude-sonnet-4 (supports vision)\n",
    "# ============================================\n",
    "\n",
    "# Configure clients for both providers\n",
    "openai_client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:7711/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "claude_client = anthropic.Anthropic(\n",
    "    api_key=\"dummy-key\",\n",
    "    base_url=\"http://localhost:7711\"\n",
    ")\n",
    "\n",
    "# Set default models for each provider\n",
    "OPENAI_DEFAULT_MODEL = \"gpt-4o\"\n",
    "CLAUDE_DEFAULT_MODEL = \"claude-3.5-sonnet\"\n",
    "\n",
    "\n",
    "def _extract_text_from_blocks(blocks):\n",
    "    \"\"\"Extract text content from response blocks returned by the API.\"\"\"\n",
    "    parts = []\n",
    "    for block in blocks:\n",
    "        text_val = getattr(block, \"text\", None)\n",
    "        if isinstance(text_val, str):\n",
    "            parts.append(text_val)\n",
    "        elif isinstance(block, dict):\n",
    "            t = block.get(\"text\")\n",
    "            if isinstance(t, str):\n",
    "                parts.append(t)\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def get_openai_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"Get completion from OpenAI models via GitHub Copilot.\"\"\"\n",
    "    if model is None:\n",
    "        model = OPENAI_DEFAULT_MODEL\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\\nüí° Make sure GitHub Copilot proxy is running on port 7711\"\n",
    "\n",
    "\n",
    "def get_claude_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"Get completion from Claude models via GitHub Copilot.\"\"\"\n",
    "    if model is None:\n",
    "        model = CLAUDE_DEFAULT_MODEL\n",
    "    try:\n",
    "        response = claude_client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=8192,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return _extract_text_from_blocks(getattr(response, \"content\", []))\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\\nüí° Make sure GitHub Copilot proxy is running on port 7711\"\n",
    "\n",
    "\n",
    "def get_chat_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"\n",
    "    Generic function to get chat completion from any provider.\n",
    "    Routes to the appropriate provider-specific function based on PROVIDER setting.\n",
    "    \"\"\"\n",
    "    if PROVIDER.lower() == \"claude\":\n",
    "        return get_claude_completion(messages, model, temperature)\n",
    "    else:  # Default to OpenAI\n",
    "        return get_openai_completion(messages, model, temperature)\n",
    "\n",
    "\n",
    "def get_default_model():\n",
    "    \"\"\"Get the default model for the current provider.\"\"\"\n",
    "    if PROVIDER.lower() == \"claude\":\n",
    "        return CLAUDE_DEFAULT_MODEL\n",
    "    else:\n",
    "        return OPENAI_DEFAULT_MODEL\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# üß™ TEST CONNECTION\n",
    "# ============================================\n",
    "print(\"üîÑ Testing connection to GitHub Copilot proxy...\")\n",
    "test_result = get_chat_completion([\n",
    "    {\"role\": \"user\", \"content\": \"test\"}\n",
    "])\n",
    "\n",
    "if test_result and \"Error\" in test_result:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ùå CONNECTION FAILED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Provider: {PROVIDER.upper()}\")\n",
    "    print(f\"Expected endpoint: http://localhost:7711\")\n",
    "    print(\"\\n‚ö†Ô∏è  The GitHub Copilot proxy is NOT running!\")\n",
    "    print(\"\\nüìã To fix this:\")\n",
    "    print(\"   1. Open a new terminal\")\n",
    "    print(\"   2. Navigate to your copilot-api directory\")\n",
    "    print(\"   3. Run: uv run copilot2api start\")\n",
    "    print(\"   4. Wait for the server to start (you should see 'Server initialized')\")\n",
    "    print(\"   5. Come back and rerun this cell\")\n",
    "    print(\"\\nüí° Need setup help? See: GitHub-Copilot-2-API/README.md\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ CONNECTION SUCCESSFUL!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ü§ñ Provider: {PROVIDER.upper()}\")\n",
    "    print(f\"üì¶ Default Model: {get_default_model()}\")\n",
    "    print(f\"üîó Endpoint: http://localhost:7711\")\n",
    "    print(f\"\\nüí° To switch providers, change PROVIDER to '{'claude' if PROVIDER.lower() == 'openai' else 'openai'}' and rerun this cell\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Option B: OpenAI API\n",
    "\n",
    "**Best for:** Users with direct OpenAI API access\n",
    "\n",
    "**Setup:** Add your API key to `.env` file, then uncomment and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Direct OpenAI API setup\n",
    "# import openai\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# client = openai.OpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\")  # Set this in your .env file\n",
    "# )\n",
    "\n",
    "# def get_chat_completion(messages, model=\"gpt-4\", temperature=0.7):\n",
    "#     try:\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=model,\n",
    "#             messages=messages,\n",
    "#             temperature=temperature\n",
    "#         )\n",
    "#         return response.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         return f\"‚ùå Error: {e}\"\n",
    "\n",
    "# print(\"‚úÖ OpenAI API configured successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option C: CircuIT APIs\n",
    "\n",
    "**Best for:** Cisco employees with CircuIT API access\n",
    "\n",
    "**Setup:** Configure environment variables (`CISCO_CLIENT_ID`, `CISCO_CLIENT_SECRET`, `CISCO_OPENAI_APP_KEY`) in `.env` file.\n",
    "\n",
    "Get values from: https://ai-chat.cisco.com/bridgeit-platform/api/home\n",
    "\n",
    "Then uncomment and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import traceback\n",
    "# import requests\n",
    "# import base64\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from openai import AzureOpenAI\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# # Open AI version to use\n",
    "# openai.api_type = \"azure\"\n",
    "# openai.api_version = \"2024-12-01-preview\"\n",
    "\n",
    "# # Get API_KEY wrapped in token - using environment variables\n",
    "# client_id = os.getenv(\"CISCO_CLIENT_ID\")\n",
    "# client_secret = os.getenv(\"CISCO_CLIENT_SECRET\")\n",
    "\n",
    "# url = \"https://id.cisco.com/oauth2/default/v1/token\"\n",
    "\n",
    "# payload = \"grant_type=client_credentials\"\n",
    "# value = base64.b64encode(f\"{client_id}:{client_secret}\".encode(\"utf-8\")).decode(\"utf-8\")\n",
    "# headers = {\n",
    "#     \"Accept\": \"*/*\",\n",
    "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#     \"Authorization\": f\"Basic {value}\",\n",
    "# }\n",
    "\n",
    "# token_response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "# print(token_response.text)\n",
    "# token_data = token_response.json()\n",
    "\n",
    "# client = AzureOpenAI(\n",
    "#     azure_endpoint=\"https://chat-ai.cisco.com\",\n",
    "#     api_key=token_data.get(\"access_token\"),\n",
    "#     api_version=\"2024-12-01-preview\",\n",
    "# )\n",
    "\n",
    "# app_key = os.getenv(\"CISCO_OPENAI_APP_KEY\")\n",
    "\n",
    "# def get_chat_completion(messages, model=\"gpt-4o\", temperature=0.0):\n",
    "#     try:\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=model,\n",
    "#             messages=messages,\n",
    "#             temperature=temperature,\n",
    "#             user=f'{\"appkey\": \"{app_key}\"}',\n",
    "#         )\n",
    "#         return response.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         return f\"‚ùå Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test Connection\n",
    "\n",
    "Run the cell below to test your first prompt and verify everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the connection with a simple prompt\n",
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful coding assistant. Respond with exactly: 'Connection successful! Ready for prompt engineering.'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Test the connection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_chat_completion(test_messages)\n",
    "print(\"üß™ Test Response:\")\n",
    "print(response)\n",
    "\n",
    "if response and \"Connection successful\" in response:\n",
    "    print(\"\\nüéâ Perfect! Your AI connection is working!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Connection test complete, but response format may vary.\")\n",
    "    print(\"This is normal - let's continue with the tutorial!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ **Connection verified!** You're ready to learn prompt engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Craft Your First AI-Powered Code Review\n",
    "\n",
    "Time to put theory into practice! You'll engineer a prompt that transforms a generic AI into a specialized code review expert.\n",
    "\n",
    "Let's see the 4 core elements in action with a software engineering example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Code review prompt with all 4 elements\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            # 1. INSTRUCTIONS\n",
    "            \"You are a senior software engineer conducting a code review. \"\n",
    "            \"Analyze the provided code and identify potential issues.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "# 2. CONTEXT\n",
    "Code context: This is a utility function for user registration in a web application.\n",
    "\n",
    "# 3. INPUT DATA\n",
    "Code to review:\n",
    "```python\n",
    "def register_user(email, password):\n",
    "    if email and password:\n",
    "        user = {{\"email\": email, \"password\": password}}\n",
    "        return user\n",
    "    return None\n",
    "```\n",
    "\n",
    "# 4. OUTPUT FORMAT\n",
    "Please provide your response in this format:\n",
    "1. Security Issues (if any)\n",
    "2. Code Quality Issues (if any)  \n",
    "3. Recommended Improvements\n",
    "4. Overall Assessment\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_chat_completion(messages)\n",
    "print(\"üîç CODE REVIEW RESULT:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÄÔ∏è Hands-On Practice\n",
    "\n",
    "Now let's practice what you've learned! These exercises will help you master the 4 core elements of effective prompts.\n",
    "\n",
    "<div style=\"padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e; color:#14532d;\">\n",
    "<strong>‚≠ê How This Works</strong><br><br>\n",
    "Work through each activity independently. After completing your solution, compare it with the suggested approach in the solutions section below.\n",
    "</div>\n",
    "\n",
    "**In this section you will:**\n",
    "- Identify missing elements in incomplete prompts\n",
    "- Build complete prompts from scratch\n",
    "- Apply the 4 core elements to real coding scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### Activity 1.1: Analyze Prompts and Identify Missing Elements\n",
    "\n",
    "**Goal:** Identify which of the 4 core elements are missing from incomplete prompts.\n",
    "\n",
    "**Your Task:** For each prompt below, determine which elements (Instructions, Context, Input Data, Output Format) are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1\n",
    "prompt_1 = \"\"\"\n",
    "Fix this code:\n",
    "def calculate(x, y):\n",
    "    return x + y\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 2\n",
    "prompt_2 = \"\"\"\n",
    "You are a Python developer.\n",
    "Make this function better.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 3\n",
    "prompt_3 = \"\"\"\n",
    "Review the following function and provide feedback.\n",
    "Return your response as a list of improvements.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANALYSIS: Write your notes identifying which elements are missing\n",
    "# Prompt 1 missing: _______________\n",
    "# Prompt 2 missing: _______________\n",
    "# Prompt 3 missing: _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 1.2: Create a Complete Prompt with All 4 Elements\n",
    "\n",
    "**Goal:** Build a complete prompt that includes all 4 core elements to generate documentation for the function below.\n",
    "\n",
    "<div style=\"padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6; color:#1e40af;\">\n",
    "<strong>üìù Success Criteria:</strong><br><br>\n",
    "Your solution should have:\n",
    "<ul>\n",
    "<li>System message with clear instructions/role</li>\n",
    "<li>User message with context about the function</li>\n",
    "<li>The function code as input data</li>\n",
    "<li>A specified output format (e.g., Purpose, Parameters, Return Value, etc.)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_document = \"\"\"\n",
    "def process_transaction(user_id, amount, transaction_type):\n",
    "    if transaction_type not in ['deposit', 'withdrawal']:\n",
    "        raise ValueError(\"Invalid transaction type\")\n",
    "    \n",
    "    if amount <= 0:\n",
    "        raise ValueError(\"Amount must be positive\")\n",
    "    \n",
    "    balance = get_user_balance(user_id)\n",
    "    \n",
    "    if transaction_type == 'withdrawal' and balance < amount:\n",
    "        raise InsufficientFundsError(\"Insufficient funds\")\n",
    "    \n",
    "    new_balance = balance + amount if transaction_type == 'deposit' else balance - amount\n",
    "    update_user_balance(user_id, new_balance)\n",
    "    log_transaction(user_id, amount, transaction_type)\n",
    "    \n",
    "    return new_balance\n",
    "\"\"\"\n",
    "\n",
    "# YOUR SOLUTION: Build complete prompt with all 4 elements\n",
    "# TODO: Uncomment and complete\n",
    "\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": \"...\"  # Instructions: Define AI's role and task\n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": f\"\"\"\n",
    "# Context: ...\n",
    "#\n",
    "# Function to document:\n",
    "# {function_to_document}\n",
    "#\n",
    "# Output format:\n",
    "# 1. ...\n",
    "# 2. ...\n",
    "# \"\"\"\n",
    "#     }\n",
    "# ]\n",
    "#\n",
    "# response = get_chat_completion(messages)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Activity Solutions\n",
    "\n",
    "<div style=\"padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b; color:#78350f;\">\n",
    "<strong>üí° Try the exercises first!</strong><br><br>\n",
    "Complete Activities 1.1 and 1.2 before reviewing the solutions below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üìã Click to reveal Activity Solutions</strong></summary>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Activity 1.1 Solution\n",
    "\n",
    "**Prompt 1 Analysis:**\n",
    "```\n",
    "\"Fix this code: def calculate(x, y): return x + y\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- ‚ùå **Instructions/Role** - No clear task or role definition\n",
    "- ‚ùå **Context** - What is this function supposed to do? What's wrong with it?\n",
    "- ‚ùå **Output Format** - No specification for how the fixed code should be presented\n",
    "- ‚úÖ **Input Data** - Has the code\n",
    "\n",
    "**Prompt 2 Analysis:**\n",
    "```\n",
    "\"You are a Python developer. Make this function better.\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- ‚úÖ **Instructions/Role** - Has a role (\"Python developer\")\n",
    "- ‚ùå **Context** - What function? What makes it need improvement?\n",
    "- ‚ùå **Input Data** - No function provided\n",
    "- ‚ùå **Output Format** - \"Better\" is vague\n",
    "\n",
    "**Prompt 3 Analysis:**\n",
    "```\n",
    "\"Review the following function and provide feedback. Return your response as a list of improvements.\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- ‚ùå **Instructions/Role** - No clear role definition (who should review it?)\n",
    "- ‚ùå **Context** - What's the function's purpose? What domain?\n",
    "- ‚ùå **Input Data** - Says \"following function\" but none is provided\n",
    "- ‚úÖ **Output Format** - Has format (\"list of improvements\")\n",
    "\n",
    "---\n",
    "\n",
    "### Activity 1.2 Solution\n",
    "\n",
    "Here's a complete prompt with all 4 elements:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a senior software engineer creating technical documentation. Write clear, comprehensive documentation for Python functions.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Context: This is a financial transaction processing function for a banking application. It handles deposits and withdrawals with validation and error handling.\n",
    "\n",
    "Function to document:\n",
    "{function_to_document}\n",
    "\n",
    "Please provide documentation in this format:\n",
    "1. Function Purpose\n",
    "2. Parameters (name, type, description for each)\n",
    "3. Return Value\n",
    "4. Exceptions/Error Conditions\n",
    "5. Usage Example\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**Why this works:**\n",
    "- ‚úÖ **Instructions** - \"senior software engineer creating technical documentation\"\n",
    "- ‚úÖ **Context** - \"financial transaction processing function for a banking application\"\n",
    "- ‚úÖ **Input Data** - The complete function code\n",
    "- ‚úÖ **Output Format** - Numbered list with specific sections\n",
    "\n",
    "**Key takeaway:** Each element serves a specific purpose in guiding the AI toward the desired output!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:16px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:10px; color:#fff; text-align:center; box-shadow:0 4px 15px rgba(102,126,234,0.3);\">\n",
    "  <strong style=\"font-size:1.05em;\">üéâ Excellent work completing the hands-on activities!</strong><br>\n",
    "  <span style=\"font-size:0.92em; opacity:0.95; margin-top:4px; display:block;\">You've practiced identifying missing elements and building complete prompts.</span>\n",
    "</div>\n",
    "\n",
    "**You've now completed:**\n",
    "- ‚úÖ Analyzed incomplete prompts to identify missing elements\n",
    "- ‚úÖ Created complete prompts with all 4 core elements\n",
    "- ‚úÖ Applied prompt engineering to real coding scenarios\n",
    "\n",
    "üí° **What makes effective prompts work?**\n",
    "- **Clear role definition** guides the AI's perspective and expertise\n",
    "- **Specific context** provides domain knowledge the AI needs\n",
    "- **Concrete input** gives the AI something tangible to work with\n",
    "- **Structured output format** ensures consistent, actionable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Module 1 Complete\n",
    "\n",
    "<div style=\"padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e; color:#14532d;\">\n",
    "<strong>‚úÖ Progress Check</strong><br><br>\n",
    "You've learned the foundations of prompt engineering and practiced applying the 4 core elements to real coding scenarios.\n",
    "</div>\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "- ‚úÖ Set up Python environment with AI model access\n",
    "- ‚úÖ Executed your first structured prompt\n",
    "- ‚úÖ Learned the 4 core elements of effective prompts\n",
    "- ‚úÖ Conducted your first AI-powered code review\n",
    "- ‚úÖ Analyzed incomplete prompts to identify missing elements\n",
    "- ‚úÖ Created complete prompts with all 4 core elements\n",
    "\n",
    "### The 4 Core Elements\n",
    "\n",
    "1. **Instructions** ‚Äî Define the AI's role and task\n",
    "2. **Context** ‚Äî Provide background information\n",
    "3. **Input Data** ‚Äî Give specific content to work with\n",
    "4. **Output Format** ‚Äî Specify structure of results\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"padding:20px 24px; background:linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius:12px; border-left:5px solid #3b82f6; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n",
    "  <div style=\"color:#1e293b; font-size:0.85em; font-weight:600; text-transform:uppercase; letter-spacing:1px; margin-bottom:8px;\">‚è≠Ô∏è Next Steps</div>\n",
    "  <div style=\"color:#0f172a; font-size:1.15em; font-weight:700; margin-bottom:6px;\">Module 2: Core Prompt Engineering Techniques</div>\n",
    "  <div style=\"color:#475569; font-size:0.95em; line-height:1.5; margin-bottom:12px;\">Master 8 powerful tactics used by professional developers to get consistently excellent results from AI assistants.</div>\n",
    "  <div style=\"color:#475569; font-size:0.9em; line-height:1.6; margin-bottom:14px;\">\n",
    "    <strong>You'll learn:</strong><br>\n",
    "    ‚Ä¢ Role prompting to transform AI into specialized experts<br>\n",
    "    ‚Ä¢ XML delimiters to organize complex inputs<br>\n",
    "    ‚Ä¢ Few-shot examples to teach AI your style<br>\n",
    "    ‚Ä¢ Chain-of-thought reasoning for systematic analysis<br>\n",
    "    ‚Ä¢ Prompt chaining to break complex tasks into steps<br>\n",
    "    ‚Ä¢ LLM-as-Judge for automated evaluation<br>\n",
    "    ‚Ä¢ Inner monologue to separate reasoning from output\n",
    "  </div>\n",
    "  <a href=\"../module-02-fundamentals/README.md\" style=\"display:inline-block; padding:8px 16px; background:#3b82f6; color:#fff; text-decoration:none; border-radius:6px; font-weight:600; font-size:0.9em; transition:all 0.2s;\">Continue to Module 2 ‚Üí</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
