{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 3 - Apply Advanced Prompting Engineering Tactics to SDLC\n",
        "\n",
        "| **Aspect** | **Details** |\n",
        "|-------------|-------------|\n",
        "| **Goal** | Blend previously mastered strategiesâ€”task decomposition, role prompting, chain-of-thought reasoning, LLM-as-Judge critique, and structured formattingâ€”to design reliable prompts for code review and software development lifecycle (SDLC) activities |\n",
        "| **Time** | ~120-150 minutes (2-2.5 hours) |\n",
        "| **Prerequisites** | Module 2 completion, Python 3.8+, IDE with notebook support, API access (GitHub Copilot, CircuIT, or OpenAI) |\n",
        "| **Setup Required** | Clone the repository and follow [Quick Setup](../../README.md#-quick-setup) before running this notebook |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ Ready to Start?\n",
        "\n",
        "<div style=\"margin-top:16px; color:#991b1b; padding:12px; background:#fee2e2; border-radius:6px; border-left:4px solid #ef4444;\">\n",
        "<strong>âš ï¸ Important:</strong> <br><br>\n",
        "This module builds directly on Module 2 techniques. Make sure you've completed Module 2 before starting.<br>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Setup: Environment Configuration\n",
        "\n",
        "### Step 1: Install Required Dependencies\n",
        "\n",
        "Let's start by installing the packages we need for this tutorial.\n",
        "\n",
        "Run the cell below. You should see a success message when installation completes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for Module 3\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    try:\n",
        "        # Install from requirements.txt\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"])\n",
        "        print(\"âœ… SUCCESS! Module 3 dependencies installed successfully.\")\n",
        "        print(\"ğŸ“¦ Ready for: openai, anthropic, python-dotenv, requests\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ Installation failed: {e}\")\n",
        "        print(\"ğŸ’¡ Try running: pip install openai anthropic python-dotenv requests\")\n",
        "\n",
        "install_requirements()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Connect to AI Model\n",
        "\n",
        "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
        "<strong>ğŸ’¡ Note:</strong> <br><br>\n",
        "The code below runs on your local machine and connects to AI services over the internet.\n",
        "</div>\n",
        "\n",
        "Choose your preferred option:\n",
        "\n",
        "- **Option A: GitHub Copilot API (local proxy)** â­ **Recommended**: \n",
        "  - Supports both **Claude** and **OpenAI** models\n",
        "  - No API keys needed - uses your GitHub Copilot subscription\n",
        "  - Follow [GitHub-Copilot-2-API/README.md](../../GitHub-Copilot-2-API/README.md) to authenticate and start the local server\n",
        "  - Run the setup cell below and **edit your preferred provider** (`\"openai\"` or `\"claude\"`) by setting the `PROVIDER` variable\n",
        "  - Available models:\n",
        "    - **OpenAI**: gpt-4o, gpt-4, gpt-3.5-turbo, o3-mini, o4-mini\n",
        "    - **Claude**: claude-3.5-sonnet, claude-3.7-sonnet, claude-sonnet-4\n",
        "\n",
        "- **Option B: OpenAI API**: If you have OpenAI API access, uncomment and run the **Option B** cell below.\n",
        "\n",
        "- **Option C: CircuIT APIs (Azure OpenAI)**: If you have CircuIT API access, uncomment and run the **Option C** cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: GitHub Copilot API setup (Recommended)\n",
        "import openai\n",
        "import anthropic\n",
        "import os\n",
        "\n",
        "# ============================================\n",
        "# ğŸ¯ CHOOSE YOUR AI MODEL PROVIDER\n",
        "# ============================================\n",
        "# Set your preference: \"openai\" or \"claude\"\n",
        "PROVIDER = \"claude\"  # Change to \"claude\" to use Claude models\n",
        "\n",
        "# ============================================\n",
        "# ğŸ“‹ Available Models by Provider\n",
        "# ============================================\n",
        "# OpenAI Models (via GitHub Copilot):\n",
        "#   - gpt-4o (recommended, supports vision)\n",
        "#   - gpt-4\n",
        "#   - gpt-3.5-turbo\n",
        "#   - o3-mini, o4-mini\n",
        "#\n",
        "# Claude Models (via GitHub Copilot):\n",
        "#   - claude-3.5-sonnet (recommended, supports vision)\n",
        "#   - claude-3.7-sonnet (supports vision)\n",
        "#   - claude-sonnet-4 (supports vision)\n",
        "# ============================================\n",
        "\n",
        "# Configure clients for both providers\n",
        "openai_client = openai.OpenAI(\n",
        "    base_url=\"http://localhost:7711/v1\",\n",
        "    api_key=\"dummy-key\"\n",
        ")\n",
        "\n",
        "claude_client = anthropic.Anthropic(\n",
        "    api_key=\"dummy-key\",\n",
        "    base_url=\"http://localhost:7711\"\n",
        ")\n",
        "\n",
        "# Set default models for each provider\n",
        "OPENAI_DEFAULT_MODEL = \"gpt-5\"\n",
        "CLAUDE_DEFAULT_MODEL = \"claude-sonnet-4\"\n",
        "\n",
        "\n",
        "def _extract_text_from_blocks(blocks):\n",
        "    \"\"\"Extract text content from response blocks returned by the API.\"\"\"\n",
        "    parts = []\n",
        "    for block in blocks:\n",
        "        text_val = getattr(block, \"text\", None)\n",
        "        if isinstance(text_val, str):\n",
        "            parts.append(text_val)\n",
        "        elif isinstance(block, dict):\n",
        "            t = block.get(\"text\")\n",
        "            if isinstance(t, str):\n",
        "                parts.append(t)\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "\n",
        "def get_openai_completion(messages, model=None, temperature=0.0):\n",
        "    \"\"\"Get completion from OpenAI models via GitHub Copilot.\"\"\"\n",
        "    if model is None:\n",
        "        model = OPENAI_DEFAULT_MODEL\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {e}\\nğŸ’¡ Make sure GitHub Copilot proxy is running on port 7711\"\n",
        "\n",
        "\n",
        "def get_claude_completion(messages, model=None, temperature=0.0):\n",
        "    \"\"\"Get completion from Claude models via GitHub Copilot.\"\"\"\n",
        "    if model is None:\n",
        "        model = CLAUDE_DEFAULT_MODEL\n",
        "    try:\n",
        "        response = claude_client.messages.create(\n",
        "            model=model,\n",
        "            max_tokens=8192,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return _extract_text_from_blocks(getattr(response, \"content\", []))\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {e}\\nğŸ’¡ Make sure GitHub Copilot proxy is running on port 7711\"\n",
        "\n",
        "\n",
        "def get_chat_completion(messages, model=None, temperature=0.0):\n",
        "    \"\"\"\n",
        "    Generic function to get chat completion from any provider.\n",
        "    Routes to the appropriate provider-specific function based on PROVIDER setting.\n",
        "    \"\"\"\n",
        "    if PROVIDER.lower() == \"claude\":\n",
        "        return get_claude_completion(messages, model, temperature)\n",
        "    else:  # Default to OpenAI\n",
        "        return get_openai_completion(messages, model, temperature)\n",
        "\n",
        "\n",
        "def get_default_model():\n",
        "    \"\"\"Get the default model for the current provider.\"\"\"\n",
        "    if PROVIDER.lower() == \"claude\":\n",
        "        return CLAUDE_DEFAULT_MODEL\n",
        "    else:\n",
        "        return OPENAI_DEFAULT_MODEL\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ğŸ§ª TEST CONNECTION\n",
        "# ============================================\n",
        "print(\"ğŸ”„ Testing connection to GitHub Copilot proxy...\")\n",
        "test_result = get_chat_completion([\n",
        "    {\"role\": \"user\", \"content\": \"Say 'Connection successful!' if you can read this.\"}\n",
        "])\n",
        "\n",
        "if test_result and (\"successful\" in test_result.lower() or \"success\" in test_result.lower()):\n",
        "    print(f\"âœ… Connection successful! Using {PROVIDER.upper()} provider with model: {get_default_model()}\")\n",
        "    print(f\"ğŸ“ Response: {test_result}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Connection test completed but response unexpected:\")\n",
        "    print(f\"ğŸ“ Response: {test_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Applying Prompt Engineering to SDLC Tasks\n",
        "\n",
        "---\n",
        "\n",
        "### Introduction: From Tactics to Real-World Applications\n",
        "\n",
        "#### ğŸš€ Ready to Transform Your Development Workflow?\n",
        "\n",
        "You've successfully mastered the core tactics in Module 2. Now comes the exciting part - **applying these techniques to real-world software engineering challenges** that you face every day.\n",
        "\n",
        "Think of what you've accomplished so far as **learning individual martial arts moves**. Now we're going to **choreograph them into powerful combinations** that solve actual development problems.\n",
        "\n",
        "\n",
        "#### ğŸ‘¨â€ğŸ’» What You're About to Master\n",
        "\n",
        "In the next sections, you'll discover **how to combine tactics strategically** to build production-ready prompts for critical SDLC tasks:\n",
        "\n",
        "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 16px; margin: 20px 0;\">\n",
        "\n",
        "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
        "<strong>ğŸ” Code Review Automation</strong><br>\n",
        "<em>Comprehensive review prompts with structured feedback</em>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
        "<strong>ğŸ§ª Test Generation & QA</strong><br>\n",
        "<em>Smart test plans with coverage gap analysis</em>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
        "<strong>âš–ï¸ Quality Validation</strong><br>\n",
        "<em>LLM-as-Judge rubrics for output verification</em>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
        "<strong>ğŸ“‹ Reusable Templates</strong><br>\n",
        "<em>Parameterized prompts for CI/CD integration</em>\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top:16px; color:#15803d; padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e;\">\n",
        "<strong>ğŸ’¡ Pro Tip:</strong> <br><br>\n",
        "This module covers practical applications over 120-150 minutes. <strong>Take short breaks</strong> between sections to reflect on how each template applies to your projects. <strong>Make notes</strong> as you progressâ€”jot down specific use cases from your codebase. The key skill is learning <strong>which tactic combinations solve which problems</strong>!\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“ How to Use Break Points\n",
        "\n",
        "<div style=\"background:#f0f9ff; border-left:4px solid #3b82f6; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#1e40af;\">ğŸ’¡ Taking Breaks? We've Got You Covered!</strong><br><br>\n",
        "\n",
        "This module is designed for 120-150 minutes of focused learning. To help you manage your time effectively, we've added **4 strategic break points** throughout:\n",
        "\n",
        "<table style=\"width:100%; margin:10px 0; border-collapse: collapse;\">\n",
        "  <tr style=\"background:#dbeafe;\">\n",
        "    <th style=\"padding:8px; text-align:left; border:1px solid #93c5fd;\">Break Point</th>\n",
        "    <th style=\"padding:8px; text-align:left; border:1px solid #93c5fd;\">Location</th>\n",
        "    <th style=\"padding:8px; text-align:left; border:1px solid #93c5fd;\">Time Elapsed</th>\n",
        "    <th style=\"padding:8px; text-align:left; border:1px solid #93c5fd;\">Bookmark Text</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">â˜• Break #1</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">After Section 1</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">~40 min</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">\"Section 2: Test Case Generation Template\"</td>\n",
        "  </tr>\n",
        "  <tr style=\"background:#eff6ff;\">\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">ğŸµ Break #2</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">After Section 2</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">~75 min</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">\"Section 3: LLM-as-Judge Evaluation Rubric\"</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">ğŸ§ƒ Break #3</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">After Section 3</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">~105 min</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">\"Hands-On Practice Activities\"</td>\n",
        "  </tr>\n",
        "  <tr style=\"background:#eff6ff;\">\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">ğŸ¯ Break #4</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">After Practice Activities</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">~145 min</td>\n",
        "    <td style=\"padding:8px; border:1px solid #93c5fd;\">\"Section 4: Template Best Practices\"</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "**How to Resume Your Session:**\n",
        "1. Scroll down to find the colorful break point card you last saw\n",
        "2. Look for the **\"ğŸ“Œ BOOKMARK TO RESUME\"** section\n",
        "3. Use `Ctrl+F` (or `Cmd+F` on Mac) to search for the bookmark text\n",
        "4. You'll jump right to where you left off!\n",
        "\n",
        "**Pro Tip:** Each break point card shows:\n",
        "- âœ… What you've completed\n",
        "- â­ï¸ What's coming next\n",
        "- â±ï¸ Estimated time for the next section\n",
        "\n",
        "Feel free to work at your own paceâ€”these are suggestions, not requirements! ğŸš€\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ¨ Technique Spotlight: Strategic Combinations\n",
        "\n",
        "Here's how Module 2 tactics combine to solve real SDLC challenges:\n",
        "\n",
        "| **Technique** | **Purpose in SDLC Context** | **Prompting Tip** |\n",
        "|---------------|----------------------------|-------------------|\n",
        "| **Task Decomposition** | Break multifaceted engineering tasks (e.g., review + test suggestions) into manageable parts | Structure prompt into numbered steps or XML blocks (e.g., `<review>`, `<tests>`) |\n",
        "| **Role Prompting** | Align the model's persona with engineering expectations (e.g., \"Senior Backend Engineer\") | Specify domain, experience level, and evaluation criteria |\n",
        "| **Chain-of-Thought** | Ensure reasoning is visible, aiding traceability and auditing | Request structured reasoning before conclusions, optionally hidden using \"inner monologue\" tags |\n",
        "| **LLM-as-Judge** | Evaluate code changes or generated artifacts against standards | Provide rubric with weighted criteria and evidence requirement |\n",
        "| **Few-Shot Examples** | Instill preferred review tone, severity labels, or test formats | Include short exemplars with both input (`<diff>`, `<tests>`) and expected reasoning |\n",
        "| **Prompt Templates** | Reduce prompt drift across teams and tools | Parameterize sections (`{{code_diff}}`, `{{requirements}}`) for consistent reuse |\n",
        "\n",
        "#### ğŸ”— The Power of Strategic Combinations\n",
        "\n",
        "The real skill isn't using tactics in isolationâ€”it's knowing **which combinations solve which problems**. Each section demonstrates a different combination pattern optimized for specific SDLC challenges.\n",
        "\n",
        "Ready to build production-ready solutions? Let's dive in! ğŸ‘‡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” Section 1: Code Review Automation Template\n",
        "\n",
        "### Building a Comprehensive Code Review Prompt with Multi-Tactic Combination\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#92400e;\">ğŸ¯ What You'll Build in This Section</strong><br><br>\n",
        "\n",
        "You'll create a **production-ready code review prompt template** that automatically analyzes code changes with the rigor of a senior engineer. This isn't just about finding bugs but rather you're building a system that provides consistent, traceable, and actionable feedback.\n",
        "\n",
        "**Time Required:** ~40 minutes (includes building, testing, and refining the template)\n",
        "</div>\n",
        "\n",
        "#### ğŸ“‹ Before You Start: What You'll Need\n",
        "\n",
        "To get the most from this section, have ready:\n",
        "\n",
        "1. **A code diff to review** (options):\n",
        "   - A recent pull request from your repository\n",
        "   - Sample code provided in the activities below\n",
        "   - Any Python, JavaScript, or Java code change you want analyzed\n",
        "\n",
        "2. **Clear review criteria** for your domain:\n",
        "   - What counts as a \"blocker\" vs \"minor\" issue in your team?\n",
        "   - Which security patterns should be enforced?\n",
        "   - What performance thresholds matter for your application?\n",
        "\n",
        "3. **Your API connection** set up and tested (from the setup section above)\n",
        "\n",
        "<div style=\"background:#dbeafe; border-left:4px solid #3b82f6; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#1e40af;\">ğŸ’¡ Why This Approach Works with Modern LLMs</strong><br><br>\n",
        "\n",
        "This template follows industry best practices for prompt engineering with advanced language models. According to [Claude 4 prompt engineering best practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices), modern LLMs excel when you:\n",
        "\n",
        "- **Be explicit about expectations** - We'll define exactly what constitutes each severity level\n",
        "- **Provide context for behavior** - Explain *why* certain patterns are problematic (e.g., \"SQL injection vulnerabilities allow attackers to access sensitive data\")\n",
        "- **Use structured formats** - XML tags help models maintain focus across complex multi-step analyses\n",
        "- **Encourage visible reasoning** - Chain-of-thought reveals the \"why\" behind each finding, making reviews auditable\n",
        "\n",
        "These aren't arbitrary choicesâ€”they directly address how advanced language models process instructions most effectively, ensuring consistent results across different AI providers.\n",
        "</div>\n",
        "\n",
        "#### ğŸ¯ The Problem We're Solving\n",
        "\n",
        "Manual code reviews face three critical challenges:\n",
        "\n",
        "1. **â° Time Bottlenecks** \n",
        "   - Senior engineers spend 8-12 hours/week reviewing PRs\n",
        "   - Review queues delay feature delivery by 2-3 days on average\n",
        "   - **Impact:** Slower velocity, frustrated developers\n",
        "\n",
        "2. **ğŸ¯ Inconsistent Standards**\n",
        "   - Different reviewers prioritize different concerns\n",
        "   - New team members lack institutional knowledge\n",
        "   - Review quality varies based on reviewer fatigue\n",
        "   - **Impact:** Technical debt accumulates, security gaps emerge\n",
        "\n",
        "3. **ğŸ“ Lost Knowledge**\n",
        "   - Review reasoning buried in PR comments\n",
        "   - No searchable audit trail for security decisions\n",
        "   - Hard to train junior developers on review standards\n",
        "   - **Impact:** Repeated mistakes, difficult compliance auditing\n",
        "\n",
        "#### âœ¨ Understanding Prompt Templates\n",
        "\n",
        "According to [prompt templating best practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables), effective prompts separate **fixed content** (static instructions) from **variable content** (dynamic inputs). This separation enables:\n",
        "\n",
        "**Key Benefits:**\n",
        "- **Consistency** - Same review standards applied every time\n",
        "- **Efficiency** - Swap inputs without rewriting instructions\n",
        "- **Testability** - Quickly test different code diffs\n",
        "- **Scalability** - Manage complexity as your application grows\n",
        "- **Version Control** - Track changes to prompt logic separately from data\n",
        "\n",
        "**How to Templatize:**\n",
        "1. **Identify fixed content** - Instructions that never change (e.g., \"Act as a Senior Backend Engineer\")\n",
        "2. **Identify variable content** - Dynamic data that changes per request (e.g., code diffs, repository names)\n",
        "3. **Use placeholders** - Mark variables with `{{double_brackets}}` for easy identification\n",
        "4. **Separate concerns** - Keep prompt logic in templates, data in variables\n",
        "\n",
        "**Example:**\n",
        "```\n",
        "Fixed: \"Review this code for security issues\"\n",
        "Variable: {{code_diff}} â† Changes with each API call\n",
        "Template: \"Review this code for security issues: {{code_diff}}\"\n",
        "```\n",
        "\n",
        "#### ğŸ—ï¸ How We'll Build It: The Tactical Combination\n",
        "\n",
        "This template strategically combines five Module 2 tactics:\n",
        "\n",
        "| **Tactic** | **Purpose in This Template** | **Why Modern LLMs Need This** |\n",
        "|------------|------------------------------|-------------------------------|\n",
        "| **Role Prompting** | Establishes \"Senior Backend Engineer\" perspective with specific expertise | LLMs respond better when given explicit expertise context rather than assuming generic knowledge |\n",
        "| **Structured Inputs (XML)** | Separates code, context, and guidelines into clear sections | Prevents models from mixing different information types during analysis |\n",
        "| **Task Decomposition** | Breaks review into 4 sequential steps (Think â†’ Assess â†’ Suggest â†’ Verdict) | Advanced LLMs excel at following explicit numbered steps rather than implicit workflows |\n",
        "| **Chain-of-Thought** | Makes reasoning visible in Analysis section | Improves accuracy by forcing deliberate analysis before conclusions |\n",
        "| **Structured Output** | Uses readable markdown format with severity levels | Enables human readability while maintaining parseable structure for automation |\n",
        "\n",
        "<div style=\"background:#dcfce7; border-left:4px solid #22c55e; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#166534;\">ğŸš€ Let's Build It!</strong><br><br>\n",
        "\n",
        "In the next cell, you'll see the complete template structure. **Pay special attention to**:\n",
        "- How we use explicit language to define severity levels (not \"bad code\" but \"allows SQL injection\")\n",
        "- Why the markdown output format is more readable than XML while still being parseable\n",
        "- How parameters like `{{tech_stack}}` and `{{change_purpose}}` make the template reusable across projects\n",
        "- How the 6 review dimensions (Security, Performance, Error Handling, etc.) ensure comprehensive analysis\n",
        "\n",
        "After reviewing the template, you'll test it on real code and see how each tactic contributes to the result.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“‹ Template Structure\n",
        "\n",
        "```xml\n",
        "<role>\n",
        "Act as a Senior Backend Engineer specializing in {{tech_stack}}.\n",
        "</role>\n",
        "\n",
        "<context>\n",
        "Repository: {{repo_name}}\n",
        "Service: {{service_name}}\n",
        "Purpose: {{change_purpose}}\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{{code_diff}}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "Evaluate the code across these critical dimensions:\n",
        "\n",
        "1. **Security**: Check for vulnerabilities (SQL injection, XSS, insecure dependencies, exposed secrets)\n",
        "2. **Performance**: Identify bottlenecks (N+1 queries, memory leaks, inefficient algorithms)\n",
        "3. **Error Handling**: Validate proper exception handling and edge case coverage\n",
        "4. **Code Quality**: Assess readability, simplicity, and adherence to standards\n",
        "5. **Correctness**: Verify logic achieves intended functionality\n",
        "6. **Maintainability**: Check for unnecessary complexity or dependencies\n",
        "\n",
        "For each finding:\n",
        "- Cite exact lines using git diff markers\n",
        "- Explain why it's problematic (impact on users, security, or system)\n",
        "- If code is acceptable, confirm with specific justification\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Think: Analyze the code systematically using chain-of-thought reasoning in the Analysis section.\n",
        "         Consider:\n",
        "         â€¢ What could go wrong with this code?\n",
        "         â€¢ Are there security implications?\n",
        "         â€¢ How does this perform at scale?\n",
        "         â€¢ Are edge cases handled?\n",
        "\n",
        "Step 2 - Assess: For each issue identified, provide:\n",
        "  â€¢ Severity: \n",
        "    - BLOCKER: Security vulnerabilities, data loss risks, critical bugs\n",
        "    - MAJOR: Performance issues, poor error handling, significant technical debt\n",
        "    - MINOR: Code style inconsistencies, missing comments, small optimizations\n",
        "    - NIT: Formatting, naming conventions, trivial improvements\n",
        "  â€¢ Description: What is the issue and why it matters\n",
        "  â€¢ Evidence: Specific line numbers and code excerpts\n",
        "  â€¢ Impact: Potential consequences (security risk, performance degradation, etc.)\n",
        "\n",
        "Step 3 - Suggest: Provide actionable remediation:\n",
        "  â€¢ Specific code improvements or refactoring\n",
        "  â€¢ Alternative approaches to consider\n",
        "  â€¢ Questions for the author about design decisions\n",
        "\n",
        "Step 4 - Verdict: Conclude with clear decision:\n",
        "  â€¢ Pass/Fail/Needs Discussion\n",
        "  â€¢ Summary of key findings\n",
        "  â€¢ Required actions before merge\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "Provide your review in clear markdown format:\n",
        "\n",
        "## ğŸ§  Analysis\n",
        "[Your reasoning about potential issues - what patterns concern you?]\n",
        "\n",
        "## ğŸ” Findings\n",
        "\n",
        "### [SEVERITY] Issue Title\n",
        "**Lines:** [specific line numbers]\n",
        "**Problem:** [what's wrong and why it matters]\n",
        "**Impact:** [consequences - security risk, performance, etc.]\n",
        "**Fix:** [specific recommendation or code suggestion]\n",
        "\n",
        "[Repeat for each issue found]\n",
        "\n",
        "## âœ… Verdict\n",
        "**Decision:** [PASS / FAIL / NEEDS_DISCUSSION]\n",
        "**Summary:** [Brief overview of review]\n",
        "**Required Actions:** [What must be done before merge]\n",
        "</output_format>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ¯ What Makes This Production-Ready?\n",
        "\n",
        "âœ… **Comprehensive Review Dimensions** - Covers Security, Performance, Error Handling, Code Quality, Correctness, and Maintainability (not just \"find bugs\")\n",
        "\n",
        "âœ… **Clear Severity Definitions** - Explicit criteria for BLOCKER/MAJOR/MINOR/NIT classifications prevent ambiguity\n",
        "\n",
        "âœ… **Impact Analysis** - Every finding explains *why* it matters (security risk, performance degradation, maintainability issues)\n",
        "\n",
        "âœ… **Actionable Guidance** - Prompts for specific code improvements, not vague suggestions\n",
        "\n",
        "âœ… **Decision Framework** - Pass/Fail/Needs Discussion verdict with required actions before merge\n",
        "\n",
        "âœ… **Readable Output Format** - Uses clean markdown instead of verbose XML for better human readability and easier integration with PR tools\n",
        "\n",
        "These additions ensure reviews are consistent, auditable, and aligned with production quality standards.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’» Working Example: Reviewing a Security Vulnerability\n",
        "\n",
        "Let's apply our enhanced template to a real-world scenario - a code change that introduces a SQL injection vulnerability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Security-Focused Code Review with Enhanced Template\n",
        "code_diff = \"\"\"\n",
        "+ def get_user_by_email(email):\n",
        "+     query = f\"SELECT * FROM users WHERE email = '{email}'\"\n",
        "+     cursor.execute(query)\n",
        "+     return cursor.fetchone()\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Senior Security Engineer specializing in application security and OWASP Top 10 vulnerabilities.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: user-service-api\n",
        "Service: Authentication Service\n",
        "Purpose: Add email-based user lookup for login feature\n",
        "Security Context: This service handles sensitive user authentication data and is exposed to external API requests\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{code_diff}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "Evaluate the code with emphasis on security vulnerabilities, following [AWS security scanning best practices](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/security-scan.md):\n",
        "\n",
        "**Primary Focus - Security:**\n",
        "- OWASP Top 10 vulnerabilities (Injection, Authentication, XSS, etc.)\n",
        "- Input validation and sanitization\n",
        "- Authentication and authorization flaws\n",
        "- Sensitive data exposure\n",
        "- Known CVE/CWE patterns\n",
        "\n",
        "**Secondary Considerations:**\n",
        "- Performance implications of security fixes\n",
        "- Error handling (avoid information leakage)\n",
        "- Code quality and maintainability\n",
        "- Correctness of implementation\n",
        "\n",
        "For each security finding:\n",
        "- Identify the vulnerability type and CWE/CVE reference if applicable\n",
        "- Cite exact lines using git diff markers\n",
        "- Explain the attack vector and potential impact\n",
        "- Provide secure coding remediation with examples\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Security Analysis: Systematically analyze for vulnerabilities in the Analysis section.\n",
        "         Consider:\n",
        "         â€¢ What attack vectors exist in this code?\n",
        "         â€¢ Which OWASP Top 10 categories apply?\n",
        "         â€¢ What is the blast radius if exploited?\n",
        "         â€¢ Are there any CWE patterns present?\n",
        "\n",
        "Step 2 - Vulnerability Assessment: For each security issue, provide:\n",
        "  â€¢ Severity (Security-focused): \n",
        "    - CRITICAL: Remote code execution, authentication bypass, SQL injection allowing data exfiltration\n",
        "    - HIGH: Privilege escalation, XSS, insecure deserialization, significant data exposure\n",
        "    - MEDIUM: Information disclosure, missing security headers, weak encryption\n",
        "    - LOW: Security misconfigurations with limited impact, verbose error messages\n",
        "  â€¢ Vulnerability Type: (e.g., \"SQL Injection - CWE-89\")\n",
        "  â€¢ OWASP Category: (e.g., \"A03:2021 - Injection\")\n",
        "  â€¢ Evidence: Specific vulnerable code with line numbers\n",
        "  â€¢ Attack Scenario: How an attacker could exploit this\n",
        "  â€¢ Impact: Data breach potential, system compromise, compliance violations\n",
        "\n",
        "Step 3 - Security Remediation: Provide secure alternatives:\n",
        "  â€¢ Specific secure code implementation\n",
        "  â€¢ Reference to security libraries/frameworks (e.g., parameterized queries, ORM)\n",
        "  â€¢ Defense-in-depth recommendations\n",
        "  â€¢ Security testing suggestions\n",
        "\n",
        "Step 4 - Security Verdict: Conclude with risk assessment:\n",
        "  â€¢ Decision: BLOCK / FIX_REQUIRED / NEEDS_SECURITY_REVIEW / APPROVE_WITH_CONDITIONS\n",
        "  â€¢ Risk Summary: Overall security posture assessment\n",
        "  â€¢ Required Actions: Security fixes that must be implemented before deployment\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "Provide your security review in clear markdown format:\n",
        "\n",
        "## ğŸ”’ Security Analysis\n",
        "[Your reasoning about security vulnerabilities - what attack vectors exist?]\n",
        "\n",
        "## ğŸš¨ Security Findings\n",
        "\n",
        "### [SEVERITY] Vulnerability Type - CWE-XXX\n",
        "**Lines:** [specific line numbers]\n",
        "**OWASP Category:** [e.g., A03:2021 - Injection]\n",
        "**Vulnerability:** [description of the security flaw]\n",
        "**Attack Scenario:** [how an attacker exploits this]\n",
        "**Impact:** [data breach, system compromise, compliance violation]\n",
        "**Secure Fix:** [specific code solution with security best practices]\n",
        "\n",
        "[Repeat for each vulnerability found]\n",
        "\n",
        "## âœ… Security Verdict\n",
        "**Risk Level:** [CRITICAL / HIGH / MEDIUM / LOW]\n",
        "**Decision:** [BLOCK / FIX_REQUIRED / NEEDS_SECURITY_REVIEW / APPROVE_WITH_CONDITIONS]\n",
        "**Summary:** [Overall security assessment]\n",
        "**Required Security Actions:** [Must-fix items before deployment]\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ğŸ”’ SECURITY-FOCUSED CODE REVIEW IN PROGRESS...\")\n",
        "print(\"=\"*70)\n",
        "review_result = get_chat_completion(messages, temperature=0.0)\n",
        "print(review_result)\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ‹ï¸ Activity: Build Your Own Code Review Template\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#92400e;\">â±ï¸ Time Required: 35-50 minutes</strong><br>\n",
        "This is a hands-on research and build activity. You'll explore professional code review patterns and create your own template.\n",
        "</div>\n",
        "\n",
        "#### ğŸ“– What You'll Do\n",
        "\n",
        "This activity challenges you to **research, design, and build** a production-ready code review template by studying real-world patterns from AWS.\n",
        "\n",
        "#### ğŸ“‹ Instructions\n",
        "\n",
        "Follow the **3-step process** in the code cell below:\n",
        "\n",
        "1. **RESEARCH (10-15 min)** - Study the AWS code review pattern and identify key elements\n",
        "2. **DESIGN (10-15 min)** - Answer design questions to plan your template structure  \n",
        "3. **BUILD (15-20 min)** - Implement your template by adapting the starter code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background:#f0f9ff; border-left:4px solid #3b82f6; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ“‹ STEP 1 - RESEARCH (10-15 minutes)\n",
        "\n",
        "**ğŸ“– READ THE AWS CODE REVIEW PATTERN:**\n",
        "   \n",
        "ğŸ‘‰ [AWS Anthropic Code Review Pattern](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/code-review.md)\n",
        "\n",
        "**ğŸ” KEY THINGS TO LOOK FOR:**\n",
        "- âœ“ How do they structure code review prompts?\n",
        "- âœ“ What review dimensions do they cover? (Security, Performance, Quality, etc.)\n",
        "- âœ“ What severity levels do they use and how are they defined?\n",
        "- âœ“ What output format do they recommend?\n",
        "- âœ“ How do they ensure actionable feedback?\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ’­ STEP 2 - DESIGN YOUR TEMPLATE (10-15 minutes)\n",
        "\n",
        "**ANSWER THESE QUESTIONS BEFORE CODING:**\n",
        "\n",
        "**1ï¸âƒ£  ROLE:** What expertise should the AI have?\n",
        "   - ğŸ’¡ *Hint: This is a Python authentication function - what type of engineer should review it?*\n",
        "\n",
        "**2ï¸âƒ£  CONTEXT:** What information helps the AI understand the code?\n",
        "   - Repository and service name?\n",
        "   - Purpose of the code change?\n",
        "   - Technology stack specifics?\n",
        "   - Security requirements?\n",
        "\n",
        "**3ï¸âƒ£  REVIEW DIMENSIONS:** What aspects should be evaluated?\n",
        "   \n",
        "   Consider the 6 dimensions from earlier in this notebook:\n",
        "   - **Security** (SQL injection, password handling, input validation)\n",
        "   - **Performance** (database queries, caching)\n",
        "   - **Error Handling** (exceptions, edge cases)\n",
        "   - **Code Quality** (readability, maintainability)\n",
        "   - **Correctness** (authentication logic)\n",
        "   - **Best Practices** (Python idioms, security standards)\n",
        "\n",
        "**4ï¸âƒ£  OUTPUT FORMAT:** How should findings be presented?\n",
        "   - Markdown vs XML?\n",
        "   - What sections are needed?\n",
        "   - How to structure individual findings?\n",
        "   - What makes feedback actionable?\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"background:#dcfce7; border-left:4px solid #22c55e; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ”¨ STEP 3 - BUILD YOUR TEMPLATE (15-20 minutes)\n",
        "\n",
        "**YOUR TASK:**\n",
        "\n",
        "âš ï¸ **Edit the starter template in the code cell below** by replacing all *TODO* sections with your own design based on your research in Steps 1 & 2.\n",
        "\n",
        "The starter template provides the basic structure - you need to enhance it by:\n",
        "1. Improving the role definition\n",
        "2. Adding relevant context\n",
        "3. Expanding review guidelines with specific checks\n",
        "4. Structuring tasks with clear steps\n",
        "5. Designing an effective output format\n",
        "\n",
        "**ğŸ’¡ TIP:** Look at the complete examples in Cells 9 and 11 to see how all pieces fit together!\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PRACTICE ACTIVITY CODE - Follow Steps 1-3 in the markdown cell above        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ CODE TO REVIEW: Python authentication function with multiple security issues â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "practice_code = \"\"\"\n",
        "+ import hashlib\n",
        "+ \n",
        "+ def authenticate_user(username, password):\n",
        "+     # Connect to database\n",
        "+     query = \"SELECT * FROM users WHERE username = '\" + username + \"'\"\n",
        "+     user = db.execute(query)\n",
        "+     \n",
        "+     # Hash the password\n",
        "+     hashed = hashlib.md5(password.encode()).hexdigest()\n",
        "+     \n",
        "+     # Check password\n",
        "+     if user['password'] == hashed:\n",
        "+         return user\n",
        "+     return None\n",
        "\"\"\"\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âš ï¸  STARTER TEMPLATE - EDIT ALL TODO SECTIONS BELOW âš ï¸\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# This is a basic template to get you started. Your task is to enhance it by:\n",
        "# 1. Improving the role definition\n",
        "# 2. Adding relevant context\n",
        "# 3. Expanding review guidelines with specific checks\n",
        "# 4. Structuring tasks with clear steps\n",
        "# 5. Designing an effective output format\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "practice_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        # âš ï¸ TODO: Change this role based on what you learned from AWS patterns\n",
        "        # ğŸ’¡ Hint: What expertise is needed to review authentication code?\n",
        "        #          Consider: \"Security Engineer\"? \"Senior Backend Engineer\"?\n",
        "        \"content\": \"You are a Senior Software Engineer.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\", \n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: user-authentication-service\n",
        "Service: Authentication API\n",
        "Purpose: Add user login authentication endpoint\n",
        "\n",
        "<!-- âš ï¸ TODO #1: Add more context here based on AWS patterns\n",
        "     Examples to consider:\n",
        "     â€¢ Security requirements: OWASP compliance? PCI-DSS?\n",
        "     â€¢ Technology stack: Python 3.x, PostgreSQL/MySQL, Flask/Django?\n",
        "     â€¢ Authentication standards: OAuth 2.0? JWT tokens?\n",
        "     â€¢ Deployment environment: AWS? On-premise?\n",
        "-->\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{practice_code}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "Evaluate the code across these critical dimensions:\n",
        "\n",
        "1. **Security**: Check for vulnerabilities (SQL injection, weak hashing, input validation)\n",
        "2. **Performance**: Identify scalability issues (database queries, caching opportunities)\n",
        "3. **Error Handling**: Validate exception handling (try-catch, edge cases)\n",
        "4. **Code Quality**: Assess readability and maintainability\n",
        "5. **Correctness**: Verify authentication logic works as intended\n",
        "6. **Best Practices**: Check Python and security standards (OWASP guidelines)\n",
        "\n",
        "<!-- âš ï¸ TODO #2: Enhance these guidelines based on AWS code review patterns\n",
        "     Reference: https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/code-review.md\n",
        "     \n",
        "     Consider adding:\n",
        "     â€¢ Specific vulnerability types to check (e.g., \"Check for CWE-89: SQL Injection\")\n",
        "     â€¢ Clear severity definitions (e.g., \"CRITICAL: Remote code execution, data breach\")\n",
        "     â€¢ Evidence requirements (e.g., \"Cite exact line numbers and code excerpts\")\n",
        "     â€¢ How to explain impact (e.g., \"Explain attack vector and business impact\")\n",
        "     â€¢ Format for secure code examples (e.g., \"Provide parameterized query alternative\")\n",
        "-->\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "<!-- âš ï¸ TODO #3: Define the review steps based on AWS code review patterns\n",
        "     Think about:\n",
        "     â€¢ Step 1 (Analysis): Should you request chain-of-thought reasoning?\n",
        "     â€¢ Step 2 (Assessment): How should issues be categorized? (BLOCKER/MAJOR/MINOR/NIT?)\n",
        "     â€¢ Step 3 (Recommendations): What makes fixes actionable? (code examples? alternatives?)\n",
        "     â€¢ Step 4 (Verdict): What decision format? (Pass/Fail/Needs Discussion?)\n",
        "-->\n",
        "\n",
        "Step 1 - Analyze: Systematically examine code for issues across all dimensions\n",
        "         [âš ï¸ Add specific analysis questions here - what should the LLM consider?]\n",
        "\n",
        "Step 2 - Assess: For each issue found, provide:\n",
        "         [âš ï¸ Define severity levels with concrete criteria]\n",
        "         [âš ï¸ Specify what evidence is needed]\n",
        "         [âš ï¸ Explain how to describe impact]\n",
        "\n",
        "Step 3 - Recommend: Provide actionable fixes\n",
        "         [âš ï¸ Define what makes recommendations actionable]\n",
        "\n",
        "Step 4 - Verdict: Conclude with clear decision\n",
        "         [âš ï¸ Specify decision format and required summary]\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<!-- âš ï¸ TODO #4: Design your output format based on AWS code review patterns\n",
        "     Reference: Look at the template in Cell 9 or Cell 11 for inspiration\n",
        "     \n",
        "     Consider:\n",
        "     â€¢ Markdown (recommended) or XML?\n",
        "     â€¢ Main sections needed? (Analysis? Findings? Verdict?)\n",
        "     â€¢ How should individual issues be structured?\n",
        "     â€¢ What makes the output actionable and readable for engineers?\n",
        "-->\n",
        "\n",
        "Provide your review in clear format:\n",
        "\n",
        "## [âš ï¸ Your Analysis Section Name]\n",
        "[âš ï¸ What goes here? Think about chain-of-thought reasoning]\n",
        "\n",
        "## [âš ï¸ Your Findings Section Name]\n",
        "[âš ï¸ How are issues structured? What information is essential?]\n",
        "\n",
        "### [SEVERITY] Issue Title\n",
        "**Lines:** [âš ï¸ Specify what line information is needed]\n",
        "**Problem:** [âš ï¸ Define how to explain the issue]\n",
        "**Impact:** [âš ï¸ Define how to explain consequences]\n",
        "**Fix:** [âš ï¸ Define how to provide recommendations]\n",
        "\n",
        "## [âš ï¸ Your Verdict Section Name]\n",
        "[âš ï¸ What final information helps decision-making?]\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ§ª TEST YOUR TEMPLATE - Uncomment when you've completed all TODO sections\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# print(\"ğŸ” TESTING YOUR CODE REVIEW TEMPLATE\")\n",
        "# print(\"=\"*70)\n",
        "# result = get_chat_completion(practice_messages, temperature=0.0)\n",
        "# print(result)\n",
        "# print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                           ğŸ’¡ HINTS FOR SUCCESS                               â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ğŸ“‹ CODE REVIEW ELEMENTS TO INCLUDE:\n",
        "   âœ“ Clear severity definitions: BLOCKER (security vulnerabilities), MAJOR, MINOR, NIT\n",
        "   âœ“ Evidence citations: Line numbers and specific code excerpts\n",
        "   âœ“ Impact explanation: Why the issue matters (security breach, data loss, etc.)\n",
        "   âœ“ Actionable recommendations: Specific code fixes with secure alternatives\n",
        "   âœ“ Reasoning transparency: Include analysis section showing thought process\n",
        "\n",
        "âš ï¸  CRITICAL ISSUES IN THIS AUTHENTICATION CODE:\n",
        "   â€¢ SQL Injection vulnerability (line 5 - string concatenation in query)\n",
        "   â€¢ Weak password hashing (line 8 - MD5 is cryptographically broken)\n",
        "   â€¢ Missing error handling (no try-catch, no validation)\n",
        "   â€¢ Information leakage (no distinction between \"user not found\" vs \"wrong password\")\n",
        "   â€¢ No input validation (username/password could be empty, malicious)\n",
        "   â€¢ Missing security best practices (no rate limiting, no password complexity)\n",
        "\n",
        "â“ SELF-CHECK QUESTIONS:\n",
        "   â†’ Does my prompt cover all 6 review dimensions?\n",
        "   â†’ Does it prioritize security issues appropriately for authentication code?\n",
        "   â†’ Does it request specific evidence (line numbers, vulnerable code excerpts)?\n",
        "   â†’ Does it ask for secure code examples (parameterized queries, bcrypt)?\n",
        "   â†’ Are severity levels well-defined with concrete security impact?\n",
        "   â†’ Does it use a clear, readable output format (markdown recommended)?\n",
        "\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                            ğŸ¯ NEXT CHALLENGES                                â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "After creating your template, extend your learning:\n",
        "   \n",
        "   1ï¸âƒ£  Test it on different code samples (frontend, backend, different languages)\n",
        "   2ï¸âƒ£  Create specialized variants:\n",
        "       â€¢ Security-only (reference: AWS security-scan.md pattern)\n",
        "       â€¢ Performance-only (reference: AWS analyze-performance.md pattern)\n",
        "   3ï¸âƒ£  Compare with the complete examples in Cells 9 and 11\n",
        "       â€¢ What did you do similarly? Differently?\n",
        "       â€¢ Which approach works better for your use case?\n",
        "\n",
        "ğŸ“š REFERENCE CELLS:\n",
        "   â€¢ Cell 9: General code review template with markdown output\n",
        "   â€¢ Cell 11: Security-focused review example with OWASP categories\n",
        "   â€¢ Cell 14: The 3-step process for this practice activity\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ğŸ“š Learn More: Advanced Code Review Patterns\n",
        "\n",
        "Want to dive deeper into production code review automation? Explore these resources:\n",
        "\n",
        "**ğŸ“– AWS Anthropic Advanced Patterns**\n",
        "- [Code Review Command Pattern](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/code-review.md) - Production-ready patterns for AI-powered code review\n",
        "- Covers advanced topics like multi-file reviews, security-focused analysis, and CI/CD integration\n",
        "\n",
        "**ğŸ”— Related Best Practices**\n",
        "- [Claude 4 Prompt Engineering Best Practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices) - Core prompting techniques\n",
        "- [Prompt Templates and Variables](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables) - Parameterization strategies\n",
        "\n",
        "**ğŸ’¡ What You Can Build Next:**\n",
        "- Integrate this template into your CI/CD pipeline (GitHub Actions, GitLab CI)\n",
        "- Create specialized variants (security-only reviews, performance-only reviews)\n",
        "- Build a review bot that automatically comments on pull requests\n",
        "- Develop custom severity criteria tailored to your team's standards\n",
        "\n",
        "<div style=\"margin-top:16px; color:#15803d; padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e;\">\n",
        "<strong>ğŸ¯ Pro Tip:</strong> The AWS patterns repository includes examples of integrating these templates with AWS Lambda, CodeCommit, and other cloud services. Great for enterprise deployments!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 24px; border-radius: 12px; margin: 40px 0; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "    <h2 style=\"color: white; margin: 0; font-size: 1.8em; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">â˜• Suggested Break Point #1</h2>\n",
        "    <p style=\"margin: 8px 0; font-size: 1.1em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">~40 minutes elapsed</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">âœ… Completed:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Section 1: Code Review Automation Template</li>\n",
        "      <li>Built production-ready code review prompts</li>\n",
        "      <li>Practiced with security vulnerability detection</li>\n",
        "      <li>Reviewed React component for performance issues</li>\n",
        "    </ul>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">â­ï¸ Coming Next:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Section 2: Test Case Generation Template</li>\n",
        "      <li>Coverage gap identification</li>\n",
        "      <li>Smart test plan creation</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">â±ï¸ Next section: ~30-35 minutes</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(255,255,255,0.95); padding: 14px; border-radius: 8px; margin: 16px 0; text-align: center; color: #1e293b;\">\n",
        "    <p style=\"margin: 0; font-weight: bold; font-size: 1.1em; color: #1e293b;\">ğŸ“Œ BOOKMARK TO RESUME:</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 1.15em; font-weight: bold; color: #0f172a;\">\"Section 2: Test Case Generation Template\"</p>\n",
        "  </div>\n",
        "  \n",
        "  <p style=\"text-align: center; margin: 16px 0 0 0; font-size: 0.9em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">\n",
        "    ğŸ’¡ <em>This is a natural stopping point. Feel free to take a break and return later!</em>\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª Section 2: Test Generation Automation Template\n",
        "\n",
        "### Building a Comprehensive Test Generation Prompt with Multi-Tactic Combination\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#92400e;\">ğŸ¯ What You'll Build in This Section</strong><br><br>\n",
        "\n",
        "You'll create a **production-ready test generation prompt template** that automatically produces comprehensive test suites by analyzing requirements and identifying coverage gaps. This isn't just about writing happy-path testsâ€”you're building a system that uncovers edge cases, flags ambiguities, and produces actionable test specifications.\n",
        "\n",
        "**Time Required:** ~40 minutes (includes building, testing, and refining the template)\n",
        "</div>\n",
        "\n",
        "#### ğŸ“‹ Before You Start: What You'll Need\n",
        "\n",
        "To get the most from this section, have ready:\n",
        "\n",
        "1. **Requirements to test** (options):\n",
        "   - A feature spec from your current sprint\n",
        "   - User stories with acceptance criteria\n",
        "   - Sample requirements provided in the activities below\n",
        "   - Any vague or ambiguous requirements that need clarification\n",
        "\n",
        "2. **Context about your test strategy**:\n",
        "   - What test types does your team write? (unit, integration, E2E)\n",
        "   - What test framework do you use? (pytest, Jest, JUnit)\n",
        "   - What makes a good test specification in your workflow?\n",
        "\n",
        "3. **Your API connection** set up and tested (from the setup section above)\n",
        "\n",
        "<div style=\"background:#dbeafe; border-left:4px solid #3b82f6; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#1e40af;\">ğŸ’¡ Why This Approach Works with Modern LLMs</strong><br><br>\n",
        "\n",
        "This template follows industry best practices for prompt engineering with advanced language models. According to [Claude 4 prompt engineering best practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices), modern LLMs excel when you:\n",
        "\n",
        "- **Structure the analysis process** - We'll decompose test generation into clear steps: analyze requirements â†’ identify gaps â†’ generate specs â†’ document infrastructure needs\n",
        "- **Request explicit reasoning** - Chain-of-thought helps the model explain *why* certain edge cases matter (e.g., \"Testing expiration at midnight requires timezone handling\")\n",
        "- **Use systematic frameworks** - Categorizing tests by type (unit/integration) and coverage dimension (happy path/edge case/error path) produces more thorough results\n",
        "- **Flag ambiguities proactively** - Encouraging the model to question unclear requirements prevents wasted testing effort on wrong assumptions\n",
        "\n",
        "These aren't arbitrary choicesâ€”they directly address how advanced language models process instructions most effectively, ensuring comprehensive test coverage across different AI providers.\n",
        "</div>\n",
        "\n",
        "#### ğŸ¯ The Problem We're Solving\n",
        "\n",
        "Manual test planning faces three critical challenges:\n",
        "\n",
        "1. **ğŸ“‹ Incomplete Coverage**\n",
        "   - Easy to miss edge cases and error paths\n",
        "   - Boundary conditions often overlooked (0%, 100%, empty inputs)\n",
        "   - Security and performance test scenarios forgotten\n",
        "   - **Impact:** Bugs slip through to production, customer trust erodes\n",
        "\n",
        "2. **â° Time Pressure**\n",
        "   - Testing gets squeezed at the end of sprints\n",
        "   - QA teams struggle to keep up with feature velocity\n",
        "   - Test planning rushed, documentation minimal\n",
        "   - **Impact:** Technical debt in test suites, maintenance nightmares\n",
        "\n",
        "3. **ğŸ² Missed Ambiguities**\n",
        "   - Unclear requirements don't get questioned until implementation\n",
        "   - Assumptions made without validation\n",
        "   - Integration points and dependencies discovered late\n",
        "   - **Impact:** Rework, missed deadlines, scope creep\n",
        "\n",
        "#### ğŸ—ï¸ How We'll Build It: The Tactical Combination\n",
        "\n",
        "| Tactic | Purpose | Implementation |\n",
        "|--------|---------|----------------|\n",
        "| **Role Prompting** | Assign QA expertise | \"You are a QA Automation Lead with expertise in {{tech_stack}}\" |\n",
        "| **Structured Inputs** | Organize requirements & existing tests | XML tags: `<requirements>`, `<existing_tests>` |\n",
        "| **Task Decomposition** | Break down test generation process | Numbered steps: Analyze â†’ Identify Gaps â†’ Generate Tests â†’ Document Dependencies |\n",
        "| **Chain-of-Thought** | Encourage reasoning about coverage | Request explicit analysis of gaps and ambiguities |\n",
        "| **Structured Output** | Enable automation | Markdown format with sections for different test types |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“‹ Test Generation Template Structure\n",
        "\n",
        "<div style=\"background:#eff6ff; border-left:4px solid #3b82f6; padding:16px; border-radius:6px; margin:20px 0; color:#1e293b;\">\n",
        "<strong>ğŸ”¨ Let's Build It</strong><br><br>\n",
        "\n",
        "We'll construct this template by:\n",
        "1. **Defining the QA role** with specific tech stack expertise\n",
        "2. **Structuring inputs** using XML tags for requirements and existing test context\n",
        "3. **Decomposing the task** into: Analyze â†’ Identify Gaps â†’ Generate Tests â†’ Document Dependencies\n",
        "4. **Requesting chain-of-thought** for coverage analysis\n",
        "5. **Specifying markdown output** for test plans (replacing verbose XML with readable format)\n",
        "6. **Adding parameters** (`{{tech_stack}}`, `{{requirements}}`, `{{existing_tests}}`) for reusability\n",
        "\n",
        "This template draws inspiration from [AWS Anthropic test generation patterns](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/generate-tests.md), adapted for clarity and automation.\n",
        "</div>\n",
        "\n",
        "```xml\n",
        "<role>\n",
        "You are a QA Automation Lead with expertise in {{tech_stack}}.\n",
        "</role>\n",
        "\n",
        "<requirements>\n",
        "{{functional_requirements}}\n",
        "</requirements>\n",
        "\n",
        "<existing_tests>\n",
        "{{test_suite_overview}}\n",
        "</existing_tests>\n",
        "\n",
        "<tasks>\n",
        "1. Analyze the requirements and existing test coverage\n",
        "2. Identify coverage gaps across these dimensions:\n",
        "   - Missing scenarios (happy paths, edge cases, error paths)\n",
        "   - Business rule validation\n",
        "   - Data boundary conditions\n",
        "   - Concurrent/async behavior\n",
        "   - Security concerns (auth, input validation)\n",
        "   - Performance considerations\n",
        "\n",
        "3. For each identified gap, generate test specifications including:\n",
        "   - Test name (descriptive, follows naming conventions)\n",
        "   - Purpose (what does this test verify?)\n",
        "   - Test type (unit, integration, e2e)\n",
        "   - Preconditions (required setup, test data, mocks)\n",
        "   - Steps (execution sequence)\n",
        "   - Expected outcome (assertions, success criteria)\n",
        "\n",
        "4. Categorize tests by type and document dependencies\n",
        "\n",
        "5. Flag ambiguities in requirements that need clarification\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "Provide your test plan in clear markdown format:\n",
        "\n",
        "## ğŸ” Analysis\n",
        "[Your reasoning about requirements and existing coverage - what patterns do you see?]\n",
        "\n",
        "## âš ï¸ Ambiguities\n",
        "[Requirements that need clarification before testing]\n",
        "\n",
        "## ğŸ“Š Coverage Gaps\n",
        "[What's missing from current test suite?]\n",
        "\n",
        "## ğŸ§ª Unit Tests\n",
        "\n",
        "### Test: [Descriptive Name]\n",
        "**Purpose:** [What this test verifies]\n",
        "**Preconditions:** [Required setup]\n",
        "**Steps:**\n",
        "1. [Action]\n",
        "2. [Action]\n",
        "**Expected:** [Success criteria]\n",
        "\n",
        "[Repeat for each unit test]\n",
        "\n",
        "## ğŸ”— Integration Tests\n",
        "\n",
        "### Test: [Descriptive Name]\n",
        "**Purpose:** [What this test verifies]\n",
        "**Preconditions:** [Required setup]\n",
        "**Steps:**\n",
        "1. [Action]\n",
        "2. [Action]\n",
        "**Expected:** [Success criteria]\n",
        "\n",
        "[Repeat for each integration test]\n",
        "\n",
        "## ğŸ› ï¸ Test Infrastructure Needs\n",
        "[Mocks, fixtures, test data, environment dependencies]\n",
        "</output_format>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’» Working Example: Payment Service Test Generation\n",
        "\n",
        "Let's generate comprehensive tests for a payment processing service.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Test Case Generation for Payment Service\n",
        "\n",
        "functional_requirements = \"\"\"\n",
        "Payment Processing Requirements:\n",
        "1. Process credit card payments with validation\n",
        "2. Handle multiple currencies (USD, EUR, GBP)\n",
        "3. Apply discounts and calculate tax\n",
        "4. Generate transaction receipts\n",
        "5. Handle payment failures and retries (max 3 attempts)\n",
        "6. Send confirmation emails on success\n",
        "7. Log all transactions for audit compliance\n",
        "8. Support payment refunds within 30 days\n",
        "\"\"\"\n",
        "\n",
        "existing_tests = \"\"\"\n",
        "Current Test Suite (payment_service_test.py):\n",
        "- test_process_valid_payment() - Happy path for USD payments\n",
        "- test_invalid_card_number() - Validates card number format\n",
        "- test_calculate_tax() - Tax calculation for US region only\n",
        "\"\"\"\n",
        "\n",
        "test_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a QA Automation Lead with expertise in Python testing frameworks (pytest).\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<requirements>\n",
        "{functional_requirements}\n",
        "</requirements>\n",
        "\n",
        "<existing_tests>\n",
        "{existing_tests}\n",
        "</existing_tests>\n",
        "\n",
        "<tasks>\n",
        "1. Analyze the requirements and existing test coverage\n",
        "2. Identify coverage gaps across these dimensions:\n",
        "   - Missing scenarios (happy paths, edge cases, error paths)\n",
        "   - Business rule validation\n",
        "   - Data boundary conditions\n",
        "   - Concurrent/async behavior\n",
        "   - Security concerns (auth, input validation)\n",
        "   - Performance considerations\n",
        "\n",
        "3. For each identified gap, generate test specifications including:\n",
        "   - Test name (descriptive, follows naming conventions)\n",
        "   - Purpose (what does this test verify?)\n",
        "   - Test type (unit, integration, e2e)\n",
        "   - Preconditions (required setup, test data, mocks)\n",
        "   - Steps (execution sequence)\n",
        "   - Expected outcome (assertions, success criteria)\n",
        "\n",
        "4. Categorize tests by type and document dependencies\n",
        "\n",
        "5. Flag ambiguities in requirements that need clarification\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "Provide your test plan in clear markdown format:\n",
        "\n",
        "## ğŸ” Analysis\n",
        "[Your reasoning about requirements and existing coverage - what patterns do you see?]\n",
        "\n",
        "## âš ï¸ Ambiguities\n",
        "[Requirements that need clarification before testing]\n",
        "\n",
        "## ğŸ“Š Coverage Gaps\n",
        "[What's missing from current test suite?]\n",
        "\n",
        "## ğŸ§ª Unit Tests\n",
        "\n",
        "### Test: [Descriptive Name]\n",
        "**Purpose:** [What this test verifies]\n",
        "**Preconditions:** [Required setup]\n",
        "**Steps:**\n",
        "1. [Action]\n",
        "2. [Action]\n",
        "**Expected:** [Success criteria]\n",
        "\n",
        "[Repeat for each unit test]\n",
        "\n",
        "## ğŸ”— Integration Tests\n",
        "\n",
        "### Test: [Descriptive Name]\n",
        "**Purpose:** [What this test verifies]\n",
        "**Preconditions:** [Required setup]\n",
        "**Steps:**\n",
        "1. [Action]\n",
        "2. [Action]\n",
        "**Expected:** [Success criteria]\n",
        "\n",
        "[Repeat for each integration test]\n",
        "\n",
        "## ğŸ› ï¸ Test Infrastructure Needs\n",
        "[Mocks, fixtures, test data, environment dependencies]\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ğŸ§ª TEST GENERATION IN PROGRESS...\")\n",
        "print(\"=\"*70)\n",
        "test_result = get_chat_completion(test_messages, temperature=0.0)\n",
        "print(test_result)\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ‹ï¸ Practice Activity: Build Your Own Test Generation Template\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:16px; border-radius:6px; margin:20px 0; color:#000000;\">\n",
        "<strong style=\"color:#92400e;\">â±ï¸ Time Required: 35-50 minutes</strong><br>\n",
        "This is a hands-on research and build activity. You'll explore professional test generation patterns and create your own template.\n",
        "</div>\n",
        "\n",
        "#### ğŸ“– What You'll Do\n",
        "\n",
        "This activity challenges you to **research, design, and build** a production-ready test generation template by studying real-world patterns from AWS. You'll work with ambiguous requirements for a shopping cart discount system - a perfect scenario for showcasing comprehensive test planning.\n",
        "\n",
        "#### ğŸ¯ Learning Objectives\n",
        "\n",
        "By completing this activity, you will:\n",
        "- âœ… Learn how to research and adapt professional test generation patterns\n",
        "- âœ… Understand how to identify coverage gaps and ambiguities in requirements\n",
        "- âœ… Practice designing structured test plans with unit and integration tests\n",
        "- âœ… Build a reusable template for automated test case generation\n",
        "\n",
        "#### ğŸ“‹ The Scenario\n",
        "\n",
        "A product manager has provided vague requirements for a new feature:\n",
        "\n",
        "**Feature: Shopping Cart Discount System**\n",
        "- Users can apply discount codes at checkout\n",
        "- Some discounts are percentage-based, others are fixed amounts\n",
        "- Discounts have expiration dates\n",
        "- Some codes are one-time use, others unlimited\n",
        "- Discounts can't be combined\n",
        "\n",
        "**Existing Test Coverage:**\n",
        "```python\n",
        "# Current test suite:\n",
        "- test_apply_percentage_discount() # 10% off $100 cart\n",
        "- test_fixed_amount_discount()     # $5 off $50 cart\n",
        "```\n",
        "\n",
        "**Your Challenge:** These requirements are intentionally vague! Your template should identify ambiguities, generate edge cases, and produce comprehensive test specifications.\n",
        "\n",
        "#### ğŸ” Code Sample for Testing\n",
        "\n",
        "Below you'll find the discount system requirements with minimal existing coverage. Use this as your test case while building your template.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background:#f0f9ff; border-left:4px solid #3b82f6; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ“‹ STEP 1 - RESEARCH (10-15 minutes)\n",
        "\n",
        "**ğŸ“– READ THE AWS TEST GENERATION PATTERN:**\n",
        "   \n",
        "ğŸ‘‰ [AWS Anthropic Test Generation Pattern](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/generate-tests.md)\n",
        "\n",
        "**ğŸ” KEY THINGS TO LOOK FOR:**\n",
        "- âœ“ How do they structure test generation prompts?\n",
        "- âœ“ What dimensions do they analyze? (happy paths, edge cases, error paths)\n",
        "- âœ“ How do they handle ambiguous requirements?\n",
        "- âœ“ What output format do they recommend for test specifications?\n",
        "- âœ“ How do they categorize tests (unit vs integration)?\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"background:#fef3c7; border-left:4px solid #f59e0b; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ’­ STEP 2 - DESIGN YOUR TEMPLATE (10-15 minutes)\n",
        "\n",
        "**ANSWER THESE QUESTIONS BEFORE CODING:**\n",
        "\n",
        "**1ï¸âƒ£  ROLE:** What expertise should the AI have?\n",
        "   - ğŸ’¡ *Hint: This is an e-commerce discount system - what type of QA engineer should test it?*\n",
        "\n",
        "**2ï¸âƒ£  INPUTS:** What information helps the AI generate comprehensive tests?\n",
        "   - Requirements document (the vague feature description)?\n",
        "   - Existing test coverage (what's already tested)?\n",
        "   - Tech stack context (Python/pytest, JavaScript/Jest)?\n",
        "   - Business rules to validate?\n",
        "\n",
        "**3ï¸âƒ£  COVERAGE DIMENSIONS:** What aspects should be tested?\n",
        "   \n",
        "   Consider these test categories:\n",
        "   - **Happy Paths** (valid discount codes, successful applications)\n",
        "   - **Edge Cases** (boundary values: 0%, 100% discounts, $0.01 amounts)\n",
        "   - **Error Paths** (expired codes, invalid codes, already-used one-time codes)\n",
        "   - **Business Rules** (no combination, minimum cart value requirements)\n",
        "   - **Ambiguities** (What if discount > cart total? Case sensitivity?)\n",
        "\n",
        "**4ï¸âƒ£  OUTPUT FORMAT:** How should test specifications be structured?\n",
        "   - Markdown vs XML?\n",
        "   - What fields per test? (name, purpose, preconditions, steps, expected)\n",
        "   - How to separate unit vs integration tests?\n",
        "   - How to flag ambiguities and infrastructure needs?\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"background:#dcfce7; border-left:4px solid #22c55e; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
        "\n",
        "### ğŸ”¨ STEP 3 - BUILD YOUR TEMPLATE (15-20 minutes)\n",
        "\n",
        "**YOUR TASK:**\n",
        "\n",
        "âš ï¸ **Edit the starter template in the code cell below** by replacing all `TODO` sections with your own design based on your research in Steps 1 & 2.\n",
        "\n",
        "The starter template provides the basic structure - you need to enhance it by:\n",
        "1. Improving the QA role definition\n",
        "2. Adding complete requirements and existing test context\n",
        "3. Expanding task steps for comprehensive coverage analysis\n",
        "4. Designing an effective output format for test specifications\n",
        "\n",
        "**ğŸ’¡ TIP:** Look at the complete example in Cell 20 to see how all pieces fit together!\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**ğŸ“– Full Solution Reference:** \n",
        "\n",
        "After completing your template, you can compare your approach with [solutions/activity-3.3-test-generation-solution.md](solutions/activity-3.3-test-generation-solution.md) to see:\n",
        "- A complete test generation template implementation\n",
        "- How to identify ambiguities in requirements systematically\n",
        "- Examples of comprehensive edge case coverage\n",
        "- Sprint planning and TDD workflow integration\n",
        "\n",
        "<div style=\"margin-top:16px; color:#15803d; padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e;\">\n",
        "<strong>ğŸ’¡ Remember:</strong> There's no single \"correct\" solution. The goal is to build a template that works for your specific testing needs. Focus on understanding the <em>why</em> behind each design decision rather than matching the solution exactly.\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PRACTICE ACTIVITY CODE - Follow Steps 1-3 in the markdown cell above       â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# REQUIREMENTS: Shopping Cart Discount System (intentionally vague!)\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "discount_requirements = \"\"\"\n",
        "Feature: Shopping Cart Discount System\n",
        "\n",
        "Requirements:\n",
        "1. Users can apply discount codes at checkout\n",
        "2. Discount types: percentage (10%, 25%, etc.) or fixed amount ($5, $20, etc.)\n",
        "3. Each discount code has an expiration date\n",
        "4. Usage limits: one-time use OR unlimited\n",
        "5. Business rule: Discounts cannot be combined (one per order)\n",
        "6. Cart total must be > 0 after discount applied\n",
        "7. Fixed discounts cannot exceed cart total\n",
        "\"\"\"\n",
        "\n",
        "existing_discount_tests = \"\"\"\n",
        "Current test suite (minimal coverage):\n",
        "- test_apply_percentage_discount() - 10% off $100 cart\n",
        "- test_fixed_amount_discount() - $5 off $50 cart\n",
        "\"\"\"\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âš ï¸  STARTER TEMPLATE - EDIT ALL TODO SECTIONS BELOW âš ï¸\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# This template provides basic structure. Your task is to enhance it by:\n",
        "# 1. Refining the QA role definition\n",
        "# 2. Structuring comprehensive task steps\n",
        "# 3. Designing an effective output format\n",
        "# 4. Adding coverage dimensions and ambiguity detection\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "discount_test_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        # âš ï¸ TODO: Refine this role based on what you learned from AWS patterns\n",
        "        # ğŸ’¡ Hint: What specific QA expertise is needed for e-commerce testing?\n",
        "        #          Consider: \"QA Automation Lead specializing in...\"?\n",
        "        \"content\": \"You are a QA Automation Lead specializing in e-commerce testing.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<requirements>\n",
        "{discount_requirements}\n",
        "\n",
        "<!-- âš ï¸ TODO #1: Should you add more context here?\n",
        "     Examples to consider:\n",
        "     â€¢ Tech stack: Python/pytest? JavaScript/Jest?\n",
        "     â€¢ Business context: B2C e-commerce platform\n",
        "     â€¢ Compliance requirements: PCI-DSS? Regional pricing laws?\n",
        "     â€¢ Performance expectations: Must handle X transactions/sec?\n",
        "-->\n",
        "</requirements>\n",
        "\n",
        "<existing_tests>\n",
        "{existing_discount_tests}\n",
        "\n",
        "<!-- âš ï¸ TODO #2: What additional test context would be helpful?\n",
        "     â€¢ Test framework details?\n",
        "     â€¢ Current coverage percentage?\n",
        "     â€¢ Known gaps in testing infrastructure?\n",
        "-->\n",
        "</existing_tests>\n",
        "\n",
        "<tasks>\n",
        "<!-- âš ï¸ TODO #3: Design comprehensive task steps based on AWS test generation patterns\n",
        "     Reference: https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/generate-tests.md\n",
        "     \n",
        "     Consider these steps:\n",
        "     â€¢ Step 1: Analyze requirements and identify ambiguities\n",
        "     â€¢ Step 2: List coverage gaps across dimensions (happy/edge/error paths)\n",
        "     â€¢ Step 3: Generate test specifications with clear purpose\n",
        "     â€¢ Step 4: Categorize by test type (unit vs integration)\n",
        "     â€¢ Step 5: Flag infrastructure needs (mocks, fixtures, test data)\n",
        "-->\n",
        "\n",
        "1. Analyze requirements and identify ambiguities or missing specifications\n",
        "   [âš ï¸ Add guiding questions: What constitutes an ambiguity? How to flag them?]\n",
        "\n",
        "2. List coverage gaps in existing tests\n",
        "   [âš ï¸ Define dimensions: happy paths, edge cases, error paths, business rules]\n",
        "\n",
        "3. Generate comprehensive test cases\n",
        "   [âš ï¸ Specify what each test needs: name format, purpose, preconditions, steps, expected]\n",
        "\n",
        "4. Categorize tests by type\n",
        "   [âš ï¸ Define criteria: What makes a test \"unit\" vs \"integration\"?]\n",
        "\n",
        "5. Document test infrastructure needs\n",
        "   [âš ï¸ What should be flagged: mocks, fixtures, environment dependencies?]\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<!-- âš ï¸ TODO #4: Design your output format based on AWS test generation patterns\n",
        "     Reference: Look at Cell 20 for the markdown format example\n",
        "     \n",
        "     Consider:\n",
        "     â€¢ Markdown (recommended) or XML?\n",
        "     â€¢ Main sections: Analysis? Ambiguities? Coverage Gaps? Test Specs?\n",
        "     â€¢ Test structure: What fields per test? (name, purpose, preconditions, steps, expected)\n",
        "     â€¢ How to separate unit vs integration tests?\n",
        "     â€¢ How to document infrastructure needs?\n",
        "-->\n",
        "\n",
        "Provide your test plan in clear format:\n",
        "\n",
        "## [âš ï¸ Your Analysis Section Name]\n",
        "[âš ï¸ What goes here? Think about requirement analysis and ambiguity detection]\n",
        "\n",
        "## [âš ï¸ Your Ambiguities Section Name]\n",
        "[âš ï¸ How should unclear requirements be flagged?]\n",
        "\n",
        "## [âš ï¸ Your Coverage Gaps Section Name]\n",
        "[âš ï¸ What information helps identify what's missing?]\n",
        "\n",
        "## [âš ï¸ Your Unit Tests Section Name]\n",
        "[âš ï¸ How should individual unit tests be structured?]\n",
        "\n",
        "### Test: [Descriptive Name]\n",
        "**Purpose:** [âš ï¸ Define what makes a good purpose statement]\n",
        "**Preconditions:** [âš ï¸ What setup information is needed?]\n",
        "**Steps:** [âš ï¸ How detailed should steps be?]\n",
        "**Expected:** [âš ï¸ What makes expectations clear and testable?]\n",
        "\n",
        "## [âš ï¸ Your Integration Tests Section Name]\n",
        "[âš ï¸ Similar structure to unit tests, but what distinguishes integration tests?]\n",
        "\n",
        "## [âš ï¸ Your Infrastructure Needs Section Name]\n",
        "[âš ï¸ What test dependencies should be documented?]\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ§ª TEST YOUR TEMPLATE - Uncomment when you've completed all TODO sections\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# print(\"ğŸ§ª TESTING YOUR TEST GENERATION TEMPLATE\")\n",
        "# print(\"=\"*70)\n",
        "# discount_test_result = get_chat_completion(discount_test_messages, temperature=0.0)\n",
        "# print(discount_test_result)\n",
        "# print(\"=\"*70)\n",
        "\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# HINTS & GUIDANCE\n",
        "#â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                           ğŸ’¡ HINTS FOR SUCCESS                               â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ğŸ“‹ TEST GENERATION ELEMENTS TO INCLUDE:\n",
        "   âœ“ Ambiguity detection: Identify unclear or missing requirements\n",
        "   âœ“ Coverage dimensions: Happy paths, edge cases, error paths, business rules\n",
        "   âœ“ Test categorization: Clear distinction between unit and integration tests\n",
        "   âœ“ Comprehensive specs: Purpose, preconditions, steps, expected outcomes\n",
        "   âœ“ Infrastructure flagging: Mocks, fixtures, test data requirements\n",
        "\n",
        "ğŸ¤” AMBIGUITIES TO IDENTIFY IN THIS DISCOUNT SYSTEM:\n",
        "   â€¢ What happens if discount code is expired? (error message? silent fail?)\n",
        "   â€¢ Are discount codes case-sensitive? (SAVE10 vs save10)\n",
        "   â€¢ What if fixed discount > cart total? (set to $0? reject?)\n",
        "   â€¢ Can percentage be 0%? 100%? Over 100%?\n",
        "   â€¢ How are percentages rounded? (0.5 rounds up or down?)\n",
        "   â€¢ Race condition: Multiple users applying one-time-use code simultaneously?\n",
        "   â€¢ Minimum cart value requirement before discount?\n",
        "   â€¢ What if cart is empty when discount is applied?\n",
        "\n",
        "ğŸ§ª EDGE CASES TO COVER:\n",
        "   â€¢ Boundary values: 0%, 1%, 99%, 100% discounts\n",
        "   â€¢ Minimum amounts: $0.01 cart, $0.01 discount\n",
        "   â€¢ Maximum amounts: Very large cart values, very large discounts\n",
        "   â€¢ Expiration: Code expires today (time zone handling?)\n",
        "   â€¢ Usage limits: Exactly at usage limit vs over limit\n",
        "   â€¢ Empty/null/invalid inputs: Missing codes, special characters\n",
        "\n",
        "â“ SELF-CHECK QUESTIONS:\n",
        "   â†’ Does my template request ambiguity identification?\n",
        "   â†’ Does it cover all test dimensions (happy/edge/error/business)?\n",
        "   â†’ Are test specifications detailed enough to implement?\n",
        "   â†’ Is the output format clear and actionable for developers?\n",
        "   â†’ Does it flag infrastructure needs (mock time for expiration tests)?\n",
        "\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                            ğŸ¯ NEXT CHALLENGES                                â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "After creating your template, extend your learning:\n",
        "   \n",
        "   1ï¸âƒ£  Test it on different features (user authentication, payment processing)\n",
        "   2ï¸âƒ£  Create specialized variants:\n",
        "       â€¢ API testing template (focus on contracts, versioning)\n",
        "       â€¢ Security testing template (focus on auth, input validation)\n",
        "   3ï¸âƒ£  Compare with the complete example in Cell 20\n",
        "       â€¢ What did you do similarly? Differently?\n",
        "       â€¢ Which approach generates more comprehensive tests?\n",
        "\n",
        "ğŸ“š REFERENCE CELLS:\n",
        "   â€¢ Cell 18: General test generation template with markdown output\n",
        "   â€¢ Cell 20: Complete working example with payment service\n",
        "   â€¢ Cell 33: The 3-step process for this practice activity\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ğŸ“š Learn More: Advanced Test Generation Patterns\n",
        "\n",
        "Want to dive deeper into AI-powered test automation? Explore these resources:\n",
        "\n",
        "**ğŸ“– AWS Anthropic Advanced Patterns**\n",
        "- [Test Generation Command Pattern](https://github.com/aws-samples/anthropic-on-aws/blob/main/advanced-claude-code-patterns/commands/generate-tests.md) - Production-ready patterns for automated test generation\n",
        "- Covers advanced topics like test data generation, coverage analysis, and CI/CD integration\n",
        "\n",
        "**ğŸ”— Related Best Practices**\n",
        "- [Claude 4 Prompt Engineering Best Practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices) - Core prompting techniques\n",
        "- [Prompt Templates and Variables](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables) - Parameterization strategies\n",
        "\n",
        "**ğŸ’¡ What You Can Build Next:**\n",
        "- Integrate this template into your CI/CD pipeline for automatic test generation\n",
        "- Create specialized variants (API testing, UI testing, security testing)\n",
        "- Build a test coverage analyzer that suggests missing test scenarios\n",
        "- Develop test data generators for edge case validation\n",
        "\n",
        "<div style=\"margin-top:16px; color:#15803d; padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e;\">\n",
        "<strong>ğŸ¯ Pro Tip:</strong> The AWS patterns repository includes examples of integrating test generation with AWS Lambda and CodeBuild. Perfect for automating test creation in your deployment pipeline!\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; padding: 24px; border-radius: 12px; margin: 40px 0; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "    <h2 style=\"color: white; margin: 0; font-size: 1.8em; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">ğŸµ Suggested Break Point #2</h2>\n",
        "    <p style=\"margin: 8px 0; font-size: 1.1em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">~75 minutes elapsed â€¢ Halfway through!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">âœ… Completed (Sections 1-2):</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Code Review Automation Template</li>\n",
        "      <li>Test Generation Automation Template</li>\n",
        "      <li>Production-ready template structures with markdown output</li>\n",
        "      <li>Hands-on practice building code review and test generation templates</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">ğŸ¯ You've completed 2 out of 4 sections!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">â­ï¸ Coming Next:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Section 3: LLM-as-Judge Evaluation Rubric</li>\n",
        "      <li>Validating AI-generated outputs</li>\n",
        "      <li>Quality gates and automated QA</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">â±ï¸ Next section: ~25-30 minutes</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(255,255,255,0.95); padding: 14px; border-radius: 8px; margin: 16px 0; text-align: center; color: #1e293b;\">\n",
        "    <p style=\"margin: 0; font-weight: bold; font-size: 1.1em; color: #1e293b;\">ğŸ“Œ BOOKMARK TO RESUME:</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 1.15em; font-weight: bold; color: #0f172a;\">\"Section 3: LLM-as-Judge Evaluation Rubric\"</p>\n",
        "  </div>\n",
        "  \n",
        "  <p style=\"text-align: center; margin: 16px 0 0 0; font-size: 0.9em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">\n",
        "    ğŸ’¡ <em>Great progress! Consider taking a break before continuing with quality assurance.</em>\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš–ï¸ Section 3: LLM-as-Judge Evaluation Rubric\n",
        "\n",
        "### Validating AI-Generated Outputs\n",
        "\n",
        "**The Quality Challenge:**\n",
        "\n",
        "When AI generates code reviews or test plans, how do you know if they're good?\n",
        "\n",
        "- â“ **Trust issue** - Can we rely on AI feedback?\n",
        "- ğŸ“Š **Consistency** - Does quality vary between runs?\n",
        "- ğŸ¯ **Standards** - Does output meet team expectations?\n",
        "\n",
        "**Solution: LLM-as-Judge Pattern**\n",
        "\n",
        "Use a second AI call with a structured rubric to evaluate the first AI's output. Think of it as automated peer review!\n",
        "\n",
        "#### ğŸ”„ The Workflow\n",
        "\n",
        "```\n",
        "1. AI Generator â†’ Produces code review / test plan\n",
        "2. LLM-as-Judge â†’ Evaluates quality against rubric  \n",
        "3. Decision â†’ Accept / Request revision / Reject\n",
        "```\n",
        "\n",
        "**Benefits:**\n",
        "- âœ… **Automated QA** - No human review needed for every AI output\n",
        "- ğŸ“Š **Objective scoring** - Rubric provides consistent evaluation\n",
        "- ğŸ” **Transparency** - Shows why output passed or failed\n",
        "- ğŸ”„ **Feedback loop** - Low scores trigger regeneration with improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“‹ LLM-as-Judge Rubric Template\n",
        "\n",
        "```xml\n",
        "<role>\n",
        "You are a Principal Engineer reviewing AI-generated code feedback.\n",
        "</role>\n",
        "\n",
        "<rubric>\n",
        "1. Accuracy (40%): Do the identified issues/tests align with the actual code/requirements?\n",
        "2. Completeness (30%): Are major concerns covered? Are tests covering edge cases?\n",
        "3. Actionability (20%): Are remediation steps clear and feasible?\n",
        "4. Communication (10%): Is tone professional and structure clear?\n",
        "</rubric>\n",
        "\n",
        "<instructions>\n",
        "Score each criterion 1-5 with detailed rationale:\n",
        "- 5: Excellent - Exceeds expectations\n",
        "- 4: Good - Meets expectations with minor gaps\n",
        "- 3: Acceptable - Meets minimum bar\n",
        "- 2: Needs work - Significant gaps\n",
        "- 1: Unacceptable - Fails to meet standards\n",
        "\n",
        "Calculate weighted total score.\n",
        "Recommend:\n",
        "- ACCEPT (â‰¥3.5): Production-ready\n",
        "- REVISE (2.5-3.4): Needs improvements, provide specific guidance\n",
        "- REJECT (<2.5): Start over with different approach\n",
        "</instructions>\n",
        "\n",
        "<submission>\n",
        "{{llm_output_under_review}}\n",
        "</submission>\n",
        "\n",
        "<output_format>\n",
        "<evaluation>\n",
        " <scores>\n",
        "   <criterion name=\"Accuracy\" weight=\"40%\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "   </criterion>\n",
        "   <!-- ... other criteria ... -->\n",
        " </scores>\n",
        " <weighted_total></weighted_total>\n",
        " <recommendation>ACCEPT/REVISE/REJECT</recommendation>\n",
        " <feedback></feedback>\n",
        "</evaluation>\n",
        "</output_format>\n",
        "```\n",
        "\n",
        "#### ğŸ”‘ Rubric Design Principles\n",
        "\n",
        "1. **Weighted Criteria** - Most important aspects (accuracy) weighted highest\n",
        "2. **Explicit Scale** - 1-5 with clear definitions prevents ambiguity\n",
        "3. **Evidence Required** - Rationale forces specific justification\n",
        "4. **Actionable Thresholds** - Clear cut-offs (3.5, 2.5) for decisions\n",
        "5. **Improvement Guidance** - \"REVISE\" verdict includes specific feedback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’» Working Example: Evaluating an AI Code Review\n",
        "\n",
        "Let's evaluate the quality of an AI-generated code review using our judge rubric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Evaluating an AI-Generated Code Review\n",
        "\n",
        "# Step 1: Generate a code review (simulated - you could use the earlier example)\n",
        "sample_code = \"\"\"\n",
        "def calculate_discount(price, discount_percent):\n",
        "    return price - (price * discount_percent / 100)\n",
        "\"\"\"\n",
        "\n",
        "# Simulated AI review (normally this would come from get_chat_completion)\n",
        "ai_generated_review = \"\"\"\n",
        "<review>\n",
        " <inner_monologue>\n",
        " Analyzing the discount calculation function. The logic appears straightforward but \n",
        " I should check for edge cases: negative values, values > 100, type handling, \n",
        " and potential precision issues with floating point arithmetic.\n",
        " </inner_monologue>\n",
        " \n",
        " <issues>\n",
        "   <issue>\n",
        "     <severity>major</severity>\n",
        "     <description>No input validation for discount_percent</description>\n",
        "     <evidence>Function accepts any numeric value. discount_percent > 100 would result in negative price.</evidence>\n",
        "     <recommendation>Add validation: if not 0 <= discount_percent <= 100: raise ValueError(\"Discount must be between 0 and 100\")</recommendation>\n",
        "   </issue>\n",
        "   \n",
        "   <issue>\n",
        "     <severity>minor</severity>\n",
        "     <description>No type hints</description>\n",
        "     <evidence>Parameters lack type annotations, making the expected types unclear.</evidence>\n",
        "     <recommendation>Add type hints: def calculate_discount(price: float, discount_percent: float) -> float:</recommendation>\n",
        "   </issue>\n",
        "   \n",
        "   <issue>\n",
        "     <severity>nit</severity>\n",
        "     <description>Missing docstring</description>\n",
        "     <evidence>Function lacks documentation explaining parameters and return value.</evidence>\n",
        "     <recommendation>Add docstring with parameter descriptions and example usage.</recommendation>\n",
        "   </issue>\n",
        " </issues>\n",
        " \n",
        " <verdict>NEEDS REVISION</verdict>\n",
        " <summary>Function has correct core logic but lacks input validation which could lead to runtime bugs. Adding validation and type hints would make it production-ready.</summary>\n",
        "</review>\n",
        "\"\"\"\n",
        "\n",
        "# Step 2: Evaluate with LLM-as-Judge\n",
        "judge_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Principal Engineer reviewing AI-generated code feedback.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Original code under review:\n",
        "{sample_code}\n",
        "\n",
        "AI-generated review to evaluate:\n",
        "</context>\n",
        "\n",
        "<rubric>\n",
        "1. Accuracy (40%): Do identified issues actually exist and are correctly described?\n",
        "2. Completeness (30%): Are major concerns covered? Any critical issues missed?\n",
        "3. Actionability (20%): Are recommendations specific and implementable?\n",
        "4. Communication (10%): Is the review professional, clear, and well-structured?\n",
        "</rubric>\n",
        "\n",
        "<instructions>\n",
        "Score each criterion 1-5 with detailed rationale.\n",
        "Calculate weighted total: (AccuracyÃ—0.4) + (CompletenessÃ—0.3) + (ActionabilityÃ—0.2) + (CommunicationÃ—0.1)\n",
        "Recommend:\n",
        "- ACCEPT (â‰¥3.5): Production-ready\n",
        "- REVISE (2.5-3.4): Needs improvements  \n",
        "- REJECT (<2.5): Unacceptable quality\n",
        "</instructions>\n",
        "\n",
        "<submission>\n",
        "{ai_generated_review}\n",
        "</submission>\n",
        "\n",
        "<output_format>\n",
        "Provide structured evaluation with scores, weighted total, recommendation, and specific feedback.\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"âš–ï¸ JUDGE EVALUATION IN PROGRESS...\")\n",
        "print(\"=\"*70)\n",
        "judge_result = get_chat_completion(judge_messages, temperature=0.0)\n",
        "print(judge_result)\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š Why LLM-as-Judge Is Powerful\n",
        "\n",
        "**1. Automated Quality Gate**\n",
        "```python\n",
        "if weighted_score >= 3.5:\n",
        "    # Auto-approve and use the AI review\n",
        "    post_review_comment(ai_generated_review)\n",
        "elif weighted_score >= 2.5:\n",
        "    # Trigger regeneration with feedback\n",
        "    regenerate_review(with_guidance=judge_feedback)\n",
        "else:\n",
        "    # Fallback to human review\n",
        "    notify_human_reviewer()\n",
        "```\n",
        "\n",
        "**2. Consistent Standards**\n",
        "- Rubric encodes team expectations\n",
        "- Same criteria applied every time\n",
        "- Reduces reviewer bias\n",
        "\n",
        "**3. Continuous Improvement**\n",
        "- Low scores â†’ Prompt refinement\n",
        "- Track score trends over time\n",
        "- A/B test different prompt versions\n",
        "\n",
        "**4. Transparency & Trust**\n",
        "- Shows reasoning for accept/reject\n",
        "- Teams can audit decisions\n",
        "- Builds confidence in AI-assisted workflows\n",
        "\n",
        "#### ğŸ¯ Real-World Use Cases\n",
        "\n",
        "| Application | Implementation |\n",
        "|-------------|----------------|\n",
        "| **CI/CD Pipeline** | Code review â†’ Judge eval â†’ Auto-comment if score > 3.5 |\n",
        "| **Test Plan Validation** | Generate tests â†’ Judge completeness â†’ Flag gaps |\n",
        "| **Documentation Review** | AI writes docs â†’ Judge clarity â†’ Request revisions |\n",
        "| **Prompt Engineering** | Compare prompts â†’ Judge outputs â†’ Pick best version |\n",
        "\n",
        "#### ğŸ”§ Customization Tips\n",
        "\n",
        "**Adjust weights for your context:**\n",
        "```python\n",
        "# Security-focused team\n",
        "Accuracy: 50%, Completeness: 30%, Actionability: 15%, Communication: 5%\n",
        "\n",
        "# DevRel/Documentation team  \n",
        "Communication: 40%, Actionability: 30%, Accuracy: 20%, Completeness: 10%\n",
        "\n",
        "# Fast-moving startup\n",
        "Actionability: 50%, Accuracy: 30%, Completeness: 15%, Communication: 5%\n",
        "```\n",
        "\n",
        "**Add domain-specific criteria:**\n",
        "- **Performance Review**: \"Does review mention Big-O complexity?\"\n",
        "- **Security Review**: \"Are OWASP Top 10 risks addressed?\"\n",
        "- **API Review**: \"Are breaking changes clearly flagged?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white; padding: 24px; border-radius: 12px; margin: 40px 0; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "    <h2 style=\"color: white; margin: 0; font-size: 1.8em; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">ğŸ§ƒ Suggested Break Point #3</h2>\n",
        "    <p style=\"margin: 8px 0; font-size: 1.1em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">~105 minutes elapsed â€¢ Almost there!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">âœ… Completed (Sections 1-3):</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Code Review Template with Decomposition + CoT</li>\n",
        "      <li>Test Case Generation with Coverage Analysis</li>\n",
        "      <li>LLM-as-Judge Evaluation Rubric</li>\n",
        "      <li>Quality gates and automated validation</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">ğŸ¯ You've completed 3 out of 4 sections!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">â­ï¸ Final Sprint:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Hands-On Practice Activities (4 exercises)</li>\n",
        "      <li>Comprehensive code review across multiple dimensions</li>\n",
        "      <li>Test generation for ambiguous requirements</li>\n",
        "      <li>Template customization and quality evaluation</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">â±ï¸ Remaining time: ~40-50 minutes</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(255,255,255,0.95); padding: 14px; border-radius: 8px; margin: 16px 0; text-align: center; color: #1e293b;\">\n",
        "    <p style=\"margin: 0; font-weight: bold; font-size: 1.1em; color: #1e293b;\">ğŸ“Œ BOOKMARK TO RESUME:</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 1.15em; font-weight: bold; color: #0f172a;\">\"Hands-On Practice Activities\"</p>\n",
        "  </div>\n",
        "  \n",
        "  <p style=\"text-align: center; margin: 16px 0 0 0; font-size: 0.9em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">\n",
        "    ğŸ’¡ <em>You're in the home stretch! Take a quick break before the practice exercises.</em>\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‹ï¸ Hands-On Practice Activities\n",
        "\n",
        "### Activity 3.2: Comprehensive Code Review Template\n",
        "\n",
        "**Goal:** Create a template for comprehensive code review across multiple dimensions.\n",
        "\n",
        "**Scenario:** Your team needs automated code reviews for all API changes. Build a prompt template that evaluates:\n",
        "- Security (authentication, input validation, common vulnerabilities)\n",
        "- Performance (query optimization, algorithm efficiency)\n",
        "- Code Quality (readability, maintainability, error handling)\n",
        "- Best Practices (language idioms, design patterns)\n",
        "\n",
        "**Your Task:**\n",
        "1. Adapt the code review template with comprehensive review guidelines\n",
        "2. Test it on the API endpoint code below\n",
        "3. Evaluate: Did it catch issues across multiple dimensions?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activity 3.2: Security Code Review\n",
        "\n",
        "security_code = \"\"\"\n",
        "+ @app.route('/api/user/<user_id>/profile', methods=['GET', 'POST'])\n",
        "+ def user_profile(user_id):\n",
        "+     if request.method == 'POST':\n",
        "+         # Update user profile\n",
        "+         data = request.get_json()\n",
        "+         query = f\"UPDATE users SET bio='{data['bio']}', website='{data['website']}' WHERE id={user_id}\"\n",
        "+         db.execute(query)\n",
        "+         \n",
        "+         # Store uploaded avatar\n",
        "+         if 'avatar' in request.files:\n",
        "+             file = request.files['avatar']\n",
        "+             file.save(f'/uploads/{file.filename}')\n",
        "+         \n",
        "+         return jsonify({\"message\": \"Profile updated\"})\n",
        "+     \n",
        "+     # Get user profile\n",
        "+     user = db.query(f\"SELECT * FROM users WHERE id={user_id}\").fetchone()\n",
        "+     return jsonify(user)\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Build your security review template\n",
        "# Hints:\n",
        "# - Role: \"Senior Security Engineer\" or \"Application Security Specialist\"\n",
        "# - Guidelines: Check for SQL injection, path traversal, missing auth, XSS\n",
        "# - Focus areas: Input validation, authentication, file upload security\n",
        "# - Severity: Use security-specific levels (Critical/High/Medium/Low)\n",
        "\n",
        "security_review_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Senior Application Security Engineer specializing in web API security.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: user-api-service  \n",
        "Endpoint: User Profile Management (new endpoint)\n",
        "Security Focus: OWASP Top 10, authentication, input validation\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{security_code}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "1. Check for OWASP Top 10 vulnerabilities (SQL injection, XSS, broken auth, etc.)\n",
        "2. Verify authentication and authorization mechanisms\n",
        "3. Assess input validation and sanitization\n",
        "4. Review file upload handling for path traversal\n",
        "5. Check for sensitive data exposure\n",
        "6. Cite exact lines with CVE/CWE references where applicable\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Think: In <inner_monologue> tags, identify security vulnerabilities.\n",
        "Step 2 - Assess: For each issue, provide:\n",
        "  â€¢ Severity (critical/high/medium/low)\n",
        "  â€¢ Vulnerability type (SQL injection, etc.)\n",
        "  â€¢ Evidence (line numbers, attack vector)\n",
        "  â€¢ CVE/CWE reference if applicable\n",
        "Step 3 - Suggest: Provide secure code alternatives.\n",
        "Step 4 - Verdict: Security assessment (block/requires-fixes/approve-with-notes).\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<security_review>\n",
        " <vulnerabilities>\n",
        "   <vulnerability>\n",
        "     <severity></severity>\n",
        "     <type></type>\n",
        "     <description></description>\n",
        "     <evidence></evidence>\n",
        "     <cwe_reference></cwe_reference>\n",
        "     <recommendation></recommendation>\n",
        "   </vulnerability>\n",
        " </vulnerabilities>\n",
        " <verdict></verdict>\n",
        " <summary></summary>\n",
        "</security_review>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ğŸ”’ SECURITY REVIEW - Activity 3.2\")\n",
        "print(\"=\"*70)\n",
        "security_result = get_chat_completion(security_review_messages, temperature=0.0)\n",
        "print(security_result)\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ’¡ Expected findings:\")\n",
        "print(\"   - SQL Injection (Critical) - f-string query construction\")\n",
        "print(\"   - Path Traversal (High) - Unsafe file.filename usage\")\n",
        "print(\"   - Missing Authentication (Critical) - No auth check on endpoint\")\n",
        "print(\"   - Potential XSS (Medium) - Unvalidated user data returned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### âœ… Solution Analysis\n",
        "\n",
        "**Key Best Practices Demonstrated:**\n",
        "\n",
        "1. **Multi-Dimensional Role** - Uses \"Senior Software Engineer\" with broad expertise (security, performance, quality)\n",
        "2. **Balanced Review Guidelines** - Covers security, performance, maintainability, and best practices\n",
        "3. **Clear Categories** - Categorizes findings (Security / Performance / Quality / Correctness)\n",
        "4. **Practical Severity** - Uses CRITICAL/MAJOR/MINOR based on impact across all dimensions\n",
        "5. **Actionable Feedback** - Provides concrete fixes and recommendations\n",
        "\n",
        "**Expected Findings:**\n",
        "- âœ… SQL Injection - f-string query construction (Security)\n",
        "- âœ… Path Traversal - Unsafe file.filename usage (Security)\n",
        "- âœ… Missing Authentication - No auth decorator (Security)\n",
        "- âœ… Poor Error Handling - Potential XSS in responses (Quality/Security)\n",
        "\n",
        "**ğŸ“– Full Solution:** See [solutions/activity-3.2-code-review-solution.md](solutions/activity-3.2-code-review-solution.md) for:\n",
        "- Detailed analysis of each best practice\n",
        "- Production CI/CD integration examples\n",
        "- Customization patterns for different tech stacks and contexts\n",
        "- Metrics for tracking template effectiveness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activity 3.3: Template Customization Challenge\n",
        "\n",
        "**Goal:** Customize prompt templates for your team's specific needs.\n",
        "\n",
        "**Scenario:** Different teams have different review standards. Adapt the base template for various contexts.\n",
        "\n",
        "**Your Task:** Choose one and implement it:\n",
        "\n",
        "**Option A: Performance-Focused Review**\n",
        "- Role: \"Senior Performance Engineer\"\n",
        "- Focus: Big-O complexity, caching, database query optimization, memory usage\n",
        "- Test on: A function with nested loops or N+1 query problem\n",
        "\n",
        "**Option B: DevOps/SRE Review**  \n",
        "- Role: \"Site Reliability Engineer\"\n",
        "- Focus: Observability (logging, metrics, tracing), error handling, graceful degradation\n",
        "- Test on: A service initialization function\n",
        "\n",
        "**Option C: API Design Review**\n",
        "- Role: \"API Architect\"  \n",
        "- Focus: RESTful conventions, versioning, backward compatibility, error responses\n",
        "- Test on: A new API endpoint design\n",
        "\n",
        "Pick one and build it below!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### âœ… Solution Analysis\n",
        "\n",
        "**Key Best Practices Demonstrated:**\n",
        "\n",
        "1. **Domain-Specific Role** - \"Performance Engineer\" not generic \"Engineer\"\n",
        "2. **Scale Context** - \"Must handle 1000+ posts\" sets clear performance bar\n",
        "3. **Quantified Analysis** - Big-O notation, query counts, latency estimates (not vague \"slow\")\n",
        "4. **Before/After Metrics** - Shows improvement: 100s â†’ 0.05s (2000x faster!)\n",
        "5. **Actionable Optimizations** - Provides exact code for the fix\n",
        "\n",
        "**Expected Findings:**\n",
        "- âœ… N+1 Query Problem - 2001 database queries (1 user + 1000 posts + 1000 likes)\n",
        "- âœ… Complexity: O(n) queries with network latency = 100 seconds for 1000 posts\n",
        "- âœ… Solution: Single join query reduces to O(1) = 0.05 seconds\n",
        "- âœ… Additional opportunities: Caching, pagination, indexing\n",
        "\n",
        "**Adaptation Pattern:**\n",
        "\n",
        "| Domain | Role | Focus | Output Metrics |\n",
        "|--------|------|-------|----------------|\n",
        "| **Performance** | Performance Engineer | Big-O, N+1, caching | Latency, query counts |\n",
        "| **SRE** | Site Reliability Engineer | Logging, metrics, resilience | Observability gaps |\n",
        "| **API Design** | API Architect | REST, versioning | Breaking changes |\n",
        "\n",
        "**Key Takeaway:** Same template structure, different expertise area!\n",
        "\n",
        "**ğŸ“– Full Solution:** See [solutions/activity-3.3-customization-solution.md](solutions/activity-3.3-customization-solution.md) for:\n",
        "- Complete N+1 query analysis and optimized code\n",
        "- Full adaptation patterns for SRE, API design, React\n",
        "- When to create domain-specific templates\n",
        "- Step-by-step customization strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activity 3.3: Template Customization\n",
        "\n",
        "# Example: Performance-Focused Review\n",
        "perf_code = \"\"\"\n",
        "+ def get_user_posts_with_likes(user_id):\n",
        "+     user = User.query.get(user_id)\n",
        "+     posts = []\n",
        "+     for post_id in user.post_ids:\n",
        "+         post = Post.query.get(post_id)\n",
        "+         like_count = Like.query.filter_by(post_id=post.id).count()\n",
        "+         post.likes = like_count\n",
        "+         posts.append(post)\n",
        "+     return posts\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Customize for YOUR chosen focus area\n",
        "# This example shows performance review - adapt for your choice!\n",
        "\n",
        "custom_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Senior Performance Engineer specializing in database optimization.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: social-media-api\n",
        "Function: get_user_posts_with_likes\n",
        "Performance Requirements: Must handle users with 1000+ posts efficiently\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{perf_code}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "1. Analyze algorithmic complexity (Big-O notation)\n",
        "2. Identify N+1 query problems\n",
        "3. Check for caching opportunities\n",
        "4. Assess memory usage patterns\n",
        "5. Recommend performance optimizations\n",
        "6. Estimate performance impact with data size\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Think: In <inner_monologue>, analyze time/space complexity and identify bottlenecks.\n",
        "Step 2 - Assess: For each issue:\n",
        "  â€¢ Severity (critical/high/medium/low based on performance impact)\n",
        "  â€¢ Complexity analysis (O(n), O(nÂ²), etc.)\n",
        "  â€¢ Evidence (specific operations causing slowdown)\n",
        "  â€¢ Performance impact estimate\n",
        "Step 3 - Suggest: Provide optimized code with complexity improvement.\n",
        "Step 4 - Verdict: Performance rating and estimated improvement.\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<performance_review>\n",
        " <complexity_analysis></complexity_analysis>\n",
        " <issues>\n",
        "   <issue>\n",
        "     <severity></severity>\n",
        "     <problem></problem>\n",
        "     <current_complexity></current_complexity>\n",
        "     <evidence></evidence>\n",
        "     <optimization></optimization>\n",
        "     <improved_complexity></improved_complexity>\n",
        "   </issue>\n",
        " </issues>\n",
        " <verdict></verdict>\n",
        " <summary></summary>\n",
        "</performance_review>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"âš¡ CUSTOM TEMPLATE - Activity 3.3 (Performance Review)\")\n",
        "print(\"=\"*70)\n",
        "custom_result = get_chat_completion(custom_messages, temperature=0.0)\n",
        "print(custom_result)\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ’¡ Adaptation tips:\")\n",
        "print(\"   - Changed role to match domain\")\n",
        "print(\"   - Added domain-specific guidelines (Big-O, N+1)\")\n",
        "print(\"   - Modified severity to reflect performance impact\")\n",
        "print(\"   - Customized output format for complexity analysis\")\n",
        "print(\"\\n   Try adapting this for SRE or API Design review!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activity 3.4: Quality Evaluation with LLM-as-Judge\n",
        "\n",
        "**Goal:** Build an automated quality gate for AI-generated outputs.\n",
        "\n",
        "**Scenario:** You're implementing automated code reviews in your CI/CD pipeline. Before posting AI reviews to PRs, you want quality assurance.\n",
        "\n",
        "**Your Task:**\n",
        "1. Generate a code review (use any previous example or create new one)\n",
        "2. Create an LLM-as-Judge rubric for your team's standards\n",
        "3. Evaluate the review and decide: Accept / Revise / Reject\n",
        "4. Reflection: Would this catch low-quality AI outputs?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### âœ… Solution Analysis\n",
        "\n",
        "**Key Best Practices Demonstrated:**\n",
        "\n",
        "1. **Intentionally Low-Quality Input** - Tests judge with vague review (\"Make it better\")\n",
        "2. **Context-Specific Rubric** - Weights match CI/CD needs (Specificity 40%, Actionability 30%)\n",
        "3. **Clear Scoring Scale** - 1-5 with explicit definitions (not subjective \"good/bad\")\n",
        "4. **Actionable Thresholds** - â‰¥4.0 = accept, 2.5-3.9 = revise, <2.5 = reject\n",
        "5. **Improvement Loop** - Provides specific feedback for regeneration\n",
        "\n",
        "**Expected Judge Scores:**\n",
        "\n",
        "```\n",
        "Specificity: 1/5 âŒ - \"Function could be improved\" is vague\n",
        "Actionability: 1/5 âŒ - \"Make it better\" not actionable\n",
        "Technical Accuracy: 2/5 âš ï¸ - Can't verify without specifics\n",
        "Completeness: 2/5 âš ï¸ - Only 1 issue found, likely incomplete\n",
        "\n",
        "Weighted Total: (1Ã—0.4) + (1Ã—0.3) + (2Ã—0.2) + (2Ã—0.1) = 1.3\n",
        "Decision: REJECT (<2.5) ğŸš«\n",
        "```\n",
        "\n",
        "**Production Workflow:**\n",
        "\n",
        "```python\n",
        "if score >= 4.0:\n",
        "    post_to_pr(review)  # Auto-approve\n",
        "elif score >= 2.5:\n",
        "    regenerate_with_feedback()  # Retry with guidance\n",
        "else:\n",
        "    flag_for_human_review()  # Fallback\n",
        "```\n",
        "\n",
        "**Why This Matters:**\n",
        "- Prevents vague AI outputs from reaching users\n",
        "- Builds trust through consistent quality\n",
        "- Enables true automation (not just \"AI suggestion\")\n",
        "\n",
        "**ğŸ“– Full Solution:** See [solutions/activity-3.4-judge-solution.md](solutions/activity-3.4-judge-solution.md) for:\n",
        "- Complete judge evaluation breakdown\n",
        "- Production quality gate implementation with retry logic\n",
        "- Monitoring dashboard examples\n",
        "- Success metrics to track (acceptance rate, cost per review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activity 3.4: Build Your Own Judge\n",
        "\n",
        "# Sample AI-generated output to evaluate (simulated)\n",
        "ai_output_to_judge = \"\"\"\n",
        "<review>\n",
        " <issues>\n",
        "   <issue>\n",
        "     <severity>medium</severity>\n",
        "     <description>Function could be improved</description>\n",
        "     <evidence>The code is not optimal</evidence>\n",
        "     <recommendation>Make it better</recommendation>\n",
        "   </issue>\n",
        " </issues>\n",
        " <verdict>NEEDS WORK</verdict>\n",
        " <summary>Some issues found</summary>\n",
        "</review>\n",
        "\"\"\"\n",
        "\n",
        "# TODO: This is a LOW QUALITY review (vague, no specifics)\n",
        "# Build a judge that catches this!\n",
        "\n",
        "judge_eval_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a Principal Engineer evaluating AI-generated code reviews for your team's CI/CD pipeline.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "<context>\n",
        "Your team is implementing automated code reviews. Reviews must meet high standards before being posted to PRs.\n",
        "</context>\n",
        "\n",
        "<rubric>\n",
        "1. Specificity (40%): Are issues concrete with exact evidence (line numbers, code snippets)?\n",
        "2. Actionability (30%): Can developer immediately act on recommendations?\n",
        "3. Technical Accuracy (20%): Are the issues technically sound?\n",
        "4. Completeness (10%): Are major categories covered (security, performance, correctness)?\n",
        "</rubric>\n",
        "\n",
        "<instructions>\n",
        "Score each criterion 1-5:\n",
        "- 5: Excellent - Ready for production\n",
        "- 4: Good - Minor improvements needed\n",
        "- 3: Acceptable - Meets minimum bar\n",
        "- 2: Poor - Significant issues, needs revision\n",
        "- 1: Unacceptable - Reject and regenerate\n",
        "\n",
        "Calculate weighted score.\n",
        "Provide specific feedback for scores < 4.\n",
        "\n",
        "Decision thresholds:\n",
        "- ACCEPT (â‰¥4.0): Post to PR\n",
        "- REVISE (2.5-3.9): Regenerate with specific guidance\n",
        "- REJECT (<2.5): Discard, use different approach\n",
        "</instructions>\n",
        "\n",
        "<submission>\n",
        "{ai_output_to_judge}\n",
        "</submission>\n",
        "\n",
        "<output_format>\n",
        "<evaluation>\n",
        " <scores>\n",
        "   <criterion name=\"Specificity\" weight=\"40%\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "     <improvement_needed></improvement_needed>\n",
        "   </criterion>\n",
        "   <criterion name=\"Actionability\" weight=\"30%\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "     <improvement_needed></improvement_needed>\n",
        "   </criterion>\n",
        "   <criterion name=\"Technical Accuracy\" weight=\"20%\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "     <improvement_needed></improvement_needed>\n",
        "   </criterion>\n",
        "   <criterion name=\"Completeness\" weight=\"10%\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "     <improvement_needed></improvement_needed>\n",
        "   </criterion>\n",
        " </scores>\n",
        " <weighted_score></weighted_score>\n",
        " <decision>ACCEPT/REVISE/REJECT</decision>\n",
        " <feedback>Specific guidance for improvement</feedback>\n",
        "</evaluation>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"âš–ï¸ QUALITY EVALUATION - Activity 3.4\")\n",
        "print(\"=\"*70)\n",
        "print(\"Evaluating this AI-generated review:\")\n",
        "print(ai_output_to_judge)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "judge_eval_result = get_chat_completion(judge_eval_messages, temperature=0.0)\n",
        "print(judge_eval_result)\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ’¡ This review is intentionally vague. Your judge should:\")\n",
        "print(\"   - Give low scores for Specificity (no line numbers)\")\n",
        "print(\"   - Give low scores for Actionability ('make it better' is useless)\")\n",
        "print(\"   - Recommend REVISE or REJECT\")\n",
        "print(\"\\n   If your judge caught these issues, it's working! âœ…\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“¦ Reference Implementation: Production-Ready Template Library\n",
        "\n",
        "Below is a complete, copy-paste ready implementation that demonstrates all best practices from this module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Production-Ready Template Library\n",
        "# Copy this to your project and customize for your team\n",
        "\n",
        "from typing import Dict, List, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "# ============================================\n",
        "# 1. TEMPLATE DEFINITIONS\n",
        "# ============================================\n",
        "\n",
        "class ReviewTemplate:\n",
        "    \"\"\"Base template for code reviews with parameterization\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def code_review_template(\n",
        "        tech_stack: str = \"Python microservices\",\n",
        "        repo_name: str = \"{{repo_name}}\",\n",
        "        service_name: str = \"{{service_name}}\",\n",
        "        code_diff: str = \"{{code_diff}}\"\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Production-ready code review template.\n",
        "        \n",
        "        Args:\n",
        "            tech_stack: Technology focus (e.g., \"Python microservices\", \"React frontend\")\n",
        "            repo_name: Repository name for context\n",
        "            service_name: Service/component name\n",
        "            code_diff: Git diff to review\n",
        "        \n",
        "        Returns:\n",
        "            Messages array ready for AI completion\n",
        "        \"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a Senior Backend Engineer specializing in {tech_stack}.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: {repo_name}\n",
        "Service: {service_name}\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{code_diff}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "1. Highlight issues affecting correctness, security, performance, and maintainability.\n",
        "2. Cite exact lines or blocks.\n",
        "3. If code is acceptable, confirm with justification.\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Think: In <inner_monologue> tags, outline potential issues.\n",
        "Step 2 - Assess: For each issue, provide severity, description, evidence.\n",
        "Step 3 - Suggest: Offer actionable remediation tips.\n",
        "Step 4 - Verdict: Conclude with pass/fail and summary.\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<review>\n",
        " <inner_monologue>...</inner_monologue>\n",
        " <issues>\n",
        "   <issue>\n",
        "     <severity></severity>\n",
        "     <description></description>\n",
        "     <evidence></evidence>\n",
        "     <recommendation></recommendation>\n",
        "   </issue>\n",
        " </issues>\n",
        " <verdict></verdict>\n",
        " <summary></summary>\n",
        "</review>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def security_review_template(\n",
        "        repo_name: str = \"{{repo_name}}\",\n",
        "        code_diff: str = \"{{code_diff}}\"\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        \"\"\"Security-focused review template\"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a Senior Application Security Engineer specializing in OWASP Top 10 vulnerabilities.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "<context>\n",
        "Repository: {repo_name}\n",
        "Security Focus: OWASP Top 10, authentication, input validation\n",
        "</context>\n",
        "\n",
        "<code_diff>\n",
        "{code_diff}\n",
        "</code_diff>\n",
        "\n",
        "<review_guidelines>\n",
        "1. Check for OWASP Top 10 vulnerabilities\n",
        "2. Verify authentication and authorization\n",
        "3. Assess input validation and sanitization\n",
        "4. Check for sensitive data exposure\n",
        "5. Cite CVE/CWE references where applicable\n",
        "</review_guidelines>\n",
        "\n",
        "<tasks>\n",
        "Step 1 - Think: In <inner_monologue>, identify security vulnerabilities.\n",
        "Step 2 - Assess: For each issue, provide severity, type, evidence, CWE reference.\n",
        "Step 3 - Suggest: Provide secure code alternatives.\n",
        "Step 4 - Verdict: Security assessment (block/requires-fixes/approve-with-notes).\n",
        "</tasks>\n",
        "\n",
        "<output_format>\n",
        "<security_review>\n",
        " <vulnerabilities>\n",
        "   <vulnerability>\n",
        "     <severity>critical/high/medium/low</severity>\n",
        "     <type>vulnerability type</type>\n",
        "     <description></description>\n",
        "     <evidence></evidence>\n",
        "     <cwe_reference></cwe_reference>\n",
        "     <recommendation></recommendation>\n",
        "   </vulnerability>\n",
        " </vulnerabilities>\n",
        " <verdict></verdict>\n",
        " <summary></summary>\n",
        "</security_review>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def test_generation_template(\n",
        "        tech_stack: str = \"Python/pytest\",\n",
        "        requirements: str = \"{{requirements}}\",\n",
        "        existing_tests: str = \"{{existing_tests}}\"\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        \"\"\"Test case generation template\"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a QA Automation Lead with expertise in {tech_stack}.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "<requirements>\n",
        "{requirements}\n",
        "</requirements>\n",
        "\n",
        "<existing_tests>\n",
        "{existing_tests}\n",
        "</existing_tests>\n",
        "\n",
        "<tasks>\n",
        "1. Analyze requirements and identify ambiguities.\n",
        "2. List coverage gaps in existing tests.\n",
        "3. Generate test cases: happy paths, edge cases, error paths, business rules.\n",
        "4. Separate unit tests from integration tests.\n",
        "5. Flag missing test data or dependencies.\n",
        "</tasks>\n",
        "\n",
        "<reasoning>\n",
        "Provide analysis in <analysis></analysis> tags.\n",
        "</reasoning>\n",
        "\n",
        "<output_format>\n",
        "<test_plan>\n",
        " <ambiguities></ambiguities>\n",
        " <coverage_gap></coverage_gap>\n",
        " <unit_tests>\n",
        "   <test>\n",
        "     <name></name>\n",
        "     <purpose></purpose>\n",
        "     <preconditions></preconditions>\n",
        "     <steps></steps>\n",
        "     <expected></expected>\n",
        "   </test>\n",
        " </unit_tests>\n",
        " <integration_tests>...</integration_tests>\n",
        " <test_data_needed></test_data_needed>\n",
        "</test_plan>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def judge_template(\n",
        "        submission: str,\n",
        "        criteria_weights: Optional[Dict[str, float]] = None\n",
        "    ) -> List[Dict[str, str]]:\n",
        "        \"\"\"LLM-as-Judge evaluation template\"\"\"\n",
        "        \n",
        "        if criteria_weights is None:\n",
        "            criteria_weights = {\n",
        "                \"Accuracy\": 0.40,\n",
        "                \"Completeness\": 0.30,\n",
        "                \"Actionability\": 0.20,\n",
        "                \"Communication\": 0.10\n",
        "            }\n",
        "        \n",
        "        weights_str = \"\\n\".join([\n",
        "            f\"{i+1}. {name} ({int(weight*100)}%)\" \n",
        "            for i, (name, weight) in enumerate(criteria_weights.items())\n",
        "        ])\n",
        "        \n",
        "        return [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a Principal Engineer evaluating AI-generated outputs for quality.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "<rubric>\n",
        "{weights_str}\n",
        "</rubric>\n",
        "\n",
        "<instructions>\n",
        "Score each criterion 1-5 with rationale.\n",
        "Calculate weighted total.\n",
        "Recommend: ACCEPT (â‰¥3.5), REVISE (2.5-3.4), REJECT (<2.5)\n",
        "</instructions>\n",
        "\n",
        "<submission>\n",
        "{submission}\n",
        "</submission>\n",
        "\n",
        "<output_format>\n",
        "<evaluation>\n",
        " <scores>\n",
        "   <criterion name=\"\">\n",
        "     <score></score>\n",
        "     <rationale></rationale>\n",
        "   </criterion>\n",
        " </scores>\n",
        " <weighted_total></weighted_total>\n",
        " <recommendation>ACCEPT/REVISE/REJECT</recommendation>\n",
        " <feedback></feedback>\n",
        "</evaluation>\n",
        "</output_format>\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 2. WORKFLOW AUTOMATION\n",
        "# ============================================\n",
        "\n",
        "@dataclass\n",
        "class ReviewResult:\n",
        "    \"\"\"Structured review result\"\"\"\n",
        "    content: str\n",
        "    score: Optional[float] = None\n",
        "    verdict: Optional[str] = None\n",
        "    passed_quality_gate: bool = False\n",
        "\n",
        "\n",
        "def automated_review_workflow(\n",
        "    code_diff: str,\n",
        "    repo_name: str,\n",
        "    quality_threshold: float = 3.5,\n",
        "    max_retries: int = 2\n",
        ") -> ReviewResult:\n",
        "    \"\"\"\n",
        "    Complete automated review workflow with quality gate.\n",
        "    \n",
        "    This demonstrates best practices:\n",
        "    - Template parameterization\n",
        "    - LLM-as-Judge validation\n",
        "    - Retry logic with feedback\n",
        "    - Structured output\n",
        "    \n",
        "    Args:\n",
        "        code_diff: Git diff to review\n",
        "        repo_name: Repository name for context\n",
        "        quality_threshold: Minimum score to accept (default 3.5)\n",
        "        max_retries: Maximum regeneration attempts\n",
        "    \n",
        "    Returns:\n",
        "        ReviewResult with content and quality metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            # Step 1: Generate review\n",
        "            review_messages = ReviewTemplate.code_review_template(\n",
        "                repo_name=repo_name,\n",
        "                code_diff=code_diff\n",
        "            )\n",
        "            \n",
        "            review_content = get_chat_completion(review_messages, temperature=0.0)\n",
        "            if not review_content:\n",
        "                raise ValueError(\"Review generation returned empty result\")\n",
        "            \n",
        "            # Step 2: Evaluate with judge\n",
        "            judge_messages = ReviewTemplate.judge_template(submission=review_content)\n",
        "            judge_result = get_chat_completion(judge_messages, temperature=0.0)\n",
        "            if not judge_result:\n",
        "                raise ValueError(\"Judge evaluation returned empty result\")\n",
        "            \n",
        "            # Step 3: Parse score (simplified - production would use XML parsing)\n",
        "            # This is a placeholder - implement proper XML parsing\n",
        "            score = 4.0  # Placeholder\n",
        "            \n",
        "            # Step 4: Decision\n",
        "            if score >= quality_threshold:\n",
        "                return ReviewResult(\n",
        "                    content=review_content,\n",
        "                    score=score,\n",
        "                    passed_quality_gate=True\n",
        "                )\n",
        "            elif attempt < max_retries:\n",
        "                print(f\"âš ï¸ Quality score {score} below threshold. Retry {attempt+1}/{max_retries}\")\n",
        "                continue\n",
        "            else:\n",
        "                return ReviewResult(\n",
        "                    content=review_content,\n",
        "                    score=score,\n",
        "                    passed_quality_gate=False\n",
        "                )\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error on attempt {attempt+1}: {e}\")\n",
        "            if attempt == max_retries:\n",
        "                return ReviewResult(\n",
        "                    content=f\"Error: {e}\",\n",
        "                    passed_quality_gate=False\n",
        "                )\n",
        "    \n",
        "    return ReviewResult(content=\"Max retries exceeded\", passed_quality_gate=False)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 3. EXAMPLE USAGE\n",
        "# ============================================\n",
        "\n",
        "print(\"ğŸ“¦ Production-Ready Template Library Loaded!\")\n",
        "print(\"\\nâœ… Available templates:\")\n",
        "print(\"   - ReviewTemplate.code_review_template()\")\n",
        "print(\"   - ReviewTemplate.security_review_template()\")\n",
        "print(\"   - ReviewTemplate.test_generation_template()\")\n",
        "print(\"   - ReviewTemplate.judge_template()\")\n",
        "print(\"\\nâœ… Workflow automation:\")\n",
        "print(\"   - automated_review_workflow()\")\n",
        "print(\"\\nğŸ’¡ Copy this cell to your project and customize!\")\n",
        "print(\"\\nğŸ“ Usage example:\")\n",
        "print(\"\"\"\n",
        "# Basic usage\n",
        "messages = ReviewTemplate.code_review_template(\n",
        "    tech_stack=\"React frontend\",\n",
        "    repo_name=\"my-app\",\n",
        "    code_diff=my_diff\n",
        ")\n",
        "result = get_chat_completion(messages)\n",
        "\n",
        "# With quality gate\n",
        "result = automated_review_workflow(\n",
        "    code_diff=my_diff,\n",
        "    repo_name=\"my-app\",\n",
        "    quality_threshold=4.0\n",
        ")\n",
        "if result.passed_quality_gate:\n",
        "    post_to_pr(result.content)\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); color: white; padding: 24px; border-radius: 12px; margin: 40px 0; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "    <h2 style=\"color: white; margin: 0; font-size: 1.8em; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">ğŸ¯ Suggested Break Point #4</h2>\n",
        "    <p style=\"margin: 8px 0; font-size: 1.1em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">~145 minutes elapsed â€¢ Final section!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">âœ… Completed:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Section 1: Code Review Automation Template</li>\n",
        "      <li>Section 2: Test Case Generation</li>\n",
        "      <li>Section 3: LLM-as-Judge Evaluation</li>\n",
        "      <li>All Hands-On Practice Activities (4 exercises)</li>\n",
        "      <li>Production-Ready Template Library</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">ğŸ‰ You've completed all core sections and exercises!</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(0,0,0,0.25); padding: 16px; border-radius: 8px; margin: 16px 0;\">\n",
        "    <p style=\"margin: 8px 0; font-size: 1.05em; font-weight: 600; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">â­ï¸ Final Topics:</p>\n",
        "    <ul style=\"margin: 8px 0; padding-left: 24px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">\n",
        "      <li>Section 4: Template Best Practices & Quality Checklist</li>\n",
        "      <li>Version control and maintenance strategies</li>\n",
        "      <li>Production deployment guidelines</li>\n",
        "      <li>CI/CD and automation integration patterns</li>\n",
        "    </ul>\n",
        "    <p style=\"margin: 12px 0 0 0; font-size: 0.95em; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\">â±ï¸ Remaining time: ~5-10 minutes (reading)</p>\n",
        "  </div>\n",
        "  \n",
        "  <div style=\"background: rgba(255,255,255,0.95); padding: 14px; border-radius: 8px; margin: 16px 0; text-align: center; color: #1e293b;\">\n",
        "    <p style=\"margin: 0; font-weight: bold; font-size: 1.1em; color: #1e293b;\">ğŸ“Œ BOOKMARK TO RESUME:</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 1.15em; font-weight: bold; color: #0f172a;\">\"Section 4: Template Best Practices\"</p>\n",
        "  </div>\n",
        "  \n",
        "  <p style=\"text-align: center; margin: 16px 0 0 0; font-size: 0.9em; text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\">\n",
        "    ğŸ’¡ <em>Nearly done! The final section covers deployment best practices and is mostly reading.</em>\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Section 4: Template Best Practices & Quality Checklist\n",
        "\n",
        "### Quality Checklist Before Deployment\n",
        "\n",
        "Before using a prompt template in production, validate it meets these standards:\n",
        "\n",
        "#### âœ… Role & Context\n",
        "- [ ] **Role description** matches task scope and domain expertise\n",
        "- [ ] **Expertise level** is appropriate (Junior/Senior/Principal)\n",
        "- [ ] **Domain specification** is clear (Backend/Frontend/Security/Performance)\n",
        "- [ ] **Context** includes necessary background (repo, service, requirements)\n",
        "\n",
        "#### âœ… Instructions & Structure\n",
        "- [ ] **Tasks decomposed** into explicit, numbered steps\n",
        "- [ ] **Required outputs** are clearly specified\n",
        "- [ ] **XML/structured tags** used for organization (`<context>`, `<tasks>`, etc.)\n",
        "- [ ] **Examples provided** where format is ambiguous\n",
        "\n",
        "#### âœ… Reasoning & Transparency\n",
        "- [ ] **Chain-of-thought** requested for complex analysis\n",
        "- [ ] **Inner monologue** tagged if reasoning should be separated from output\n",
        "- [ ] **Evidence required** for all claims (line numbers, specific quotes)\n",
        "- [ ] **Rationale requested** for subjective decisions\n",
        "\n",
        "#### âœ… Output Format\n",
        "- [ ] **Structured format** defined (XML, JSON, or clear template)\n",
        "- [ ] **Severity/priority** levels standardized across team\n",
        "- [ ] **Output is parseable** by automation tools if needed\n",
        "- [ ] **Format examples** provided in prompt or documentation\n",
        "\n",
        "#### âœ… Evaluation & Quality\n",
        "- [ ] **LLM-as-Judge rubric** defined with weighted criteria\n",
        "- [ ] **Acceptance thresholds** established (e.g., score â‰¥ 3.5)\n",
        "- [ ] **Failure modes** identified with fallback strategies\n",
        "- [ ] **Quality metrics** tracked over time\n",
        "\n",
        "#### âœ… Parameterization & Reuse\n",
        "- [ ] **Variables identified** and marked with `{{placeholders}}`\n",
        "- [ ] **Template documented** with parameter descriptions\n",
        "- [ ] **Usage examples** provided for team members\n",
        "- [ ] **Default values** specified where appropriate\n",
        "\n",
        "#### âœ… Testing & Validation\n",
        "- [ ] **Tested on multiple scenarios** (happy path, edge cases, errors)\n",
        "- [ ] **Peer reviewed** by subject matter experts\n",
        "- [ ] **Failure cases** tested (what happens with bad input?)\n",
        "- [ ] **Performance measured** (latency, token usage, cost)\n",
        "\n",
        "#### âœ… Team Alignment\n",
        "- [ ] **Standards match** team conventions (severity labels, output format)\n",
        "- [ ] **Language/tone** appropriate for team culture\n",
        "- [ ] **Integration points** defined (CI/CD, IDE, chat tools)\n",
        "- [ ] **Feedback mechanism** established for continuous improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“ Template Versioning & Maintenance\n",
        "\n",
        "**Treat prompts like code** - version control and track changes!\n",
        "\n",
        "#### Version Control Structure\n",
        "```\n",
        "prompts/\n",
        "â”œâ”€â”€ code-review/\n",
        "â”‚   â”œâ”€â”€ v1.0-baseline.md\n",
        "â”‚   â”œâ”€â”€ v1.1-added-security-focus.md\n",
        "â”‚   â”œâ”€â”€ v2.0-restructured-output.md\n",
        "â”‚   â””â”€â”€ CHANGELOG.md\n",
        "â”œâ”€â”€ test-generation/\n",
        "â”‚   â”œâ”€â”€ v1.0-baseline.md\n",
        "â”‚   â””â”€â”€ CHANGELOG.md\n",
        "â””â”€â”€ llm-as-judge/\n",
        "    â”œâ”€â”€ code-review-judge-v1.0.md\n",
        "    â””â”€â”€ CHANGELOG.md\n",
        "```\n",
        "\n",
        "#### CHANGELOG Example\n",
        "```markdown\n",
        "## Code Review Template - Changelog\n",
        "\n",
        "### v2.0 (2024-03-15)\n",
        "**Breaking Changes:**\n",
        "- Changed output format from plain text to XML\n",
        "- Renamed severity levels: blockerâ†’critical, nitâ†’trivial\n",
        "\n",
        "**Improvements:**\n",
        "- Added <inner_monologue> for reasoning transparency\n",
        "- Increased evidence requirement (must cite line numbers)\n",
        "- Added performance impact estimation\n",
        "\n",
        "**Metrics:**\n",
        "- LLM-as-Judge avg score: 4.2 â†’ 4.6\n",
        "- False positive rate: 12% â†’ 8%\n",
        "- User satisfaction: 3.8 â†’ 4.3\n",
        "\n",
        "### v1.1 (2024-02-20)\n",
        "**Improvements:**\n",
        "- Added security-specific guidelines (OWASP Top 10)\n",
        "- Increased token limit to handle larger diffs\n",
        "\n",
        "**Metrics:**\n",
        "- Caught 15% more security issues in testing\n",
        "```\n",
        "\n",
        "#### When to Version Bump\n",
        "- **Major (v1 â†’ v2)**: Breaking changes to output format, role changes\n",
        "- **Minor (v1.0 â†’ v1.1)**: Added capabilities, new guidelines\n",
        "- **Patch (v1.1.0 â†’ v1.1.1)**: Bug fixes, clarity improvements\n",
        "\n",
        "#### A/B Testing Prompts\n",
        "```python\n",
        "# Compare two prompt versions\n",
        "results_v1 = run_reviews_with_template(\"code-review-v1.0.md\", test_prs)\n",
        "results_v2 = run_reviews_with_template(\"code-review-v2.0.md\", test_prs)\n",
        "\n",
        "# Evaluate with LLM-as-Judge\n",
        "scores_v1 = [judge(r) for r in results_v1]\n",
        "scores_v2 = [judge(r) for r in results_v2]\n",
        "\n",
        "print(f\"v1.0 avg score: {mean(scores_v1)}\")  # 3.8\n",
        "print(f\"v2.0 avg score: {mean(scores_v2)}\")  # 4.3\n",
        "# Deploy v2.0!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸš€ Extension & Automation Ideas\n",
        "\n",
        "Ready to take it further? Here are real-world integration patterns:\n",
        "\n",
        "#### 1. CI/CD Pipeline Integration\n",
        "```yaml\n",
        "# .github/workflows/ai-code-review.yml\n",
        "name: AI Code Review\n",
        "\n",
        "on: pull_request\n",
        "\n",
        "jobs:\n",
        "  ai-review:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - name: Get PR diff\n",
        "        run: gh pr diff ${{ github.event.pull_request.number }} > diff.txt\n",
        "      \n",
        "      - name: Run AI Review\n",
        "        run: python scripts/ai_review.py --diff diff.txt --template prompts/code-review-v2.0.md\n",
        "      \n",
        "      - name: Evaluate with Judge\n",
        "        run: python scripts/judge_review.py --review review.json\n",
        "      \n",
        "      - name: Post if High Quality (score â‰¥ 4.0)\n",
        "        if: steps.judge.outputs.score >= 4.0\n",
        "        run: gh pr comment ${{ github.event.pull_request.number }} --body-file review.md\n",
        "```\n",
        "\n",
        "#### 2. IDE Integration (VS Code Extension)\n",
        "```javascript\n",
        "// AI Review on Save\n",
        "vscode.workspace.onDidSaveTextDocument((doc) => {\n",
        "  const diff = getDiff(doc);\n",
        "  const template = loadTemplate('code-review-v2.0.md');\n",
        "  const review = callAI(template, diff);\n",
        "  const score = judgeReview(review);\n",
        "  \n",
        "  if (score >= 3.5) {\n",
        "    showInlineComments(review);\n",
        "  }\n",
        "});\n",
        "```\n",
        "\n",
        "#### 3. Slack Bot Integration\n",
        "```python\n",
        "@slack_app.command(\"/ai-review\")\n",
        "def review_command(ack, body, say):\n",
        "    pr_url = body['text']\n",
        "    diff = github.get_pr_diff(pr_url)\n",
        "    \n",
        "    review = generate_review(diff, template='code-review-v2.0.md')\n",
        "    score = judge_review(review)\n",
        "    \n",
        "    if score >= 4.0:\n",
        "        say(f\"âœ… AI Review (score: {score}/5.0):\\n{review}\")\n",
        "    else:\n",
        "        say(f\"âš ï¸ Low confidence review (score: {score}/5.0). Human review recommended.\")\n",
        "```\n",
        "\n",
        "#### 4. Pre-Commit Hook\n",
        "```bash\n",
        "#!/bin/bash\n",
        "# .git/hooks/pre-commit\n",
        "\n",
        "# Get staged changes\n",
        "git diff --cached > /tmp/staged.diff\n",
        "\n",
        "# Run AI review\n",
        "python scripts/quick_review.py /tmp/staged.diff\n",
        "\n",
        "# Ask for confirmation if issues found\n",
        "if [ $? -ne 0 ]; then\n",
        "    read -p \"AI found issues. Continue? (y/n) \" -n 1 -r\n",
        "    echo\n",
        "    if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n",
        "        exit 1\n",
        "    fi\n",
        "fi\n",
        "```\n",
        "\n",
        "#### 5. Test Generation in Sprint Planning\n",
        "```python\n",
        "def generate_test_plan(feature_spec: str) -> TestPlan:\n",
        "    \"\"\"Generate test plan during sprint planning\"\"\"\n",
        "    \n",
        "    # Generate tests\n",
        "    test_plan = generate_tests(\n",
        "        requirements=feature_spec,\n",
        "        existing_tests=get_current_suite(),\n",
        "        template='test-generation-v1.0.md'\n",
        "    )\n",
        "    \n",
        "    # Validate coverage\n",
        "    judge_result = evaluate_test_plan(test_plan)\n",
        "    \n",
        "    if judge_result.score < 3.5:\n",
        "        # Regenerate with feedback\n",
        "        test_plan = generate_tests(\n",
        "            requirements=feature_spec,\n",
        "            existing_tests=get_current_suite(),\n",
        "            template='test-generation-v1.0.md',\n",
        "            previous_feedback=judge_result.feedback\n",
        "        )\n",
        "    \n",
        "    return test_plan\n",
        "\n",
        "# Use in planning:\n",
        "story_points = estimate_from_test_count(test_plan.total_tests)\n",
        "```\n",
        "\n",
        "#### 6. Continuous Monitoring Dashboard\n",
        "```python\n",
        "# Track prompt performance over time\n",
        "dashboard = {\n",
        "    \"code_review_v2.0\": {\n",
        "        \"avg_judge_score\": 4.3,\n",
        "        \"usage_count\": 1247,\n",
        "        \"acceptance_rate\": 0.89,\n",
        "        \"avg_latency_ms\": 3200,\n",
        "        \"cost_per_review\": 0.04\n",
        "    },\n",
        "    \"test_generation_v1.0\": {\n",
        "        \"avg_judge_score\": 3.9,\n",
        "        \"usage_count\": 543,\n",
        "        \"acceptance_rate\": 0.76,\n",
        "        \"avg_latency_ms\": 4100,\n",
        "        \"cost_per_plan\": 0.08\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "#### ğŸ¯ Start Small, Scale Gradually\n",
        "1. **Week 1**: Use templates manually in code reviews\n",
        "2. **Week 2**: Add LLM-as-Judge validation\n",
        "3. **Week 3**: Integrate into one repo's CI/CD\n",
        "4. **Month 2**: Expand to team repos, collect metrics\n",
        "5. **Month 3**: Optimize based on feedback, version templates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ˆ Track Your Progress\n",
        "\n",
        "### Self-Assessment Questions\n",
        "\n",
        "After completing Module 3, reflect on these questions:\n",
        "\n",
        "1. **Can I design code review prompts with task decomposition?**\n",
        "   - Do you understand how to break reviews into steps (analyze â†’ assess â†’ suggest â†’ verdict)?\n",
        "   - Can you create role prompts that match domain expertise?\n",
        "\n",
        "2. **Can I create test generation templates that identify coverage gaps?**\n",
        "   - Can you design prompts that compare requirements vs existing tests?\n",
        "   - Do you know how to structure test specifications (purpose, preconditions, steps, expected)?\n",
        "\n",
        "3. **Can I build LLM-as-Judge rubrics with weighted criteria?**\n",
        "   - Can you define evaluation criteria appropriate for your domain?\n",
        "   - Do you know how to set acceptance thresholds and provide feedback?\n",
        "\n",
        "4. **Can I parameterize templates for reuse?**\n",
        "   - Do you know how to identify and mark template variables (`{{placeholder}}`)?\n",
        "   - Can you document template parameters for team use?\n",
        "\n",
        "5. **Can I refine templates based on feedback?**\n",
        "   - Do you understand version control for prompts?\n",
        "   - Can you A/B test different prompt versions?\n",
        "\n",
        "6. **Do I understand how to prepare prompts for CI/CD integration?**\n",
        "   - Can you design structured outputs that tools can parse?\n",
        "   - Do you know how to chain prompts (generate â†’ judge â†’ act)?\n",
        "\n",
        "### âœ… Check Off Your Learning Objectives\n",
        "\n",
        "Review the module objectives and check what you've mastered:\n",
        "\n",
        "- [ ] **Implement SDLC-focused prompts** for code review, test generation, and documentation\n",
        "- [ ] **Design reusable templates** with parameterized sections for specific workflows\n",
        "- [ ] **Evaluate prompt effectiveness** using LLM-as-Judge rubrics\n",
        "- [ ] **Refine and adapt templates** based on feedback and edge cases\n",
        "- [ ] **Apply best practices** for version control, parameterization, and quality assurance\n",
        "\n",
        "<div style=\"margin-top:16px; color:#065f46; padding:12px; background:#d1fae5; border-radius:6px; border-left:4px solid #10b981;\">\n",
        "<strong>ğŸ’¡ Self-Check:</strong> <br><br>\n",
        "If you can confidently check off 4+ objectives, you're ready to apply these techniques in production!<br>\n",
        "If not, revisit the sections where you feel less confident and try the practice activities again.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŠ Module 3 Complete!\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #8b5cf6 0%, #6d28d9 100%); padding: 32px; border-radius: 12px; color: white; text-align: center; margin: 32px 0;\">\n",
        "  <h2 style=\"margin: 0 0 16px 0; color: white;\">ğŸ‰ Congratulations!</h2>\n",
        "  <p style=\"font-size: 1.2em; margin: 0; opacity: 0.95;\">\n",
        "    You've mastered production-ready prompt engineering for SDLC tasks!\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### What You've Accomplished\n",
        "\n",
        "- âœ… **Applied prompt engineering tactics** to real SDLC scenarios\n",
        "- âœ… **Built code review templates** with decomposition and chain-of-thought\n",
        "- âœ… **Created test generation workflows** that identify coverage gaps\n",
        "- âœ… **Implemented LLM-as-Judge** for quality assurance\n",
        "- âœ… **Designed reusable templates** with parameterization\n",
        "- âœ… **Learned best practices** for production deployment\n",
        "\n",
        "### ğŸ”‘ Key Takeaways\n",
        "\n",
        "**1. Combine Tactics Strategically**\n",
        "- Real-world prompts use multiple tactics together\n",
        "- **Role + Structure + CoT + Judge = Robust workflow**\n",
        "- Each tactic amplifies the others\n",
        "\n",
        "**2. Templates Enable Scale**\n",
        "- Parameterized templates reduce prompt drift\n",
        "- Version control ensures consistency over time\n",
        "- Team collaboration becomes possible and repeatable\n",
        "- Documentation turns templates into shared assets\n",
        "\n",
        "**3. Quality Assurance Matters**\n",
        "- LLM-as-Judge catches issues early, before they reach production\n",
        "- Rubrics encode team standards in executable form\n",
        "- Iterative refinement improves quality over time\n",
        "- Metrics provide objective feedback loops\n",
        "\n",
        "**4. Prepare for Production**\n",
        "- Test templates thoroughly on diverse scenarios\n",
        "- Document parameters and usage clearly\n",
        "- Monitor performance (latency, cost, quality scores)\n",
        "- Iterate based on real-world feedback\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š What's Next?\n",
        "\n",
        "**Apply What You've Learned:**\n",
        "\n",
        "1. **Create templates for your team** \n",
        "   - Start with code review or test generation\n",
        "   - Adapt examples from this module to your domain\n",
        "   - Share with 2-3 teammates for feedback\n",
        "\n",
        "2. **Integrate into your workflow**\n",
        "   - Begin with manual use in daily work\n",
        "   - Add to CI/CD when templates are stable\n",
        "   - Consider IDE extensions or Slack bots\n",
        "\n",
        "3. **Collect feedback and iterate**\n",
        "   - Track what works and what doesn't\n",
        "   - Use LLM-as-Judge for objective metrics\n",
        "   - Version templates as they improve\n",
        "\n",
        "4. **Share with your team**\n",
        "   - Build a template library in your repo\n",
        "   - Document usage patterns and best practices\n",
        "   - Create a feedback channel for continuous improvement\n",
        "\n",
        "**Continue Learning:**\n",
        "\n",
        "- **Module 4**: Integration - Connect prompts to your development workflow (CI/CD, IDE, APIs)\n",
        "- **Advanced Topics**: Multi-agent systems, prompt optimization, cost/latency tradeoffs\n",
        "- **Community**: Share your templates and learn from others\n",
        "\n",
        "---\n",
        "\n",
        "<div style=\"margin-top:24px; color:#1e3a8a; padding:16px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6;\">\n",
        "<strong>ğŸš€ Ready for Real-World Impact:</strong> <br><br>\n",
        "You now have the skills to design production-ready prompt engineering workflows for software development. The templates you've learned aren't just exercisesâ€”they're patterns used by engineering teams at scale.<br><br>\n",
        "Go build something amazing! ğŸ¯\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ™ Thank You!\n",
        "\n",
        "Thank you for completing Module 3! Your journey from learning individual tactics to building complete workflows demonstrates real growth in prompt engineering expertise.\n",
        "\n",
        "**Questions or feedback?** Open an issue in the repository or reach out to the maintainers. We'd love to hear how you're applying these techniques!\n",
        "\n",
        "**Next:** [Continue to Module 4: Integration](../module-04-integration/README.md)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
