{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.2: Roles and Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect** | **Details** |\n",
    "|-------------|-------------|\n",
    "| **Goal** | Master role prompting personas and structured input patterns. |\n",
    "| **Time** | ~20 minutes |\n",
    "| **Prerequisites** | Complete Section 2.1 and confirm your environment is configured. |\n",
    "| **Next Steps** | Continue to Section 2.3: Patterns for Reasoning |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Quick Setup Check\n",
    "\n",
    "Since you completed Section 1, setup is already done! We just need to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup check - imports setup_utils\n",
    "try:\n",
    "    import importlib\n",
    "    import setup_utils\n",
    "    importlib.reload(setup_utils)\n",
    "    from setup_utils import *\n",
    "    print(f\"‚úÖ Setup loaded! Using {AVAILABLE_PROVIDERS} with {get_default_model()}\")\n",
    "    print(\"üöÄ Ready to build test generation templates!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Setup not found!\")\n",
    "    print(\"üí° Please run 2.1-setup-and-foundations.ipynb first to set up your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üé≠ Tactic 1: Role Prompting\n",
    "\n",
    "**Transform AI into specialized domain experts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use role prompting as a way to get AI models to emulate certain styles in writing, speak in a certain voice, or guide the complexity of their answers. Role prompting can also make AI models better at performing math or logic tasks.\n",
    "\n",
    "Using the `system` parameter for role prompting is the most powerful way to transform any LLM from a general assistant into your virtual domain expert. The right role enhances accuracy in complex scenarios, tailors the communication tone, and improves focus by keeping the LLM within the bounds of your task's specific requirements.\n",
    "\n",
    "In coding scenarios, role prompting helps with tasks like specific refactoring requirements (e.g., \"Extract this into separate classes following SOLID principles\"), detailed code review criteria (e.g., \"Focus on security vulnerabilities and performance bottlenecks\"), and precise testing specifications (e.g., \"Generate unit tests with 90% coverage including edge cases\").\n",
    "\n",
    "*Reference: [Claude Documentation - System Prompts](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/system-prompts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of asking for a generic response, adopt a specific persona\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a code reviewer. Analyze the provided code and give exactly 3 specific feedback points: 1 about code structure, 1 about naming conventions, and 1 about potential improvements. Format each point as a bullet with the category in brackets.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"def calc(x, y): return x + y if x > 0 and y > 0 else 0\",\n",
    "    }\n",
    "]\n",
    "response = get_chat_completion(messages)\n",
    "\n",
    "print(\"CODE REVIEWER PERSONA RESULT:\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Software Engineering Personas\n",
    "\n",
    "The below cells show how different engineering personas provide specialized expertise for code reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Engineer Persona\n",
    "security_messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a security engineer. Review code for security vulnerabilities and provide specific recommendations.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Review this login function:\n",
    "        \n",
    "def login(username, password):\n",
    "    query = f\"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'\"\n",
    "    result = database.execute(query)\n",
    "    return result\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "security_response = get_chat_completion(security_messages)\n",
    "print(\"üîí SECURITY ENGINEER ANALYSIS:\")\n",
    "print(security_response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéØ Try It Yourself: Role Prompting\n",
    "\n",
    "**Common Misconception:** Generic code review requests produce the same quality results regardless of expertise focus.\n",
    "\n",
    "**The Reality:** Different personas catch different issues. A security engineer spots vulnerabilities a performance engineer might miss.\n",
    "\n",
    "**Your Task:** Below is a generic code review prompt. Fix it by:\n",
    "1. Adding an appropriate role in the `system` message\n",
    "2. Choosing between: Security Engineer, Performance Engineer, or QA Engineer\n",
    "3. Specifying what that persona should focus on\n",
    "\n",
    "Compare the generic review with your specialized review!\n",
    "\n",
    "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
    "<strong>üí° Tip:</strong> If you see long AI responses and the output shows \"Output is truncated. View as a scrollable element\" - <strong>click that link</strong> to see the full response in a scrollable view!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to review\n",
    "code_to_review = \"\"\"\n",
    "def get_user_data(user_id):\n",
    "    query = f\"SELECT * FROM users WHERE id = {user_id}\"\n",
    "    results = db.execute(query).fetchall()\n",
    "    return results\n",
    "\"\"\"\n",
    "\n",
    "# ‚ùå BAD: Generic review (no specific expertise)\n",
    "bad_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Review this code:\\n\\n{code_to_review}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "bad_response = get_chat_completion(bad_messages)\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERIC REVIEW (No Role):\")\n",
    "print(\"=\" * 70)\n",
    "print(bad_response)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ‚úÖ YOUR TURN: Add a role and specific focus\n",
    "# TODO: Uncomment and complete this section\n",
    "# Choose a role: Security Engineer, Performance Engineer, or QA Engineer\n",
    "good_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a Security Engineer. Review code specifically for security vulnerabilities including SQL injection, authentication issues, and data exposure risks. Provide severity ratings.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Review this code:\\n\\n{code_to_review}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "good_response = get_chat_completion(good_messages)\n",
    "print(\"=\" * 70)\n",
    "print(\"SECURITY ENGINEER REVIEW (With Role):\")\n",
    "print(\"=\" * 70)\n",
    "print(good_response)\n",
    "\n",
    "print(\"\\nüí° Notice the difference? The security engineer immediately spots SQL injection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### üìã Tactic 2: Structured Inputs\n",
    "\n",
    "**Organize complex scenarios with delimiters**\n",
    "\n",
    "When your prompts involve multiple components like context, instructions, and examples, it can be a game-changer to use delimiters that clearly separate these parts. Delimiters help AI models parse your prompts more accurately, leading to higher-quality outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin:16px 0; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6; color:#1f2937;\">\n",
    "<style>\n",
    "code {\n",
    "  font-family: Consolas,\"courier new\";\n",
    "  color:rgb(238, 13, 13);\n",
    "  background-color: #f1f1f1;\n",
    "  padding: 2px;\n",
    "  font-size: 110%;\n",
    "}\n",
    "</style>\n",
    "<strong style=\"color:#1e40af;\">üìå Building on Previous Tactics:</strong><br><br>\n",
    "While <em>Tactics 0</em> and <em>1</em> used basic structure (separating system/user messages and organizing information in JSON format), Tactic 2 takes structure further by using explicit delimiters <em>within</em> your prompt content to organize complex, multi-part information.\n",
    "<br><br>\n",
    "<strong>Note:</strong> JSON format is required to pass messages to the <code>get_chat_completion()</code> function - that's the API's message structure. Tactic 2 adds delimiters <em>inside</em> the message content itself for better organization.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Delimiters**\n",
    "\n",
    "* Simple Delimiters\n",
    "  - Use `###` or `#` to create visual section headers within your prompts\n",
    "  - These act like markdown headers, making sections distinct and easy to identify\n",
    "  - Example: `### CODE ###` followed by code, then `### REQUIREMENTS ###` followed by requirements\n",
    "  - The LLM recognizes these as visual separators that indicate different content sections\n",
    "\n",
    "* XML Delimiters\n",
    "  - More powerful and precise than simple delimiters\n",
    "  - LLMs are extensively trained on XML/HTML during their training, making them particularly good at parsing tagged content\n",
    "  - You can create your own tag names that are descriptive (e.g., `<user_input>`, `<system_logs>`, `<test_cases>`)\n",
    "  - Tag names should be meaningful and describe their content - while you have flexibility, clear names improve results\n",
    "  - Common effective tags: `<instructions>`, `<example>`, `<context>`, `<requirements>`, `<code>`, `<output>`\n",
    "  - LLMs have seen standard HTML/XML tags during training (like `<document>`, `<source>`, `<content>`), which is why the Claude documentation recommends certain tags\n",
    "\n",
    "**Why This Works:**\n",
    "- **Clarity:** Clearly separate different parts of your prompt and ensure your prompt is well structured\n",
    "- **Accuracy:** Reduce errors caused by AI models misinterpreting parts of your prompt  \n",
    "- **Flexibility:** Easily find, add, remove, or modify parts of your prompt without rewriting everything\n",
    "- **Parseability:** Having the AI use delimiters in its output makes it easier to extract specific parts of its response\n",
    "\n",
    "In multi-file refactoring, separating different files being modified becomes essential using delimiters like `<original_file>` and `<refactored_file>`. You can distinguish between `<requirements>` and `<existing_code>`, organize `<test_cases>`, `<edge_cases>`, and `<error_cases>`, and structure pull request reviews with `<pr_description>`, `<code_changes>`, and `<test_changes>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple example showing how delimiters clarify different sections of your prompt by using `###` as delimiters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using delimiters to refactor code\n",
    "function_code = \"def process_data(items): return [x.upper() for x in items if len(x) > 3]\"\n",
    "requirements = \"Follow PEP 8 style guide, add type hints, improve readability\"\n",
    "\n",
    "delimiter_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a Python code reviewer. Provide only the refactored code without explanations.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Refactor this function based on the requirements:\n",
    "\n",
    "### CODE ###\n",
    "{function_code}\n",
    "###\n",
    "\n",
    "### REQUIREMENTS ###\n",
    "{requirements}\n",
    "###\n",
    "\n",
    "Return only the improved function code.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "delimiter_response = get_chat_completion(delimiter_messages)\n",
    "print(\"üîß REFACTORED CODE:\")\n",
    "print(delimiter_response)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-File Scenarios with XML Delimiters\n",
    "\n",
    "One of the most powerful techniques for complex software development tasks is using XML tags and delimiters to structure your prompts. This approach dramatically improves AI accuracy and reduces misinterpretation.\n",
    "\n",
    "**Key Benefits:**\n",
    "- **Clarity**: Clearly separate different parts of your prompt (instructions, context, examples)\n",
    "- **Accuracy**: Reduce errors caused by AI misinterpreting parts of your prompt\n",
    "- **Flexibility**: Easily modify specific sections without rewriting everything\n",
    "- **Parseability**: Structure AI outputs for easier post-processing\n",
    "\n",
    "**Best Practices:**\n",
    "- Use tags like `<instructions>`, `<example>`, and `<formatting>` to clearly separate different parts\n",
    "- Be consistent with tag names throughout your prompts\n",
    "- Nest tags hierarchically: `<outer><inner></inner></outer>` for structured content\n",
    "- Choose meaningful tag names that describe their content\n",
    "\n",
    "**Reference**: Learn more about XML tagging best practices in the [Claude Documentation on XML Tags](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In coding scenarios, delimiters become essential for:\n",
    "\n",
    "- **Multi-file refactoring** - Separate different files being modified: `<original_file>`, `<refactored_file>`\n",
    "- **Code vs. requirements** - Distinguish between `<requirements>` and `<existing_code>`\n",
    "- **Test scenarios** - Organize `<test_cases>`, `<edge_cases>`, `<error_cases>`\n",
    "- **Pull request reviews** - Structure `<pr_description>`, `<code_changes>`, `<test_changes>`\n",
    "\n",
    "The below cell demonstrates multi-file refactoring using XML delimiters to organize complex codebases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-file analysis with XML delimiters\n",
    "multifile_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a software architect. Analyze the provided files and identify architectural concerns.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "<user_model>\n",
    "class User:\n",
    "    def __init__(self, email, password):\n",
    "        self.email = email\n",
    "        self.password = password\n",
    "    \n",
    "    def save(self):\n",
    "        # Save to database\n",
    "        pass\n",
    "</user_model>\n",
    "\n",
    "<user_controller>\n",
    "from flask import Flask, request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/register', methods=['POST'])\n",
    "def register():\n",
    "    email = request.form['email']\n",
    "    password = request.form['password']\n",
    "    user = User(email, password)\n",
    "    user.save()\n",
    "    return \"User registered\"\n",
    "</user_controller>\n",
    "\n",
    "<requirements>\n",
    "- Follow separation of concerns\n",
    "- Add input validation\n",
    "- Implement proper error handling\n",
    "- Use dependency injection\n",
    "</requirements>\n",
    "\n",
    "Provide architectural recommendations for improving this code structure.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "multifile_response = get_chat_completion(multifile_messages)\n",
    "print(\"üèóÔ∏è ARCHITECTURAL ANALYSIS:\")\n",
    "print(multifile_response)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéØ Try It Yourself: Structured Inputs\n",
    "\n",
    "**Common Misconception:** AI can parse messy, unorganized prompts just as well as structured ones.\n",
    "\n",
    "**The Reality:** Delimiters dramatically reduce misinterpretation and improve accuracy, especially with complex multi-part inputs.\n",
    "\n",
    "**Your Task:** Below is a messy prompt with requirements, code, and context all jumbled together. Reorganize it using XML tags:\n",
    "- `<requirements>` for what needs to be done\n",
    "- `<current_code>` for the existing implementation\n",
    "- `<context>` for background information\n",
    "\n",
    "Run both versions and see how structure improves the analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BAD: Messy, unstructured prompt\n",
    "bad_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "I need to refactor this function: def send_email(to, subject, body): smtp.send(to, subject, body)\n",
    "\n",
    "The requirements are: add error handling, implement retry logic with exponential backoff, add logging, and validate email format. This is for a high-traffic notification service that sends 10k emails per hour. The current implementation fails silently when SMTP server is down and doesn't validate email addresses. We need 99.9% delivery rate.\n",
    "\n",
    "Please refactor this code following best practices.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "bad_response = get_chat_completion(bad_messages)\n",
    "print(\"=\" * 70)\n",
    "print(\"MESSY PROMPT RESULT:\")\n",
    "print(\"=\" * 70)\n",
    "print(bad_response)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ‚úÖ YOUR TURN: Restructure with XML tags\n",
    "# TODO: Uncomment and complete this section\n",
    "# good_messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"\"\"\n",
    "# <current_code>\n",
    "# def send_email(to, subject, body):\n",
    "#     smtp.send(to, subject, body)\n",
    "# </current_code>\n",
    "# \n",
    "# <context>\n",
    "# This is for a high-traffic notification service that sends 10k emails per hour.\n",
    "# Current implementation fails silently when SMTP server is down.\n",
    "# Email addresses are not validated.\n",
    "# We need 99.9% delivery rate.\n",
    "# </context>\n",
    "# \n",
    "# <requirements>\n",
    "# 1. Add error handling\n",
    "# 2. Implement retry logic with exponential backoff\n",
    "# 3. Add logging for monitoring\n",
    "# 4. Validate email format before sending\n",
    "# 5. Follow Python best practices\n",
    "# </requirements>\n",
    "# \n",
    "# Please refactor this code addressing all requirements.\n",
    "# \"\"\"\n",
    "#     }\n",
    "# ]\n",
    "# \n",
    "# good_response = get_chat_completion(good_messages)\n",
    "# print(\"=\" * 70)\n",
    "# print(\"STRUCTURED PROMPT RESULT:\")\n",
    "# print(\"=\" * 70)\n",
    "# print(good_response)\n",
    "# \n",
    "# print(\"\\nüí° Notice how the structured version produces more organized, complete refactoring!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<div style=\"margin:20px 0; padding:16px 24px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:10px; color:#fff; text-align:center; box-shadow:0 4px 15px rgba(102,126,234,0.3);\">\n  <strong style=\"font-size:1.05em;\">‚ú® Great work! Learning sticks better with breaks.</strong><br>\n  <span style=\"font-size:0.92em; opacity:0.95; margin-top:4px; display:block;\">Step away for 5 minutes‚Äîstretch, breathe, and return ready for the next tactics.</span>\n</div>\n\n---\n\n<div style=\"margin:24px 0; padding:20px 24px; background:linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius:12px; border-left:5px solid #8b5cf6; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n  <div style=\"color:#1e293b; font-size:0.85em; font-weight:600; text-transform:uppercase; letter-spacing:1px; margin-bottom:8px;\">‚è≠Ô∏è Next Section</div>\n  <div style=\"color:#0f172a; font-size:1.15em; font-weight:700; margin-bottom:6px;\">Section 2.3: Patterns for Reasoning</div>\n  <div style=\"color:#475569; font-size:0.95em; line-height:1.5; margin-bottom:12px;\">Learn few-shot exemplars, chain-of-thought reasoning, and reference citations for reliable responses.</div>\n  <a href=\"./2.3-patterns-for-reasoning.ipynb\" style=\"display:inline-block; padding:8px 16px; background:#8b5cf6; color:#fff; text-decoration:none; border-radius:6px; font-weight:600; font-size:0.9em; transition:all 0.2s;\">Continue to Section 2.3 ‚Üí</a>\n</div>"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}