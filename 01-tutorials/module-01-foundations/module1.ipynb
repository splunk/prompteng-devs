{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: Prompt Engineering for Developers\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "By the end of this hands-on tutorial, you'll master the essential prompt engineering skills that transform AI assistants into powerful development tools. You'll learn to write precise prompts that consistently deliver production-ready code, thorough code reviews, and effective debugging assistance.\n",
        "\n",
        "**What you'll accomplish:**\n",
        "- ‚úÖ Set up a local development environment for prompt engineering\n",
        "- ‚úÖ Master foundational prompting techniques (zero-shot, few-shot, chain-of-thought)\n",
        "- ‚úÖ Build advanced prompt structures that eliminate hallucinations\n",
        "- ‚úÖ Create custom commands for code review, debugging, and API integration\n",
        "- ‚úÖ Deploy a working prompt engineering toolkit for your daily development workflow\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "### Required Knowledge\n",
        "- Basic familiarity with Python (variables, functions, basic syntax)\n",
        "- Experience with any IDE (VS Code, Cursor, or similar)\n",
        "- Understanding of basic software development concepts\n",
        "\n",
        "### Required Setup\n",
        "- [ ] Python 3.8+ installed on your system\n",
        "- [ ] IDE with notebook support (VS Code or Cursor) or Google Collab \n",
        "- [ ] API access to either:\n",
        "  - GitHub Copilot (preferred for this tutorial)\n",
        "  - CircuIT APIs, or\n",
        "  - OpenAI API key\n",
        "\n",
        "### Time Required\n",
        "- Approximately 90 minutes total\n",
        "- Can be completed in 3 sessions of 30 minutes each\n",
        "\n",
        "## Tutorial Structure\n",
        "\n",
        "### Module 1: Foundation Setup (20 min)\n",
        "- Set up your development environment\n",
        "- Connect to AI models via API\n",
        "- Verify everything works with your first prompt\n",
        "- Understand the 4 core elements of effective prompts\n",
        "\n",
        "### Module 2: Core Prompting Techniques (30 min)\n",
        "- Master role prompting and personas\n",
        "- Use delimiters and structured inputs\n",
        "- Apply few-shot examples and chain-of-thought reasoning\n",
        "- Practice with real software engineering scenarios\n",
        "\n",
        "### Module 3: Advanced Software Engineering Applications (30 min)\n",
        "- Build prompts for code quality and refactoring\n",
        "- Create systematic testing and QA workflows\n",
        "- Design effective code review and debugging prompts\n",
        "- Develop API integration and documentation helpers\n",
        "\n",
        "### Module 4: Custom Command Integration (10 min)\n",
        "- Create reusable prompt templates\n",
        "- Set up custom commands for your AI assistant\n",
        "- Build a personal prompt engineering toolkit\n",
        "- Plan your next steps for continued learning\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Ready to Start?\n",
        "\n",
        "Let's begin by setting up your development environment and running your first successful prompt!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Module 1: Foundation Setup\n",
        "\n",
        "In this section, we'll get your development environment ready and help you understand what makes prompts effective.\n",
        "\n",
        "## Learning Outcomes for Module 1\n",
        "\n",
        "By the end of this section, you will:\n",
        "- [ ] Have a working Python environment with AI model access\n",
        "- [ ] Successfully execute your first structured prompt\n",
        "- [ ] Understand the 4 core elements that make prompts effective\n",
        "- [ ] Feel confident to move to advanced techniques\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.1: Install Required Dependencies\n",
        "\n",
        "Let's start by installing the packages we need for this tutorial.\n",
        "\n",
        "Run the cell below. You should see a success message when installation completes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    try:\n",
        "        # Install from requirements.txt\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
        "        print(\"‚úÖ SUCCESS! All dependencies installed successfully.\")\n",
        "        print(\"üì¶ Installed: openai, anthropic, python-dotenv, requests\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Installation failed: {e}\")\n",
        "        print(\"üí° Try running: pip install openai anthropic python-dotenv requests\")\n",
        "\n",
        "install_requirements()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "‚úÖ **Success!** You've installed the necessary Python packages.\n",
        "\n",
        "üí° **What just happened?** We installed libraries that let us communicate with AI models programmatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.2: Set Up API Connection\n",
        "\n",
        "Now let's connect to an AI model. We'll use GitHub Copilot through a local proxy (recommended) or you can use other options.\n",
        "\n",
        "Run these Python cells to set up authentication to the foundational LLM models and a helper for chat completions. There are two ways to setup authentication to access foundational LLM models for this course:\n",
        "\n",
        "- **Oprion A: GitHub Copilot API (local proxy)**: Recommended if you don't have OpenAI or CircuIT API access. Follow `GitHub-Copilot-2-API/README.md` to authenticate and start the local server, then run the \"GitHub Copilot (local proxy)\" setup cells below.\n",
        "\n",
        "- **Option B: OpenAI API**: If you have OpenAI API access, you can use the OpenAI connection cells provided later in this notebook.\n",
        "\n",
        "- **Option C: CircuIT APIs (Azure OpenAI)**: If you have CircuIT API access, you can use the CircuIT connection cells provided later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: GitHub Copilot (Recommended)\n",
        "\n",
        "If you have GitHub Copilot, this is the easiest option:\n",
        "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
        "<strong>üí° Note:</strong> <br><br>\n",
        "The GitHub Copilot API repository (<code style=\"background:#f3f4f6; padding:2px 6px; border-radius:3px; color:#dc2626;\">copilot-api</code>) used in this course is a fork of the original repository from <strong><a href=\"https://cto-github.cisco.com/xinyu3/copilot2api\">https://cto-github.cisco.com/xinyu3/copilot2api</a></strong>.\n",
        "</div>\n",
        "\n",
        "- Follow the setup steps in [https://github.com/snehangshu-splunk/copilot-api/blob/main/.github/README.md](https://github.com/snehangshu-splunk/copilot-api/blob/main/.github/README.md) to:\n",
        "  - Authenticate (`auth`) with your GitHub account that has Copilot access\n",
        "  - Start the local server (default: `http://localhost:7711`)\n",
        "- Then run the \"GitHub Copilot API setup (local proxy)\" cells below.\n",
        "\n",
        "Quick reference (see `README` for details):\n",
        "1. Download and install dependencies\n",
        "    ```bash\n",
        "    # Clone the repository\n",
        "    git clone git@github.com:snehangshu-splunk/copilot-api.git\n",
        "    cd copilot-api\n",
        "\n",
        "    # Install dependencies\n",
        "    uv sync\n",
        "    ```\n",
        "2. Before starting the server, you need to authenticate with GitHub:\n",
        "    ```bash\n",
        "    # For business account\n",
        "    uv run copilot2api auth --business\n",
        "    ```\n",
        "    When authenticating for the first time, you will see the following information:\n",
        "    ```\n",
        "    Press Ctrl+C to stop the server\n",
        "    Starting Copilot API server...\n",
        "    Starting GitHub device authorization flow...\n",
        "\n",
        "    Please enter the code '14B4-5D82' at:\n",
        "    https://github.com/login/device\n",
        "\n",
        "    Waiting for authorization...\n",
        "    ```\n",
        "    You need to copy `https://github.com/login/device` to your browser, then log in to your GitHub account through the browser. This GitHub account should have GitHub Copilot functionality. After authentication is complete, copy '14B4-5D82' in the browser prompt box. This string of numbers is system-generated and may be different each time.\n",
        "\n",
        "    > **Don't copy the code here.** If you copy this, it will only cause your authorization to fail.\n",
        "\n",
        "    After successful device authorization:\n",
        "    - macOS or Linux:\n",
        "    - In the `$HOME/.config/copilot2api/` directory, you will see the github-token file.\n",
        "    - Windows system:\n",
        "    - You will find the github-token file in the `C:\\Users\\<username>\\AppData\\Roaming\\copilot2api\\` directory.\n",
        "\n",
        "  3. Start the Server\n",
        "      ```bash\n",
        "        # Start API server (default port 7711)\n",
        "        uv run copilot2api start\n",
        "      ```\n",
        " Now use the OpenAI libraries to connect to the LLM, by executing the below cell.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHub Copilot API setup (local proxy)\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Configure for local GitHub Copilot proxy\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"http://localhost:7711/v1\",\n",
        "    api_key=\"dummy-key\"  # The local proxy doesn't need a real key\n",
        ")\n",
        "\n",
        "def get_chat_completion(messages, model=\"gpt-4\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Get a chat completion from the AI model.\n",
        "    \n",
        "    Args:\n",
        "        messages: List of message dictionaries with 'role' and 'content'\n",
        "        model: Model name (default: gpt-4)\n",
        "        temperature: Creativity level 0-1 (default: 0.7)\n",
        "    \n",
        "    Returns:\n",
        "        String response from the AI model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\\\\n\\\\nüí° Make sure the GitHub Copilot local proxy is running on port 7711\"\n",
        "\n",
        "print(\"‚úÖ GitHub Copilot API configured successfully!\")\n",
        "print(\"üîó Connected to: http://localhost:7711\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Direct OpenAI API\n",
        "\n",
        "If you prefer to use OpenAI directly, uncomment and run this cell instead:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Direct OpenAI API setup\n",
        "# import openai\n",
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv()\n",
        "\n",
        "# client = openai.OpenAI(\n",
        "#     api_key=os.getenv(\"OPENAI_API_KEY\")  # Set this in your .env file\n",
        "# )\n",
        "\n",
        "# def get_chat_completion(messages, model=\"gpt-4\", temperature=0.7):\n",
        "#     try:\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=model,\n",
        "#             messages=messages,\n",
        "#             temperature=temperature\n",
        "#         )\n",
        "#         return response.choices[0].message.content\n",
        "#     except Exception as e:\n",
        "#         return f\"‚ùå Error: {e}\"\n",
        "\n",
        "# print(\"‚úÖ OpenAI API configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option C: CircuIT APIs (Azure OpenAI)\n",
        "\n",
        "If you have CircuIT API access, you can use the Azure OpenAI-backed APIs instead of the Copilot proxy.\n",
        "\n",
        "- Ensure your environment variables are configured (`CISCO_CLIENT_ID`, `CISCO_CLIENT_SECRET`, `CISCO_OPENAI_APP_KEY`) in the `.env` file.\n",
        "\n",
        "<div style=\"margin-top:16px; color:#000000; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6\">\n",
        "<strong>üí° Remember:</strong><br><br>\n",
        "The values for these enviroment variables can be found at <strong><a href=\"https://ai-chat.cisco.com/bridgeit-platform/api/home\">https://ai-chat.cisco.com/bridgeit-platform/api/home</a></strong> by clicking the <code style=\"background:#f3f4f6; padding:2px 6px; border-radius:3px; color:#dc2626;\">View</code> button found against the <code style=\"background:#f3f4f6; padding:2px 6px; border-radius:3px; color:#dc2626;\">App Key</code>.\n",
        "</div>\n",
        "\n",
        "If you prefer to use CircuIT APIs, uncomment and run this cell instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import openai\n",
        "# import traceback\n",
        "# import requests\n",
        "# import base64\n",
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "# from openai import AzureOpenAI\n",
        "\n",
        "# # Load environment variables\n",
        "# load_dotenv()\n",
        "\n",
        "# # Open AI version to use\n",
        "# openai.api_type = \"azure\"\n",
        "# openai.api_version = \"2024-12-01-preview\"\n",
        "\n",
        "# # Get API_KEY wrapped in token - using environment variables\n",
        "# client_id = os.getenv(\"CISCO_CLIENT_ID\")\n",
        "# client_secret = os.getenv(\"CISCO_CLIENT_SECRET\")\n",
        "\n",
        "# url = \"https://id.cisco.com/oauth2/default/v1/token\"\n",
        "\n",
        "# payload = \"grant_type=client_credentials\"\n",
        "# value = base64.b64encode(f\"{client_id}:{client_secret}\".encode(\"utf-8\")).decode(\"utf-8\")\n",
        "# headers = {\n",
        "#     \"Accept\": \"*/*\",\n",
        "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "#     \"Authorization\": f\"Basic {value}\",\n",
        "# }\n",
        "\n",
        "# token_response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "# print(token_response.text)\n",
        "# token_data = token_response.json()\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#     azure_endpoint=\"https://chat-ai.cisco.com\",\n",
        "#     api_key=token_data.get(\"access_token\"),\n",
        "#     api_version=\"2024-12-01-preview\",\n",
        "# )\n",
        "\n",
        "# app_key = os.getenv(\"CISCO_OPENAI_APP_KEY\")\n",
        "\n",
        "# def get_chat_completion(messages, model=\"gpt-4o\", temperature=0.0):\n",
        "#     try:\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=model,\n",
        "#             messages=messages,\n",
        "#             temperature=temperature,\n",
        "#             user=f'{\"appkey\": \"{app_key}\"}',\n",
        "#         )\n",
        "#         return response.choices[0].message.content\n",
        "#     except Exception as e:\n",
        "#         return f\"‚ùå Error: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.3: Test Your Connection\n",
        "\n",
        "Let's verify everything is working by running your first structured prompt:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the connection with a simple prompt\n",
        "test_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful coding assistant. Respond with exactly: 'Connection successful! Ready for prompt engineering.'\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Test the connection\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_chat_completion(test_messages)\n",
        "print(\"üß™ Test Response:\")\n",
        "print(response)\n",
        "\n",
        "if response and \"Connection successful\" in response:\n",
        "    print(\"\\\\nüéâ Perfect! Your AI connection is working!\")\n",
        "else:\n",
        "    print(\"\\\\n‚ö†Ô∏è  Connection test complete, but response format may vary.\")\n",
        "    print(\"This is normal - let's continue with the tutorial!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint: Verify Your Progress\n",
        "\n",
        "Before continuing, let's make sure everything is working:\n",
        "\n",
        "1. ‚úÖ Check that you saw \"SUCCESS!\" from the dependency installation\n",
        "2. ‚úÖ Verify you saw \"configured successfully!\" from the API setup\n",
        "3. ‚úÖ Confirm you received a response from the test prompt\n",
        "\n",
        "If any of these checks fail, see the Troubleshooting section below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.4: Why Prompt Engineering for Software Engineers?\n",
        "\n",
        "Prompt engineering is the fastest way to harness the power of large language models. By interacting with an LLM through a series of questions, statements, or instructions, you can adjust LLM output behavior based on the specific context of the output you want to achieve.\n",
        "\n",
        "### üîç Traditional Approach vs. Prompt Engineering\n",
        "\n",
        "| **Traditional Approach**            | **Prompt Engineering Approach**                                                                                                                   |\n",
        "| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| ‚ùå Generic queries: \"Fix this code\" | ‚úÖ Specific requirements: \"Refactor this code following SOLID principles, add type hints, handle edge cases, and maintain backward compatibility\" |\n",
        "| ‚ùå Vague requests: \"Make it better\" | ‚úÖ Systematic analysis: Step-by-step code reviews covering security, performance, and maintainability                                             |\n",
        "| ‚ùå Inconsistent results and quality | ‚úÖ Consistent, production-ready outputs                                                                                                           |\n",
        "\n",
        "### üéØ Key Benefits\n",
        "\n",
        "Effective prompt techniques can help you accomplish the following benefits:\n",
        "\n",
        "- **üöÄ Boost a model's abilities and improve safety**  \n",
        "  Well-crafted prompts guide models toward more accurate and appropriate responses\n",
        "\n",
        "- **üß† Augment the model with domain knowledge and external tools**  \n",
        "  Without changing model parameters or fine-tuning\n",
        "\n",
        "- **üí° Interact with language models to grasp their full capabilities**  \n",
        "  Unlock advanced reasoning and problem-solving abilities\n",
        "\n",
        "- **üìà Achieve better quality outputs through better quality inputs**  \n",
        "  The precision of your prompts directly impacts the quality of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.5: Understanding Prompt Structure\n",
        "\n",
        "A prompt's form depends on the task you are giving to a model. Now that your environment is ready, let's understand what makes prompts effective by examining the **4 Core Elements**. Let's explore a basic example that demonstrates the key prompt elements in action.\n",
        "\n",
        "### üìñ Example Prompt\n",
        "\n",
        "Review the following prompt example to understand the structure of a prompt.\n",
        "\n",
        "```text\n",
        "You are a helpful writing assistant. Analyze the following email draft and provide suggestions for improvement.\n",
        "\n",
        "Email context: This is a follow-up email to a client after a project meeting.\n",
        "\n",
        "Email draft:\n",
        "\"Hi there,\n",
        "Thanks for the meeting. We discussed some stuff and I think we're on the right track. Let me know if you have questions.\n",
        "Best,\n",
        "John\"\n",
        "\n",
        "Please provide your response in the following format:\n",
        "1. Tone assessment\n",
        "2. Three specific improvement suggestions\n",
        "3. Revised email draft\n",
        "```\n",
        "---\n",
        "\n",
        "**The Output:**\n",
        "\n",
        "```text\n",
        "1. Tone assessment:\n",
        "The current tone is overly casual and vague for professional client communication. It lacks specificity and doesn't reinforce professionalism or next steps.\n",
        "\n",
        "2. Three specific improvement suggestions:\n",
        "- Replace \"Hi there\" with the client's name for personalization\n",
        "- Replace \"some stuff\" with specific meeting topics discussed\n",
        "- Add clear next steps and timeline expectations\n",
        "\n",
        "3. Revised email draft:\n",
        "\"Dear [Client Name],\n",
        "\n",
        "Thank you for taking the time to meet with us today. We had a productive discussion about the project timeline, budget considerations, and deliverable specifications. Based on our conversation, I believe we're aligned on the project direction and ready to move forward.\n",
        "\n",
        "I'll send you the detailed project proposal by Friday, and we can schedule a follow-up call next week to address any questions you might have.\n",
        "\n",
        "Best regards,\n",
        "John\"\n",
        "```\n",
        "---\n",
        "\n",
        "### The 4 Core Elements of Effective Prompts\n",
        "\n",
        "Every effective prompt contains these elements:\n",
        "\n",
        "1. **üìù Instructions** - What you want the AI to do\n",
        "2. **üåê Context** - Background information that helps the AI understand the situation\n",
        "3. **üìä Input Data** - The specific content to work with\n",
        "4. **üé® Output Format** - How you want the response structured\n",
        "\n",
        "Let's see this in action with a software engineering example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Code review prompt with all 4 elements\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            # 1. INSTRUCTIONS\n",
        "            \"You are a senior software engineer conducting a code review. \"\n",
        "            \"Analyze the provided code and identify potential issues.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "# 2. CONTEXT\n",
        "Code context: This is a utility function for user registration in a web application.\n",
        "\n",
        "# 3. INPUT DATA\n",
        "Code to review:\n",
        "```python\n",
        "def register_user(email, password):\n",
        "    if email and password:\n",
        "        user = {{\"email\": email, \"password\": password}}\n",
        "        return user\n",
        "    return None\n",
        "```\n",
        "\n",
        "# 4. OUTPUT FORMAT\n",
        "Please provide your response in this format:\n",
        "1. Security Issues (if any)\n",
        "2. Code Quality Issues (if any)  \n",
        "3. Recommended Improvements\n",
        "4. Overall Assessment\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_chat_completion(messages)\n",
        "print(\"üîç CODE REVIEW RESULT:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background:#f8f9fa; border-radius:8px; padding:18px 22px; margin-bottom:18px; border:1px solid #e0e0e0; box-shadow:0 1px 4px #0001\">\n",
        "\n",
        "<div style=\"font-weight:600; font-size:1.1em; color:#2d3748; margin-bottom:6px\">üèÉ‚Äç‚ôÄÔ∏è Practice Exercises</div>\n",
        "\n",
        "<div><span style=\"color:#718096; font-size:0.95em; font-weight:500; margin-right:6px\">Overview:</span><span style=\"font-family:monospace; background:#f1f5f9; padding:7px 10px; border-radius:5px; display:block; margin-top:3px; white-space:pre-wrap; color:#1a202c\">Ready to test your skills? The prompt-engineering-exercises.ipynb notebook contains hands-on activities that reinforce the concepts you've learned in this module.</span></div>\n",
        "\n",
        "<div><span style=\"color:#718096; font-size:0.95em; font-weight:500; margin-right:6px\">Module 1 Activities:</span><span style=\"font-family:monospace; background:#f1f5f9; padding:7px 10px; border-radius:5px; display:block; margin-top:3px; white-space:pre-wrap; color:#1a202c\">‚Ä¢ Activity 1.1: Analyze these prompts and identify missing elements\n",
        "‚Ä¢ Activity 1.2: Create a complete prompt with all 4 elements for code\n",
        "</span></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üéâ **Excellent!** You've just executed a structured prompt with all 4 core elements.\n",
        "\n",
        "üí° **What makes this work?**\n",
        "- **Clear role definition** (\"senior software engineer conducting code review\")\n",
        "- **Specific context** about the code's purpose\n",
        "- **Concrete input** to analyze\n",
        "- **Structured output format** for consistent results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Tracking Your Progress\n",
        "\n",
        "### Self-Assessment Questions\n",
        "\n",
        "After completing Module 1, ask yourself:\n",
        "1. Can I explain why structured prompts work better than vague ones?\n",
        "2. Can I apply the 4 core elements to my daily coding tasks?\n",
        "3. Can I teach a colleague how to write effective prompts?\n",
        "4. Can I create variations of prompts for different scenarios?\n",
        "\n",
        "### Progress Tracking\n",
        "\n",
        "<div style=\"background:#f8f9fa; border-radius:8px; padding:18px 22px; margin-bottom:18px; border:1px solid #e0e0e0; box-shadow:0 1px 4px #0001; color:#000000\">\n",
        "\n",
        "<span style=\"color:#000000; font-weight:600\">**Module 1 Skills Mastery:**</span> \n",
        "<div style=\"margin:10px 0; font-size:0.9em; color:#666\">Track your progress by checking off skills below. When you master all 8 skills, you'll have achieved 100% completion!</div>\n",
        "\n",
        "**Current Status:**\n",
        "- <span style=\"color:#059669\">‚úÖ Environment Setup (Tutorial Completed)</span>\n",
        "- <span style=\"color:#059669\">‚úÖ Basic Understanding (Tutorial Completed)</span>  \n",
        "- <span style=\"color:#e97316\">‚¨ú Skills Mastery (Use Skills Checklist below)</span>\n",
        "\n",
        "**Progress Guide:**\n",
        "- <span style=\"color:#666; font-size:0.9em\">0-2 skills checked: Beginner (50-63%)</span>\n",
        "- <span style=\"color:#666; font-size:0.9em\">3-5 skills checked: Intermediate (69-81%)</span>\n",
        "- <span style=\"color:#666; font-size:0.9em\">6-7 skills checked: Advanced (88-94%)</span>\n",
        "- <span style=\"color:#666; font-size:0.9em\">8 skills checked: Expert (100%) üéâ</span>\n",
        "\n",
        "<span style=\"color:#000000; font-weight:600\">**Module 2:**</span> <span style=\"color:#888888; font-weight:600\">Coming Next</span>\n",
        "- <span style=\"color:#888888\">‚¨ú Role Prompting Mastered</span>\n",
        "- <span style=\"color:#888888\">‚¨ú Delimiters & Structure</span>\n",
        "- <span style=\"color:#888888\">‚¨ú Few-Shot Examples</span>\n",
        "- <span style=\"color:#888888\">‚¨ú Chain-of-Thought Reasoning</span>\n",
        "\n",
        "</div>\n",
        "\n",
        "### Skills Checklist\n",
        "\n",
        "<div style=\"background:#f8f9fa; border-radius:8px; padding:18px 22px; margin-bottom:18px; border:1px solid #e0e0e0; box-shadow:0 1px 4px #0001; color:#000000\">\n",
        "\n",
        "<span style=\"color:#000000\">Mark each skill as you master it:</span>\n",
        "\n",
        "<span style=\"color:#000000; font-weight:600\">**Foundation Skills:**</span>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill1\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can identify the 4 core prompt elements in any example</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill2\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can convert vague requests into structured prompts</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill3\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can write clear instructions for AI assistants</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill4\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can provide appropriate context for coding tasks</span>\n",
        "</div>\n",
        "\n",
        "<span style=\"color:#000000; font-weight:600\">**Application Skills:**</span>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill5\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can use prompts for code review and analysis</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill6\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can adapt prompts for different programming languages</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill7\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can troubleshoot when prompts don't work as expected</span>\n",
        "</div>\n",
        "<div style=\"margin:8px 0\">\n",
        "- <input type=\"checkbox\" id=\"skill8\" onchange=\"this.nextSibling.style.textDecoration = this.checked ? 'line-through' : 'none'; this.nextSibling.style.color = this.checked ? '#888888' : '#000000'; this.nextSibling.style.fontWeight = this.checked ? 'normal' : '500';\"> <span style=\"color:#000000; font-weight:500\">I can explain prompt engineering benefits to my team</span>\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top:16px; color:#000000; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6\">\n",
        "<strong>üí° Remember:</strong><br><br>\n",
        "The goal is not just to complete activities, but to build lasting skills that transform your development workflow!\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Module 1 Complete! üéâ\n",
        "\n",
        "### What You've Accomplished\n",
        "- ‚úÖ Set up a working Python environment with AI model access\n",
        "- ‚úÖ Successfully executed your first structured prompt\n",
        "- ‚úÖ Learned the 4 core elements of effective prompts\n",
        "- ‚úÖ Conducted your first AI-powered code review\n",
        "\n",
        "### Next Steps\n",
        "Ready to learn advanced prompting techniques? \n",
        "Continue to **Module 2: Core Prompting Techniques** where you'll master:\n",
        "- Role prompting and personas for specialized expertise\n",
        "- Using delimiters and structured inputs\n",
        "- Few-shot examples and chain-of-thought reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "#### Issue: \"pip install failed\" or \"ModuleNotFoundError\"\n",
        "**Solution**: \n",
        "1. Make sure you're in the correct directory with `requirements.txt`\n",
        "2. Try installing packages individually: `pip install openai anthropic python-dotenv requests`\n",
        "3. If using a virtual environment, make sure it's activated\n",
        "\n",
        "#### Issue: \"Connection failed\" or \"Error connecting to localhost:7711\"\n",
        "**Solution**: \n",
        "1. Make sure the GitHub Copilot local proxy is running\n",
        "2. Follow the setup instructions in `GitHub-Copilot-2-API/README.md`\n",
        "3. Alternative: Use Option B (Direct OpenAI API) instead\n",
        "\n",
        "#### Issue: \"Invalid API key\" or authentication errors\n",
        "**Solution**: \n",
        "1. For GitHub Copilot: Ensure you've authenticated with `uv run copilot2api auth --business`\n",
        "2. For OpenAI: Check that your API key is correctly set in the `.env` file\n",
        "3. Verify your account has the necessary permissions\n",
        "\n",
        "## Complete Code Reference\n",
        "\n",
        "Here's the complete setup code for reference:\n",
        "\n",
        "```python\n",
        "# Install requirements\n",
        "import subprocess\n",
        "import sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"../requirements.txt\"])\n",
        "\n",
        "# Configure API client\n",
        "import openai\n",
        "client = openai.OpenAI(base_url=\"http://localhost:7711/v1\", api_key=\"dummy-key\")\n",
        "\n",
        "# Helper function\n",
        "def get_chat_completion(messages, model=\"gpt-4\", temperature=0.7):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model, messages=messages, temperature=temperature\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "üéä **Congratulations!** You've completed Module 1 and are ready to become a prompt engineering expert!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
